{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport sys\nimport time\nimport numpy as np\nfrom sklearn.metrics import f1_score\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-20T08:49:50.565846Z","iopub.execute_input":"2023-08-20T08:49:50.566940Z","iopub.status.idle":"2023-08-20T08:49:51.869772Z","shell.execute_reply.started":"2023-08-20T08:49:50.566899Z","shell.execute_reply":"2023-08-20T08:49:51.868793Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}]},{"cell_type":"code","source":"!pip install pytorch-metric-learning","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:49:51.871967Z","iopub.execute_input":"2023-08-20T08:49:51.872659Z","iopub.status.idle":"2023-08-20T08:50:06.687538Z","shell.execute_reply.started":"2023-08-20T08:49:51.872623Z","shell.execute_reply":"2023-08-20T08:50:06.686355Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pytorch-metric-learning\n  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (1.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (4.65.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (1.11.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\nInstalling collected packages: pytorch-metric-learning\nSuccessfully installed pytorch-metric-learning-2.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torchvision\n\nclass ResNet(nn.Module):\n    \"\"\"encoder + classifier\"\"\"\n    def __init__(self, name='resnet50', num_classes=2):\n        super(ResNet, self).__init__()\n        if (name == 'resnet50'):\n            self.encoder = torchvision.models.resnet50(zero_init_residual=True)\n            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            self.encoder.fc = nn.Identity()\n            self.fc = nn.Linear(2048, num_classes)\n        else:\n            self.encoder = torchvision.models.resnet18(zero_init_residual=True)\n            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n            self.encoder.fc = nn.Identity()\n            self.fc = nn.Linear(512, num_classes)\n    def forward(self, x):\n\n        return self.fc(self.encoder(x))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:06.690568Z","iopub.execute_input":"2023-08-20T08:50:06.691192Z","iopub.status.idle":"2023-08-20T08:50:10.064612Z","shell.execute_reply.started":"2023-08-20T08:50:06.691153Z","shell.execute_reply":"2023-08-20T08:50:10.063514Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Prj_Head(nn.Module):\n    def __init__(self,in_dim,feature_dim):\n        super(Prj_Head, self).__init__()\n        \n        self.g1 = nn.Sequential(nn.Linear(in_dim, 1024, bias=False),\n                               nn.BatchNorm1d(1024),\n                               nn.ReLU(inplace=True)\n                               )\n        self.g2 = nn.Sequential(nn.Linear(1024, 512, bias=False),\n                                nn.BatchNorm1d(512),\n                                nn.ReLU(inplace=True)\n                                )\n        self.g3=nn.Linear(512, feature_dim, bias=True)\n    def forward(self, x):\n        # print(x.shape)\n        x = torch.flatten(x, start_dim=1, end_dim=- 1) \n        x = self.g1(x)\n        x = self.g2(x)\n        x = self.g3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.067359Z","iopub.execute_input":"2023-08-20T08:50:10.068252Z","iopub.status.idle":"2023-08-20T08:50:10.075874Z","shell.execute_reply.started":"2023-08-20T08:50:10.068214Z","shell.execute_reply":"2023-08-20T08:50:10.074970Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Encdr(nn.Module):\n    \"\"\"encoder + classifier\"\"\"\n    def __init__(self, name='resnet50', num_classes=2):\n        super(Encdr, self).__init__()\n        self.encoder = torchvision.models.resnet50(pretrained=True, zero_init_residual=True)\n        self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.encoder.fc = nn.Identity()\n        self.fc = nn.Linear(2048, 512)\n\n    def forward(self, x):\n\n        return self.fc(self.encoder(x))\n    \n    def add_feature(self):\n        self.fc1=nn.Linear(512,2)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.077186Z","iopub.execute_input":"2023-08-20T08:50:10.077959Z","iopub.status.idle":"2023-08-20T08:50:10.089969Z","shell.execute_reply.started":"2023-08-20T08:50:10.077926Z","shell.execute_reply":"2023-08-20T08:50:10.088956Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# datasets.py\n\nimport torch.utils.data as data\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\n\nclass OLIVES(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        path = self.img_dir + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n        b1 = self.df.iloc[idx,1]\n        b2 = self.df.iloc[idx,2]\n        b3 = self.df.iloc[idx,3]\n        b4 = self.df.iloc[idx, 4]\n        b5 = self.df.iloc[idx, 5]\n        b6 = self.df.iloc[idx, 6]\n        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n        return image, bio_tensor\n\n\n\n\nclass RECOVERY(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        path = self.img_dir + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n        return image\n\n\n\nclass RECOVERY_TEST(data.Dataset):\n    def __init__(self,df, img_dir, transforms):\n        self.img_dir = img_dir\n        self.transforms = transforms\n        self.df = pd.read_csv(df)\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        path = self.img_dir + self.df.iloc[idx,0]\n        image = Image.open(path).convert(\"L\")\n        image = np.array(image)\n        image = Image.fromarray(image)\n        image = self.transforms(image)\n        b1 = self.df.iloc[idx,1]\n        b2 = self.df.iloc[idx,2]\n        b3 = self.df.iloc[idx,3]\n        b4 = self.df.iloc[idx, 4]\n        b5 = self.df.iloc[idx, 5]\n        b6 = self.df.iloc[idx, 6]\n        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n        return image, bio_tensor\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.091483Z","iopub.execute_input":"2023-08-20T08:50:10.092103Z","iopub.status.idle":"2023-08-20T08:50:10.110754Z","shell.execute_reply.started":"2023-08-20T08:50:10.092061Z","shell.execute_reply":"2023-08-20T08:50:10.109773Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# data_preprocessing.py\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport glob\nfrom tqdm import tqdm\nfrom PIL import Image\n\ndef combine_excel(csv_dir):\n    filenames = glob.glob(csv_dir + \"/*.xlsx\")\n    outputxlsx = pd.DataFrame()\n\n    for file in filenames:\n        df = pd.concat(pd.read_excel(file, sheet_name=None), ignore_index=True, sort=False)\n        outputxlsx = outputxlsx.append(df, ignore_index=True)\n\n    outputxlsx.to_csv('test_set_labels.csv',index=False)\n\ndef analyze_dataframe(csv_dir):\n    pass\n\ndef process_images(csv_dir):\n    df = pd.read_csv(csv_dir)\n\n    for i in tqdm(range(0,len(df))):\n        path = df.iloc[i,0]\n        im = Image.open(path).convert('L')\n\n\ndef numpy_submission(sub_dir,np_dir):\n    np_file  = np.load(np_dir)\n    print(len(np_file))\n    sub_dir = pd.read_csv(sub_dir)\n    print(len(sub_dir))\n    for i in range(0,len(sub_dir)):\n        sub_dir.iloc[i,1] = np_file[i,0]\n        sub_dir.iloc[i, 2] = np_file[i, 1]\n        sub_dir.iloc[i, 3] = np_file[i, 2]\n        sub_dir.iloc[i, 4] = np_file[i, 3]\n        sub_dir.iloc[i, 5] = np_file[i, 4]\n        sub_dir.iloc[i, 6] = np_file[i, 5]\n    print(sub_dir.head())\n    sub_dir.to_csv('baseline_result.csv',index=False)\n\n\n\n    #process_images(csv_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.112169Z","iopub.execute_input":"2023-08-20T08:50:10.112766Z","iopub.status.idle":"2023-08-20T08:50:10.127806Z","shell.execute_reply.started":"2023-08-20T08:50:10.112705Z","shell.execute_reply":"2023-08-20T08:50:10.126773Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\n\nimport math\nimport numpy as np\nimport torch.optim as optim\nimport os\nfrom sklearn.metrics import f1_score\nimport torch.backends.cudnn as cudnn\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import random_split, Subset\n\nimport torch.nn as nn\ndef set_model(opt, freeze = False):\n\n\n    device = opt.device\n    model = ResNet(name=opt.model,num_classes = opt.ncls)\n    if freeze:\n        model.encoder.requires_grad_(False)\n    criterion = torch.nn.BCEWithLogitsLoss()\n\n    model = model.to(device)\n    criterion = criterion.to(device)\n\n\n    return model, criterion\n\n\n# model for self supervised training\n\ndef set_model_st(opt,Net):\n\n\n    device = opt.device\n    #model = Encdr(name=opt.model,num_classes = opt.ncls)\n    model = nn.Sequential(\n    Net, \n    nn.ReLU(),\n    nn.Linear(512, 6))\n    criterion = torch.nn.BCEWithLogitsLoss()\n\n    model = model.to(device)\n    criterion = criterion.to(device)\n\n\n    return model, criterion\n\n\n\n\ndef set_loader(opt):\n    # construct data loader\n    if opt.dataset == 'OLIVES' or opt.dataset == 'RECOVERY':\n        mean = (.1706)\n        std = (.2112)\n    else:\n        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n\n    normalize = transforms.Normalize(mean=mean, std=std)\n\n    train_transform = transforms.Compose([\n        transforms.RandomResizedCrop(size=224, scale=(0.5, 1.)),\n        transforms.RandomHorizontalFlip(),\n\n        transforms.RandomApply([\n            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n        ], p=0.8),\n        transforms.RandomGrayscale(p=0.2),\n        transforms.ToTensor(),\n        normalize,\n    ])\n\n    val_transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        normalize,\n    ])\n\n\n    if opt.dataset =='OLIVES':\n        csv_path_train = opt.train_csv_path\n        csv_path_test = opt.test_csv_path\n        data_path_train = opt.train_image_path\n        data_path_test = opt.test_image_path\n        train_dataset = OLIVES(csv_path_train,data_path_train,transforms = train_transform)\n        unlabelled_train_dataset = RECOVERY(csv_path_unlabelled,data_path_train,transforms = val_transform)\n        test_dataset = RECOVERY(csv_path_test,data_path_test,transforms = val_transform)\n        train_dataset, val_dataset = random_split(train_dataset, [0.95, 0.05], generator=torch.Generator().manual_seed(42))\n        unlabelled_train_dataset = Subset(unlabelled_train_dataset, range(unlabel_count))\n    else:\n        raise ValueError(opt.dataset)\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=opt.batch_size, shuffle=True,\n        num_workers=opt.num_workers, pin_memory=True)\n    \n    val_loader = torch.utils.data.DataLoader(\n        val_dataset, batch_size=1, shuffle=False,\n        num_workers=0, pin_memory=True,drop_last=False)\n    \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=1, shuffle=False,\n        num_workers=0, pin_memory=True,drop_last=False)\n    \n    unlabelled_train_loader = torch.utils.data.DataLoader(\n        unlabelled_train_dataset, batch_size=opt.batch_size, shuffle=True,\n        num_workers=opt.num_workers, pin_memory=True)\n\n    return train_loader, val_loader, test_loader, unlabelled_train_loader\n\n\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\ndef adjust_learning_rate(args, optimizer, epoch):\n    lr = args.learning_rate\n    if args.cosine:\n        eta_min = lr * (args.lr_decay_rate ** 3)\n        lr = eta_min + (lr - eta_min) * (\n                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n    else:\n        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n        if steps > 0:\n            lr = lr * (args.lr_decay_rate ** steps)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n    if args.warm and epoch <= args.warm_epochs:\n        p = (batch_id + (epoch - 1) * total_batches) / \\\n            (args.warm_epochs * total_batches)\n        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\n\ndef set_optimizer(opt, model):\n\n    optimizer = optim.SGD(model.parameters(),\n                          lr=opt.learning_rate,\n                          momentum=opt.momentum,\n                          weight_decay=opt.weight_decay)\n\n\n    return optimizer\n\n\ndef save_model(model, optimizer, opt, epoch, save_file):\n    print('==> Saving...')\n    state = {\n        'opt': opt,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'epoch': epoch,\n    }\n    torch.save(state, save_file)\n    del state","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.129118Z","iopub.execute_input":"2023-08-20T08:50:10.131032Z","iopub.status.idle":"2023-08-20T08:50:10.161636Z","shell.execute_reply.started":"2023-08-20T08:50:10.130998Z","shell.execute_reply":"2023-08-20T08:50:10.160694Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#----------------------------------------------------------------------------------------------------\n# Augmentations\nfrom torchvision import transforms\nclass GaussianBlur(object):\n    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n    \"\"\"Borrowed from MoCo implementation\"\"\"\n\n    def __init__(self, sigma=[.1, 2.]):\n        self.sigma = sigma\n\n    def __call__(self, x):\n        sigma = random.uniform(self.sigma[0], self.sigma[1])\n        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n        return x\n    \nclass FixedRandomRotation:\n    \"\"\"Rotate by one of the given angles.\"\"\"\n    def __init__(self, angles):\n        self.angles = angles\n\n    def __call__(self, x):\n        angle = random.choice(self.angles)\n        return transforms.functional.rotate(x, angle)\n    \ndef torchvision_transforms(eval=False, aug=None):\n\n    trans = []\n\n    if aug[\"resize\"]:\n        trans.append(transforms.Resize(aug[\"resize\"]))\n\n    if aug[\"randcrop\"] and aug[\"scale\"] and not eval:\n        trans.append(transforms.RandomResizedCrop(aug[\"randcrop\"], scale=aug[\"scale\"]))\n\n    if aug[\"randcrop\"] and eval:\n        trans.append(transforms.CenterCrop(aug[\"randcrop\"]))\n\n    if aug[\"flip\"] and not eval:\n        trans.append(transforms.RandomHorizontalFlip(p=0.5))\n        trans.append(transforms.RandomVerticalFlip(p=0.5))\n\n    if aug[\"jitter_d\"] and not eval:\n        trans.append(transforms.RandomApply(\n            [transforms.ColorJitter(0.8*aug[\"jitter_d\"], 0.8*aug[\"jitter_d\"], 0.8*aug[\"jitter_d\"], 0.2*aug[\"jitter_d\"])],\n             p=aug[\"jitter_p\"]))\n\n    if aug[\"gaussian_blur\"] and not eval:\n        trans.append(transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1,.2))], p=aug[\"gaussian_blur\"]))\n\n    if aug[\"rotation\"] and not eval:\n        # rotation_transform = FixedRandomRotation(angles=[0, 90, 180, 270])\n        trans.append(FixedRandomRotation(angles=[0, 90, 180, 270]))\n\n\n    trans = transforms.Compose(trans)\n   \n    return trans\naug = {\"resize\":0,\n    \"randcrop\":224,\n      \"scale\": (0.25, 1.0),\n      \"flip\":0,\n      \"jitter_d\":0.3,\n       \"jitter_p\":0.3,\n       \"gaussian_blur\":0.5,\n       \"rotation\":1\n      }\naugmentations = torchvision_transforms(aug = aug)\nprint(augmentations)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.163199Z","iopub.execute_input":"2023-08-20T08:50:10.163550Z","iopub.status.idle":"2023-08-20T08:50:10.182991Z","shell.execute_reply.started":"2023-08-20T08:50:10.163516Z","shell.execute_reply":"2023-08-20T08:50:10.181824Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Compose(\n    RandomResizedCrop(size=(224, 224), scale=(0.25, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n    RandomApply(\n    p=0.3\n    ColorJitter(brightness=(0.76, 1.24), contrast=(0.76, 1.24), saturation=(0.76, 1.24), hue=(-0.06, 0.06))\n)\n    RandomApply(\n    p=0.5\n    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.2))\n)\n    <__main__.FixedRandomRotation object at 0x7b0a755aeb30>\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# config.py\n\nimport argparse\nimport math\nimport os\n\ndef parse_option(string):\n    parser = argparse.ArgumentParser('argument for training')\n\n    parser.add_argument('--print_freq', type=int, default=10,\n                        help='print frequency')\n    parser.add_argument('--save_freq', type=int, default=50,\n                        help='save frequency')\n    parser.add_argument('--batch_size', type=int, default=128,\n                        help='batch_size')\n    parser.add_argument('--num_workers', type=int, default=8,\n                        help='num of workers to use')\n    parser.add_argument('--epochs', type=int, default=100,\n                        help='number of training epochs')\n    parser.add_argument('--device', type=str, default='cuda:0')\n    # optimization\n    parser.add_argument('--learning_rate', type=float, default=0.05,\n                        help='learning rate')\n    parser.add_argument('--patient_lambda', type=float, default=1,\n                        help='learning rate')\n    parser.add_argument('--cluster_lambda', type=float, default=1,\n                        help='learning rate')\n    parser.add_argument('--lr_decay_epochs', type=str, default='100',\n                        help='where to decay lr, can be a list')\n    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n                        help='decay rate for learning rate')\n    parser.add_argument('--weight_decay', type=float, default=1e-4,\n                        help='weight decay')\n    parser.add_argument('--momentum', type=float, default=0.9,\n                        help='momentum')\n    parser.add_argument('--train_csv_path', type=str, default='train data csv')\n    parser.add_argument('--test_csv_path', type=str, default='test data csv')\n    parser.add_argument('--train_image_path', type=str, default='train data csv')\n    parser.add_argument('--test_image_path', type=str, default='test data csv')\n\n    parser.add_argument('--parallel', type=int, default=1, help='data parallel')\n    parser.add_argument('--ncls', type=int, default=6, help='Number of Classes')\n    # model dataset\n    parser.add_argument('--model', type=str, default='resnet50')\n    parser.add_argument('--dataset', type=str, default='TREX_DME',\n                        choices=[ 'OLIVES'], help='dataset')\n    parser.add_argument('--mean', type=str, help='mean of dataset in path in form of str tuple')\n    parser.add_argument('--std', type=str, help='std of dataset in path in form of str tuple')\n    parser.add_argument('--data_folder', type=str, default=None, help='path to custom dataset')\n    parser.add_argument('--size', type=int, default=128, help='parameter for RandomResizedCrop')\n\n    # temperature\n    parser.add_argument('--temp', type=float, default=0.07,\n                        help='temperature for loss function')\n\n\n\n    opt = parser.parse_args(string)\n\n    # check if dataset is path that passed required arguments\n    if opt.dataset == 'path':\n        assert opt.data_folder is not None \\\n               and opt.mean is not None \\\n               and opt.std is not None\n\n    # set the path according to the environment\n    if opt.data_folder is None:\n        opt.data_folder = './datasets/'\n    opt.model_path = './save/{}_models'.format(opt.dataset)\n\n    iterations = opt.lr_decay_epochs.split(',')\n    opt.lr_decay_epochs = list([])\n    for it in iterations:\n        opt.lr_decay_epochs.append(int(it))\n\n    opt.model_name = '{}_lr_{}_decay_{}_bsz_{}_temp_{}'. \\\n        format(opt.model, opt.learning_rate,\n               opt.weight_decay, opt.batch_size, opt.temp)\n\n\n    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n    if not os.path.isdir(opt.save_folder):\n        os.makedirs(opt.save_folder)\n\n    return opt","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.187899Z","iopub.execute_input":"2023-08-20T08:50:10.188166Z","iopub.status.idle":"2023-08-20T08:50:10.208639Z","shell.execute_reply.started":"2023-08-20T08:50:10.188143Z","shell.execute_reply":"2023-08-20T08:50:10.207675Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from pytorch_metric_learning.losses import NTXentLoss\nss_loss_func = NTXentLoss(temperature=0.10)\n\ndef train_ss(Net,projection_head,data_loader, epoch):\n    Net.train()\n    projection_head.train()\n    total_loss = AverageMeter()\n    for idx, x in enumerate(data_loader): \n        # print(batch_idx)\n        optimizer.zero_grad()\n        x = x.to(device)\n        # Get data representations\n        \n        A1 = augmentations(x)\n        A2 = augmentations(x)\n        \n        h1 = Net(A1)\n        z1 = projection_head(h1)\n        \n        h2 = Net(A2)\n        z2 = projection_head(h2)\n        \n        # Prepare for loss\n        embeddings = torch.cat((z1, z2))\n        # The same index corresponds to a positive pair\n        indices = torch.arange(0, z1.size(0), device=z2.device)\n        labels = torch.cat((indices, indices))\n        loss = ss_loss_func(embeddings, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss.update(loss.data.item())\n        \n        # print info\n        if (idx + 1) % 50 == 0:\n            print('Train: [{0}][{1}/{2}]\\t'.format(\n                epoch, idx + 1, len(data_loader)))\n            \n    return total_loss.avg","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.210130Z","iopub.execute_input":"2023-08-20T08:50:10.210522Z","iopub.status.idle":"2023-08-20T08:50:10.239848Z","shell.execute_reply.started":"2023-08-20T08:50:10.210488Z","shell.execute_reply":"2023-08-20T08:50:10.238893Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_supervised(train_loader, model,criterion, optimizer, epoch, opt):\n    \"\"\"one epoch training\"\"\"\n    model.train()\n\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    device = opt.device\n    end = time.time()\n    correct_predictions = 0\n\n    for idx, (image, bio_tensor) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n\n        images = image.to(device)\n\n        labels = bio_tensor.float()\n\n        labels = labels.to(device)\n        bsz = labels.shape[0]\n\n        # compute loss\n        output = model(images)\n        loss = criterion(output, labels)\n        \n        # Calculate training accuracy\n        predicted_labels = torch.round(torch.sigmoid(output)) \n        correct_predictions += (predicted_labels == labels).sum().item()\n\n        # update metric\n        losses.update(loss.item(), bsz)\n\n        # SGD\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        # print info\n        if (idx + 1) % 10 == 0:\n            print('Train: [{0}][{1}/{2}]\\t'.format(\n                epoch, idx + 1, len(train_loader)))\n\n            sys.stdout.flush()\n\n    total_values = len(train_loader.dataset) * 6\n    training_accuracy = (correct_predictions / total_values) * 100.0\n    print(f\"Training Accuracy: {training_accuracy:.2f}%\")\n    \n    return losses.avg\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.243081Z","iopub.execute_input":"2023-08-20T08:50:10.243529Z","iopub.status.idle":"2023-08-20T08:50:10.253620Z","shell.execute_reply.started":"2023-08-20T08:50:10.243495Z","shell.execute_reply":"2023-08-20T08:50:10.252613Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def submission_generate(val_loader, model, opt):\n    \"\"\"validation\"\"\"\n    model.eval()\n\n    device = opt.device\n    out_list = []\n    with torch.no_grad():\n        for idx, image in (enumerate(val_loader)):\n\n            images = image.float().to(device)\n\n            # forward\n            output = model(images)\n            output = torch.round(torch.sigmoid(output))\n            out_list.append(output.squeeze().detach().cpu().numpy())\n\n\n    out_submisison = np.array(out_list)\n    np.save('output',out_submisison)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.255174Z","iopub.execute_input":"2023-08-20T08:50:10.255585Z","iopub.status.idle":"2023-08-20T08:50:10.269402Z","shell.execute_reply.started":"2023-08-20T08:50:10.255551Z","shell.execute_reply":"2023-08-20T08:50:10.268580Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def sample_evaluation(val_loader, model, opt):\n    \"\"\"validation\"\"\"\n    model.eval()\n\n    device = opt.device\n    out_list = []\n    label_list = []\n    correct_count = 0\n    total_count = 0\n\n    with torch.no_grad():\n        for idx, (image,bio_tensor) in (enumerate(val_loader)):\n\n            images = image.float().to(device)\n            labels = bio_tensor.float().to(device)\n\n            labels = labels.float()\n\n            label_list.append(labels.squeeze().detach().cpu().numpy())\n            # forward\n            output = model(images)\n            output = torch.round(torch.sigmoid(output))\n            out_list.append(output.squeeze().detach().cpu().numpy())\n            \n            correct_count += (labels == output).sum().item()\n            total_count += len(labels) * 6\n        \n    print((correct_count / total_count) * 100, \"%\")\n\n    label_array = np.array(label_list)\n    out_array = np.array(out_list)\n    f = f1_score(label_array,out_array,average='macro')\n    print(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.270947Z","iopub.execute_input":"2023-08-20T08:50:10.271281Z","iopub.status.idle":"2023-08-20T08:50:10.281925Z","shell.execute_reply.started":"2023-08-20T08:50:10.271250Z","shell.execute_reply":"2023-08-20T08:50:10.281063Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = args = ['--batch_size', '64', '--model', \"resnet50\", '--dataset', 'OLIVES', '--epochs', '120', '--device', 'cuda:0', '--train_image_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TRAIN/OLIVES', '--test_image_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/', '--test_csv_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv', '--train_csv_path', '/kaggle/input/olives-training-labels/Training_Biomarker_Data.csv']\nopt = parse_option(args)\ncsv_path_unlabelled = \"/kaggle/input/olives-training-labels/unlabelled_images.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.283463Z","iopub.execute_input":"2023-08-20T08:50:10.283906Z","iopub.status.idle":"2023-08-20T08:50:10.300206Z","shell.execute_reply.started":"2023-08-20T08:50:10.283873Z","shell.execute_reply":"2023-08-20T08:50:10.299205Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# build data loader\nunlabel_count = 20000\ntrain_loader, val_loader, test_loader, unlabelled_train_loader = set_loader(opt)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.303286Z","iopub.execute_input":"2023-08-20T08:50:10.303557Z","iopub.status.idle":"2023-08-20T08:50:10.584929Z","shell.execute_reply.started":"2023-08-20T08:50:10.303534Z","shell.execute_reply":"2023-08-20T08:50:10.583957Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}]},{"cell_type":"code","source":"len(unlabelled_train_loader)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.586287Z","iopub.execute_input":"2023-08-20T08:50:10.587661Z","iopub.status.idle":"2023-08-20T08:50:10.593823Z","shell.execute_reply.started":"2023-08-20T08:50:10.587624Z","shell.execute_reply":"2023-08-20T08:50:10.592919Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"313"},"metadata":{}}]},{"cell_type":"code","source":"# build optimizer\n#optimizer = set_optimizer(opt, model)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.595282Z","iopub.execute_input":"2023-08-20T08:50:10.595927Z","iopub.status.idle":"2023-08-20T08:50:10.604769Z","shell.execute_reply.started":"2023-08-20T08:50:10.595895Z","shell.execute_reply":"2023-08-20T08:50:10.603731Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#--------------------------------------------------------------------------\ndevice = torch.device(\"cuda:0\" )\nNet = Encdr().to(device)\nprojection_head = Prj_Head(512,128).to(device)\n\noptimizer = torch.optim.Adam(list(Net.parameters())+list(projection_head.parameters()), lr=0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n\n#train(Net,projection_head,train_loader)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:10.607226Z","iopub.execute_input":"2023-08-20T08:50:10.608311Z","iopub.status.idle":"2023-08-20T08:50:15.396606Z","shell.execute_reply.started":"2023-08-20T08:50:10.608274Z","shell.execute_reply":"2023-08-20T08:50:15.395587Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:01<00:00, 87.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"n_epoch = 40\nloss_list = []\nbest_loss = 10000\nsave_file = os.path.join(opt.save_folder, 'last.pth')\n#save_model(model, optimizer, opt, opt.epochs, save_file)\n\nfor epoch in range(1, n_epoch):\n    loss = train_ss(Net,projection_head,unlabelled_train_loader, epoch)\n    print(f'Epoch {epoch:3d}, Loss: {loss:.4f}')\n    scheduler.step()\n    loss_list.append(loss)\n    if loss<best_loss:\n        best_loss = loss\n        #torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_best_loss.pth.tar') \n        save_model(Net, optimizer, opt, opt.epochs, save_file)\n    elif n_epoch%10 ==0:\n        best_loss = loss\n        #torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_checkpoint.pth.tar') \n        save_model(Net, optimizer, opt, opt.epochs, save_file)\n#torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_final_checkpoint.pth.tar') \nplt.figure()\nplt.plot(loss_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T08:50:15.398277Z","iopub.execute_input":"2023-08-20T08:50:15.398652Z","iopub.status.idle":"2023-08-20T10:55:38.889460Z","shell.execute_reply.started":"2023-08-20T08:50:15.398614Z","shell.execute_reply":"2023-08-20T10:55:38.888344Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train: [1][50/313]\t\nTrain: [1][100/313]\t\nTrain: [1][150/313]\t\nTrain: [1][200/313]\t\nTrain: [1][250/313]\t\nTrain: [1][300/313]\t\nEpoch   1, Loss: 2.6876\n==> Saving...\nTrain: [2][50/313]\t\nTrain: [2][100/313]\t\nTrain: [2][150/313]\t\nTrain: [2][200/313]\t\nTrain: [2][250/313]\t\nTrain: [2][300/313]\t\nEpoch   2, Loss: 1.7958\n==> Saving...\nTrain: [3][50/313]\t\nTrain: [3][100/313]\t\nTrain: [3][150/313]\t\nTrain: [3][200/313]\t\nTrain: [3][250/313]\t\nTrain: [3][300/313]\t\nEpoch   3, Loss: 1.2322\n==> Saving...\nTrain: [4][50/313]\t\nTrain: [4][100/313]\t\nTrain: [4][150/313]\t\nTrain: [4][200/313]\t\nTrain: [4][250/313]\t\nTrain: [4][300/313]\t\nEpoch   4, Loss: 1.0204\n==> Saving...\nTrain: [5][50/313]\t\nTrain: [5][100/313]\t\nTrain: [5][150/313]\t\nTrain: [5][200/313]\t\nTrain: [5][250/313]\t\nTrain: [5][300/313]\t\nEpoch   5, Loss: 0.8110\n==> Saving...\nTrain: [6][50/313]\t\nTrain: [6][100/313]\t\nTrain: [6][150/313]\t\nTrain: [6][200/313]\t\nTrain: [6][250/313]\t\nTrain: [6][300/313]\t\nEpoch   6, Loss: 0.6971\n==> Saving...\nTrain: [7][50/313]\t\nTrain: [7][100/313]\t\nTrain: [7][150/313]\t\nTrain: [7][200/313]\t\nTrain: [7][250/313]\t\nTrain: [7][300/313]\t\nEpoch   7, Loss: 0.5409\n==> Saving...\nTrain: [8][50/313]\t\nTrain: [8][100/313]\t\nTrain: [8][150/313]\t\nTrain: [8][200/313]\t\nTrain: [8][250/313]\t\nTrain: [8][300/313]\t\nEpoch   8, Loss: 0.5348\n==> Saving...\nTrain: [9][50/313]\t\nTrain: [9][100/313]\t\nTrain: [9][150/313]\t\nTrain: [9][200/313]\t\nTrain: [9][250/313]\t\nTrain: [9][300/313]\t\nEpoch   9, Loss: 0.5728\n==> Saving...\nTrain: [10][50/313]\t\nTrain: [10][100/313]\t\nTrain: [10][150/313]\t\nTrain: [10][200/313]\t\nTrain: [10][250/313]\t\nTrain: [10][300/313]\t\nEpoch  10, Loss: 0.5006\n==> Saving...\nTrain: [11][50/313]\t\nTrain: [11][100/313]\t\nTrain: [11][150/313]\t\nTrain: [11][200/313]\t\nTrain: [11][250/313]\t\nTrain: [11][300/313]\t\nEpoch  11, Loss: 0.4691\n==> Saving...\nTrain: [12][50/313]\t\nTrain: [12][100/313]\t\nTrain: [12][150/313]\t\nTrain: [12][200/313]\t\nTrain: [12][250/313]\t\nTrain: [12][300/313]\t\nEpoch  12, Loss: 0.4101\n==> Saving...\nTrain: [13][50/313]\t\nTrain: [13][100/313]\t\nTrain: [13][150/313]\t\nTrain: [13][200/313]\t\nTrain: [13][250/313]\t\nTrain: [13][300/313]\t\nEpoch  13, Loss: 0.3256\n==> Saving...\nTrain: [14][50/313]\t\nTrain: [14][100/313]\t\nTrain: [14][150/313]\t\nTrain: [14][200/313]\t\nTrain: [14][250/313]\t\nTrain: [14][300/313]\t\nEpoch  14, Loss: 0.3577\n==> Saving...\nTrain: [15][50/313]\t\nTrain: [15][100/313]\t\nTrain: [15][150/313]\t\nTrain: [15][200/313]\t\nTrain: [15][250/313]\t\nTrain: [15][300/313]\t\nEpoch  15, Loss: 0.3987\n==> Saving...\nTrain: [16][50/313]\t\nTrain: [16][100/313]\t\nTrain: [16][150/313]\t\nTrain: [16][200/313]\t\nTrain: [16][250/313]\t\nTrain: [16][300/313]\t\nEpoch  16, Loss: 0.3217\n==> Saving...\nTrain: [17][50/313]\t\nTrain: [17][100/313]\t\nTrain: [17][150/313]\t\nTrain: [17][200/313]\t\nTrain: [17][300/313]\t\nEpoch  17, Loss: 0.3679\n==> Saving...\nTrain: [18][50/313]\t\nTrain: [18][100/313]\t\nTrain: [18][150/313]\t\nTrain: [18][200/313]\t\nTrain: [18][250/313]\t\nTrain: [18][300/313]\t\nEpoch  18, Loss: 0.3455\n==> Saving...\nTrain: [19][50/313]\t\nTrain: [19][100/313]\t\nTrain: [19][150/313]\t\nTrain: [19][200/313]\t\nTrain: [19][250/313]\t\nTrain: [19][300/313]\t\nEpoch  19, Loss: 0.3080\n==> Saving...\nTrain: [20][50/313]\t\nTrain: [20][100/313]\t\nTrain: [20][150/313]\t\nTrain: [20][200/313]\t\nTrain: [20][250/313]\t\nTrain: [20][300/313]\t\nEpoch  20, Loss: 0.2818\n==> Saving...\nTrain: [21][50/313]\t\nTrain: [21][100/313]\t\nTrain: [21][150/313]\t\nTrain: [21][200/313]\t\nTrain: [21][250/313]\t\nTrain: [21][300/313]\t\nEpoch  21, Loss: 0.2366\n==> Saving...\nTrain: [22][50/313]\t\nTrain: [22][100/313]\t\nTrain: [22][150/313]\t\nTrain: [22][200/313]\t\nTrain: [22][250/313]\t\nTrain: [22][300/313]\t\nEpoch  22, Loss: 0.1881\n==> Saving...\nTrain: [23][50/313]\t\nTrain: [23][100/313]\t\nTrain: [23][150/313]\t\nTrain: [23][200/313]\t\nTrain: [23][250/313]\t\nTrain: [23][300/313]\t\nEpoch  23, Loss: 0.2183\n==> Saving...\nTrain: [24][50/313]\t\nTrain: [24][100/313]\t\nTrain: [24][150/313]\t\nTrain: [24][200/313]\t\nTrain: [24][250/313]\t\nTrain: [24][300/313]\t\nEpoch  24, Loss: 0.2059\n==> Saving...\nTrain: [25][50/313]\t\nTrain: [25][100/313]\t\nTrain: [25][150/313]\t\nTrain: [25][200/313]\t\nTrain: [25][250/313]\t\nTrain: [25][300/313]\t\nEpoch  25, Loss: 0.2022\n==> Saving...\nTrain: [26][50/313]\t\nTrain: [26][100/313]\t\nTrain: [26][150/313]\t\nTrain: [26][200/313]\t\nTrain: [26][250/313]\t\nTrain: [26][300/313]\t\nEpoch  26, Loss: 0.1787\n==> Saving...\nTrain: [27][50/313]\t\nTrain: [27][100/313]\t\nTrain: [27][150/313]\t\nTrain: [27][200/313]\t\nTrain: [27][250/313]\t\nTrain: [27][300/313]\t\nEpoch  27, Loss: 0.1939\n==> Saving...\nTrain: [28][50/313]\t\nTrain: [28][100/313]\t\nTrain: [28][150/313]\t\nTrain: [28][200/313]\t\nTrain: [28][250/313]\t\nTrain: [28][300/313]\t\nEpoch  28, Loss: 0.2308\n==> Saving...\nTrain: [29][50/313]\t\nTrain: [29][100/313]\t\nTrain: [29][150/313]\t\nTrain: [29][200/313]\t\nTrain: [29][250/313]\t\nTrain: [29][300/313]\t\nEpoch  29, Loss: 0.1936\n==> Saving...\nTrain: [30][50/313]\t\nTrain: [30][100/313]\t\nTrain: [30][150/313]\t\nTrain: [30][200/313]\t\nTrain: [30][250/313]\t\nTrain: [30][300/313]\t\nEpoch  30, Loss: 0.1916\n==> Saving...\nTrain: [31][50/313]\t\nTrain: [31][100/313]\t\nTrain: [31][150/313]\t\nTrain: [31][200/313]\t\nTrain: [31][250/313]\t\nTrain: [31][300/313]\t\nEpoch  31, Loss: 0.1939\n==> Saving...\nTrain: [32][50/313]\t\nTrain: [32][100/313]\t\nTrain: [32][150/313]\t\nTrain: [32][200/313]\t\nTrain: [32][250/313]\t\nTrain: [32][300/313]\t\nEpoch  32, Loss: 0.1811\n==> Saving...\nTrain: [33][50/313]\t\nTrain: [33][100/313]\t\nTrain: [33][150/313]\t\nTrain: [33][200/313]\t\nTrain: [33][250/313]\t\nTrain: [33][300/313]\t\nEpoch  33, Loss: 0.1814\n==> Saving...\nTrain: [34][50/313]\t\nTrain: [34][100/313]\t\nTrain: [34][150/313]\t\nTrain: [34][200/313]\t\nTrain: [34][250/313]\t\nTrain: [34][300/313]\t\nEpoch  34, Loss: 0.1928\n==> Saving...\nTrain: [35][50/313]\t\nTrain: [35][100/313]\t\nTrain: [35][150/313]\t\nTrain: [35][200/313]\t\nTrain: [35][250/313]\t\nTrain: [35][300/313]\t\nEpoch  35, Loss: 0.1614\n==> Saving...\nTrain: [36][50/313]\t\nTrain: [36][100/313]\t\nTrain: [36][150/313]\t\nTrain: [36][200/313]\t\nTrain: [36][250/313]\t\nTrain: [36][300/313]\t\nEpoch  36, Loss: 0.1632\n==> Saving...\nTrain: [37][50/313]\t\nTrain: [37][100/313]\t\nTrain: [37][150/313]\t\nTrain: [37][200/313]\t\nTrain: [37][250/313]\t\nTrain: [37][300/313]\t\nEpoch  37, Loss: 0.1597\n==> Saving...\nTrain: [38][50/313]\t\nTrain: [38][100/313]\t\nTrain: [38][150/313]\t\nTrain: [38][200/313]\t\nTrain: [38][250/313]\t\nTrain: [38][300/313]\t\nEpoch  38, Loss: 0.1875\n==> Saving...\nTrain: [39][50/313]\t\nTrain: [39][100/313]\t\nTrain: [39][150/313]\t\nTrain: [39][200/313]\t\nTrain: [39][250/313]\t\nTrain: [39][300/313]\t\nEpoch  39, Loss: 0.1354\n==> Saving...\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7b0a753d1c00>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"#Net.add_feature()\nmodel, criterion = set_model_st(opt, Net)    \noptimizer = set_optimizer(opt, model)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T10:55:38.891360Z","iopub.execute_input":"2023-08-20T10:55:38.892008Z","iopub.status.idle":"2023-08-20T10:55:38.903708Z","shell.execute_reply.started":"2023-08-20T10:55:38.891965Z","shell.execute_reply":"2023-08-20T10:55:38.902793Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# To check performance without the pre training\nnew_model, new_criterion = set_model(opt)    \nnew_optimizer = set_optimizer(opt, new_model)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T10:55:38.905185Z","iopub.execute_input":"2023-08-20T10:55:38.905664Z","iopub.status.idle":"2023-08-20T10:55:39.325757Z","shell.execute_reply.started":"2023-08-20T10:55:38.905630Z","shell.execute_reply":"2023-08-20T10:55:39.324740Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Modified\n# training routine\nfor epoch in range(1, opt.epochs + 1): \n    train_supervised(train_loader, model, criterion, optimizer, epoch, opt)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T10:55:39.327058Z","iopub.execute_input":"2023-08-20T10:55:39.327432Z","iopub.status.idle":"2023-08-20T12:24:46.690687Z","shell.execute_reply.started":"2023-08-20T10:55:39.327382Z","shell.execute_reply":"2023-08-20T12:24:46.688687Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Train: [1][10/140]\t\nTrain: [1][20/140]\t\nTrain: [1][30/140]\t\nTrain: [1][40/140]\t\nTrain: [1][50/140]\t\nTrain: [1][60/140]\t\nTrain: [1][70/140]\t\nTrain: [1][80/140]\t\nTrain: [1][90/140]\t\nTrain: [1][100/140]\t\nTrain: [1][110/140]\t\nTrain: [1][120/140]\t\nTrain: [1][130/140]\t\nTrain: [1][140/140]\t\nTraining Accuracy: 68.94%\nTrain: [2][10/140]\t\nTrain: [2][20/140]\t\nTrain: [2][30/140]\t\nTrain: [2][40/140]\t\nTrain: [2][50/140]\t\nTrain: [2][60/140]\t\nTrain: [2][70/140]\t\nTrain: [2][80/140]\t\nTrain: [2][90/140]\t\nTrain: [2][100/140]\t\nTrain: [2][110/140]\t\nTrain: [2][120/140]\t\nTrain: [2][130/140]\t\nTrain: [2][140/140]\t\nTraining Accuracy: 75.29%\nTrain: [3][10/140]\t\nTrain: [3][20/140]\t\nTrain: [3][30/140]\t\nTrain: [3][40/140]\t\nTrain: [3][50/140]\t\nTrain: [3][60/140]\t\nTrain: [3][70/140]\t\nTrain: [3][80/140]\t\nTrain: [3][90/140]\t\nTrain: [3][100/140]\t\nTrain: [3][110/140]\t\nTrain: [3][120/140]\t\nTrain: [3][130/140]\t\nTrain: [3][140/140]\t\nTraining Accuracy: 77.80%\nTrain: [4][10/140]\t\nTrain: [4][20/140]\t\nTrain: [4][30/140]\t\nTrain: [4][40/140]\t\nTrain: [4][50/140]\t\nTrain: [4][60/140]\t\nTrain: [4][70/140]\t\nTrain: [4][80/140]\t\nTrain: [4][90/140]\t\nTrain: [4][100/140]\t\nTrain: [4][110/140]\t\nTrain: [4][120/140]\t\nTrain: [4][130/140]\t\nTrain: [4][140/140]\t\nTraining Accuracy: 79.09%\nTrain: [5][10/140]\t\nTrain: [5][20/140]\t\nTrain: [5][30/140]\t\nTrain: [5][40/140]\t\nTrain: [5][50/140]\t\nTrain: [5][60/140]\t\nTrain: [5][70/140]\t\nTrain: [5][80/140]\t\nTrain: [5][90/140]\t\nTrain: [5][100/140]\t\nTrain: [5][110/140]\t\nTrain: [5][120/140]\t\nTrain: [5][130/140]\t\nTrain: [5][140/140]\t\nTraining Accuracy: 80.36%\nTrain: [6][10/140]\t\nTrain: [6][20/140]\t\nTrain: [6][30/140]\t\nTrain: [6][40/140]\t\nTrain: [6][50/140]\t\nTrain: [6][60/140]\t\nTrain: [6][70/140]\t\nTrain: [6][80/140]\t\nTrain: [6][90/140]\t\nTrain: [6][100/140]\t\nTrain: [6][110/140]\t\nTrain: [6][120/140]\t\nTrain: [6][130/140]\t\nTrain: [6][140/140]\t\nTraining Accuracy: 81.36%\nTrain: [7][10/140]\t\nTrain: [7][20/140]\t\nTrain: [7][30/140]\t\nTrain: [7][40/140]\t\nTrain: [7][50/140]\t\nTrain: [7][60/140]\t\nTrain: [7][70/140]\t\nTrain: [7][80/140]\t\nTrain: [7][90/140]\t\nTrain: [7][100/140]\t\nTrain: [7][110/140]\t\nTrain: [7][120/140]\t\nTrain: [7][130/140]\t\nTrain: [7][140/140]\t\nTraining Accuracy: 82.09%\nTrain: [8][10/140]\t\nTrain: [8][20/140]\t\nTrain: [8][30/140]\t\nTrain: [8][40/140]\t\nTrain: [8][50/140]\t\nTrain: [8][60/140]\t\nTrain: [8][70/140]\t\nTrain: [8][80/140]\t\nTrain: [8][90/140]\t\nTrain: [8][100/140]\t\nTrain: [8][110/140]\t\nTrain: [8][120/140]\t\nTrain: [8][130/140]\t\nTrain: [8][140/140]\t\nTraining Accuracy: 82.55%\nTrain: [9][10/140]\t\nTrain: [9][20/140]\t\nTrain: [9][30/140]\t\nTrain: [9][40/140]\t\nTrain: [9][50/140]\t\nTrain: [9][60/140]\t\nTrain: [9][70/140]\t\nTrain: [9][80/140]\t\nTrain: [9][90/140]\t\nTrain: [9][100/140]\t\nTrain: [9][110/140]\t\nTrain: [9][120/140]\t\nTrain: [9][130/140]\t\nTrain: [9][140/140]\t\nTraining Accuracy: 83.14%\nTrain: [10][10/140]\t\nTrain: [10][20/140]\t\nTrain: [10][30/140]\t\nTrain: [10][40/140]\t\nTrain: [10][50/140]\t\nTrain: [10][60/140]\t\nTrain: [10][70/140]\t\nTrain: [10][80/140]\t\nTrain: [10][90/140]\t\nTrain: [10][100/140]\t\nTrain: [10][110/140]\t\nTrain: [10][120/140]\t\nTrain: [10][130/140]\t\nTrain: [10][140/140]\t\nTraining Accuracy: 83.54%\nTrain: [11][10/140]\t\nTrain: [11][20/140]\t\nTrain: [11][30/140]\t\nTrain: [11][40/140]\t\nTrain: [11][50/140]\t\nTrain: [11][60/140]\t\nTrain: [11][70/140]\t\nTrain: [11][80/140]\t\nTrain: [11][90/140]\t\nTrain: [11][100/140]\t\nTrain: [11][110/140]\t\nTrain: [11][120/140]\t\nTrain: [11][130/140]\t\nTrain: [11][140/140]\t\nTraining Accuracy: 84.10%\nTrain: [12][10/140]\t\nTrain: [12][20/140]\t\nTrain: [12][30/140]\t\nTrain: [12][40/140]\t\nTrain: [12][50/140]\t\nTrain: [12][60/140]\t\nTrain: [12][70/140]\t\nTrain: [12][80/140]\t\nTrain: [12][90/140]\t\nTrain: [12][100/140]\t\nTrain: [12][110/140]\t\nTrain: [12][120/140]\t\nTrain: [12][130/140]\t\nTrain: [12][140/140]\t\nTraining Accuracy: 84.16%\nTrain: [13][10/140]\t\nTrain: [13][20/140]\t\nTrain: [13][30/140]\t\nTrain: [13][40/140]\t\nTrain: [13][50/140]\t\nTrain: [13][60/140]\t\nTrain: [13][70/140]\t\nTrain: [13][80/140]\t\nTrain: [13][90/140]\t\nTrain: [13][100/140]\t\nTrain: [13][110/140]\t\nTrain: [13][120/140]\t\nTrain: [13][130/140]\t\nTrain: [13][140/140]\t\nTraining Accuracy: 84.32%\nTrain: [14][10/140]\t\nTrain: [14][20/140]\t\nTrain: [14][30/140]\t\nTrain: [14][40/140]\t\nTrain: [14][50/140]\t\nTrain: [14][60/140]\t\nTrain: [14][70/140]\t\nTrain: [14][80/140]\t\nTrain: [14][90/140]\t\nTrain: [14][100/140]\t\nTrain: [14][110/140]\t\nTrain: [14][120/140]\t\nTrain: [14][130/140]\t\nTrain: [14][140/140]\t\nTraining Accuracy: 84.76%\nTrain: [15][10/140]\t\nTrain: [15][20/140]\t\nTrain: [15][30/140]\t\nTrain: [15][40/140]\t\nTrain: [15][50/140]\t\nTrain: [15][60/140]\t\nTrain: [15][70/140]\t\nTrain: [15][80/140]\t\nTrain: [15][90/140]\t\nTrain: [15][100/140]\t\nTrain: [15][110/140]\t\nTrain: [15][120/140]\t\nTrain: [15][130/140]\t\nTrain: [15][140/140]\t\nTraining Accuracy: 85.06%\nTrain: [16][10/140]\t\nTrain: [16][20/140]\t\nTrain: [16][30/140]\t\nTrain: [16][40/140]\t\nTrain: [16][50/140]\t\nTrain: [16][60/140]\t\nTrain: [16][70/140]\t\nTrain: [16][80/140]\t\nTrain: [16][90/140]\t\nTrain: [16][100/140]\t\nTrain: [16][110/140]\t\nTrain: [16][120/140]\t\nTrain: [16][130/140]\t\nTrain: [16][140/140]\t\nTraining Accuracy: 85.19%\nTrain: [17][10/140]\t\nTrain: [17][20/140]\t\nTrain: [17][30/140]\t\nTrain: [17][40/140]\t\nTrain: [17][50/140]\t\nTrain: [17][60/140]\t\nTrain: [17][70/140]\t\nTrain: [17][80/140]\t\nTrain: [17][90/140]\t\nTrain: [17][100/140]\t\nTrain: [17][110/140]\t\nTrain: [17][120/140]\t\nTrain: [17][130/140]\t\nTrain: [17][140/140]\t\nTraining Accuracy: 85.49%\nTrain: [18][10/140]\t\nTrain: [18][20/140]\t\nTrain: [18][30/140]\t\nTrain: [18][40/140]\t\nTrain: [18][50/140]\t\nTrain: [18][60/140]\t\nTrain: [18][70/140]\t\nTrain: [18][80/140]\t\nTrain: [18][90/140]\t\nTrain: [18][100/140]\t\nTrain: [18][110/140]\t\nTrain: [18][120/140]\t\nTrain: [18][130/140]\t\nTrain: [18][140/140]\t\nTraining Accuracy: 85.34%\nTrain: [19][10/140]\t\nTrain: [19][20/140]\t\nTrain: [19][30/140]\t\nTrain: [19][40/140]\t\nTrain: [19][50/140]\t\nTrain: [19][60/140]\t\nTrain: [19][70/140]\t\nTrain: [19][80/140]\t\nTrain: [19][90/140]\t\nTrain: [19][100/140]\t\nTrain: [19][110/140]\t\nTrain: [19][120/140]\t\nTrain: [19][130/140]\t\nTrain: [19][140/140]\t\nTraining Accuracy: 85.57%\nTrain: [20][10/140]\t\nTrain: [20][20/140]\t\nTrain: [20][30/140]\t\nTrain: [20][40/140]\t\nTrain: [20][50/140]\t\nTrain: [20][60/140]\t\nTrain: [20][70/140]\t\nTrain: [20][80/140]\t\nTrain: [20][90/140]\t\nTrain: [20][100/140]\t\nTrain: [20][110/140]\t\nTrain: [20][120/140]\t\nTrain: [20][130/140]\t\nTrain: [20][140/140]\t\nTraining Accuracy: 85.93%\nTrain: [21][10/140]\t\nTrain: [21][20/140]\t\nTrain: [21][30/140]\t\nTrain: [21][40/140]\t\nTrain: [21][50/140]\t\nTrain: [21][60/140]\t\nTrain: [21][70/140]\t\nTrain: [21][80/140]\t\nTrain: [21][90/140]\t\nTrain: [21][100/140]\t\nTrain: [21][110/140]\t\nTrain: [21][120/140]\t\nTrain: [21][130/140]\t\nTrain: [21][140/140]\t\nTraining Accuracy: 85.98%\nTrain: [22][10/140]\t\nTrain: [22][20/140]\t\nTrain: [22][30/140]\t\nTrain: [22][40/140]\t\nTrain: [22][50/140]\t\nTrain: [22][60/140]\t\nTrain: [22][70/140]\t\nTrain: [22][80/140]\t\nTrain: [22][90/140]\t\nTrain: [22][100/140]\t\nTrain: [22][110/140]\t\nTrain: [22][120/140]\t\nTrain: [22][130/140]\t\nTrain: [22][140/140]\t\nTraining Accuracy: 86.38%\nTrain: [23][10/140]\t\nTrain: [23][20/140]\t\nTrain: [23][30/140]\t\nTrain: [23][40/140]\t\nTrain: [23][50/140]\t\nTrain: [23][60/140]\t\nTrain: [23][70/140]\t\nTrain: [23][80/140]\t\nTrain: [23][90/140]\t\nTrain: [23][100/140]\t\nTrain: [23][110/140]\t\nTrain: [23][120/140]\t\nTrain: [23][130/140]\t\nTrain: [23][140/140]\t\nTraining Accuracy: 86.60%\nTrain: [24][10/140]\t\nTrain: [24][20/140]\t\nTrain: [24][30/140]\t\nTrain: [24][40/140]\t\nTrain: [24][50/140]\t\nTrain: [24][60/140]\t\nTrain: [24][70/140]\t\nTrain: [24][80/140]\t\nTrain: [24][90/140]\t\nTrain: [24][100/140]\t\nTrain: [24][110/140]\t\nTrain: [24][120/140]\t\nTrain: [24][130/140]\t\nTrain: [24][140/140]\t\nTraining Accuracy: 86.67%\nTrain: [25][10/140]\t\nTrain: [25][20/140]\t\nTrain: [25][30/140]\t\nTrain: [25][40/140]\t\nTrain: [25][50/140]\t\nTrain: [25][60/140]\t\nTrain: [25][70/140]\t\nTrain: [25][80/140]\t\nTrain: [25][90/140]\t\nTrain: [25][100/140]\t\nTrain: [25][110/140]\t\nTrain: [25][120/140]\t\nTrain: [25][130/140]\t\nTrain: [25][140/140]\t\nTraining Accuracy: 86.86%\nTrain: [26][10/140]\t\nTrain: [26][20/140]\t\nTrain: [26][30/140]\t\nTrain: [26][40/140]\t\nTrain: [26][50/140]\t\nTrain: [26][60/140]\t\nTrain: [26][70/140]\t\nTrain: [26][80/140]\t\nTrain: [26][90/140]\t\nTrain: [26][100/140]\t\nTrain: [26][110/140]\t\nTrain: [26][120/140]\t\nTrain: [26][130/140]\t\nTrain: [26][140/140]\t\nTraining Accuracy: 86.89%\nTrain: [27][10/140]\t\nTrain: [27][20/140]\t\nTrain: [27][30/140]\t\nTrain: [27][40/140]\t\nTrain: [27][50/140]\t\nTrain: [27][60/140]\t\nTrain: [27][70/140]\t\nTrain: [27][80/140]\t\nTrain: [27][90/140]\t\nTrain: [27][100/140]\t\nTrain: [27][110/140]\t\nTrain: [27][120/140]\t\nTrain: [27][130/140]\t\nTrain: [27][140/140]\t\nTraining Accuracy: 86.94%\nTrain: [28][10/140]\t\nTrain: [28][20/140]\t\nTrain: [28][30/140]\t\nTrain: [28][40/140]\t\nTrain: [28][50/140]\t\nTrain: [28][60/140]\t\nTrain: [28][70/140]\t\nTrain: [28][80/140]\t\nTrain: [28][90/140]\t\nTrain: [28][100/140]\t\nTrain: [28][110/140]\t\nTrain: [28][120/140]\t\nTrain: [28][130/140]\t\nTrain: [28][140/140]\t\nTraining Accuracy: 87.07%\nTrain: [29][10/140]\t\nTrain: [29][20/140]\t\nTrain: [29][30/140]\t\nTrain: [29][40/140]\t\nTrain: [29][50/140]\t\nTrain: [29][60/140]\t\nTrain: [29][70/140]\t\nTrain: [29][80/140]\t\nTrain: [29][90/140]\t\nTrain: [29][100/140]\t\nTrain: [29][110/140]\t\nTrain: [29][120/140]\t\nTrain: [29][130/140]\t\nTrain: [29][140/140]\t\nTraining Accuracy: 87.07%\nTrain: [30][10/140]\t\nTrain: [30][20/140]\t\nTrain: [30][30/140]\t\nTrain: [30][40/140]\t\nTrain: [30][50/140]\t\nTrain: [30][60/140]\t\nTrain: [30][70/140]\t\nTrain: [30][80/140]\t\nTrain: [30][90/140]\t\nTrain: [30][100/140]\t\nTrain: [30][110/140]\t\nTrain: [30][120/140]\t\nTrain: [30][130/140]\t\nTrain: [30][140/140]\t\nTraining Accuracy: 87.22%\nTrain: [31][10/140]\t\nTrain: [31][20/140]\t\nTrain: [31][30/140]\t\nTrain: [31][40/140]\t\nTrain: [31][50/140]\t\nTrain: [31][60/140]\t\nTrain: [31][70/140]\t\nTrain: [31][80/140]\t\nTrain: [31][90/140]\t\nTrain: [31][100/140]\t\nTrain: [31][110/140]\t\nTrain: [31][120/140]\t\nTrain: [31][130/140]\t\nTrain: [31][140/140]\t\nTraining Accuracy: 87.43%\nTrain: [32][10/140]\t\nTrain: [32][20/140]\t\nTrain: [32][30/140]\t\nTrain: [32][40/140]\t\nTrain: [32][50/140]\t\nTrain: [32][60/140]\t\nTrain: [32][70/140]\t\nTrain: [32][80/140]\t\nTrain: [32][90/140]\t\nTrain: [32][100/140]\t\nTrain: [32][110/140]\t\nTrain: [32][120/140]\t\nTrain: [32][130/140]\t\nTrain: [32][140/140]\t\nTraining Accuracy: 87.48%\nTrain: [33][10/140]\t\nTrain: [33][20/140]\t\nTrain: [33][30/140]\t\nTrain: [33][40/140]\t\nTrain: [33][50/140]\t\nTrain: [33][60/140]\t\nTrain: [33][70/140]\t\nTrain: [33][80/140]\t\nTrain: [33][90/140]\t\nTrain: [33][100/140]\t\nTrain: [33][110/140]\t\nTrain: [33][120/140]\t\nTrain: [33][130/140]\t\nTrain: [33][140/140]\t\nTraining Accuracy: 87.78%\nTrain: [34][10/140]\t\nTrain: [34][20/140]\t\nTrain: [34][30/140]\t\nTrain: [34][40/140]\t\nTrain: [34][50/140]\t\nTrain: [34][60/140]\t\nTrain: [34][70/140]\t\nTrain: [34][80/140]\t\nTrain: [34][90/140]\t\nTrain: [34][100/140]\t\nTrain: [34][110/140]\t\nTrain: [34][120/140]\t\nTrain: [34][130/140]\t\nTrain: [34][140/140]\t\nTraining Accuracy: 87.62%\nTrain: [35][10/140]\t\nTrain: [35][20/140]\t\nTrain: [35][30/140]\t\nTrain: [35][40/140]\t\nTrain: [35][50/140]\t\nTrain: [35][60/140]\t\nTrain: [35][70/140]\t\nTrain: [35][80/140]\t\nTrain: [35][90/140]\t\nTrain: [35][100/140]\t\nTrain: [35][110/140]\t\nTrain: [35][120/140]\t\nTrain: [35][130/140]\t\nTrain: [35][140/140]\t\nTraining Accuracy: 87.70%\nTrain: [36][10/140]\t\nTrain: [36][20/140]\t\nTrain: [36][30/140]\t\nTrain: [36][40/140]\t\nTrain: [36][50/140]\t\nTrain: [36][60/140]\t\nTrain: [36][70/140]\t\nTrain: [36][80/140]\t\nTrain: [36][90/140]\t\nTrain: [36][100/140]\t\nTrain: [36][110/140]\t\nTrain: [36][120/140]\t\nTrain: [36][130/140]\t\nTrain: [36][140/140]\t\nTraining Accuracy: 87.88%\nTrain: [37][10/140]\t\nTrain: [37][20/140]\t\nTrain: [37][30/140]\t\nTrain: [37][40/140]\t\nTrain: [37][50/140]\t\nTrain: [37][60/140]\t\nTrain: [37][70/140]\t\nTrain: [37][80/140]\t\nTrain: [37][90/140]\t\nTrain: [37][100/140]\t\nTrain: [37][110/140]\t\nTrain: [37][120/140]\t\nTrain: [37][130/140]\t\nTrain: [37][140/140]\t\nTraining Accuracy: 87.81%\nTrain: [38][10/140]\t\nTrain: [38][20/140]\t\nTrain: [38][30/140]\t\nTrain: [38][40/140]\t\nTrain: [38][50/140]\t\nTrain: [38][60/140]\t\nTrain: [38][70/140]\t\nTrain: [38][80/140]\t\nTrain: [38][90/140]\t\nTrain: [38][100/140]\t\nTrain: [38][110/140]\t\nTrain: [38][120/140]\t\nTrain: [38][130/140]\t\nTrain: [38][140/140]\t\nTraining Accuracy: 87.95%\nTrain: [39][10/140]\t\nTrain: [39][20/140]\t\nTrain: [39][30/140]\t\nTrain: [39][40/140]\t\nTrain: [39][50/140]\t\nTrain: [39][60/140]\t\nTrain: [39][70/140]\t\nTrain: [39][80/140]\t\nTrain: [39][90/140]\t\nTrain: [39][100/140]\t\nTrain: [39][110/140]\t\nTrain: [39][120/140]\t\nTrain: [39][130/140]\t\nTrain: [39][140/140]\t\nTraining Accuracy: 88.40%\nTrain: [40][10/140]\t\nTrain: [40][20/140]\t\nTrain: [40][30/140]\t\nTrain: [40][40/140]\t\nTrain: [40][50/140]\t\nTrain: [40][60/140]\t\nTrain: [40][70/140]\t\nTrain: [40][80/140]\t\nTrain: [40][90/140]\t\nTrain: [40][100/140]\t\nTrain: [40][110/140]\t\nTrain: [40][120/140]\t\nTrain: [40][130/140]\t\nTrain: [40][140/140]\t\nTraining Accuracy: 88.29%\nTrain: [41][10/140]\t\nTrain: [41][20/140]\t\nTrain: [41][30/140]\t\nTrain: [41][40/140]\t\nTrain: [41][50/140]\t\nTrain: [41][60/140]\t\nTrain: [41][70/140]\t\nTrain: [41][80/140]\t\nTrain: [41][90/140]\t\nTrain: [41][100/140]\t\nTrain: [41][110/140]\t\nTrain: [41][120/140]\t\nTrain: [41][130/140]\t\nTrain: [41][140/140]\t\nTraining Accuracy: 88.61%\nTrain: [42][10/140]\t\nTrain: [42][20/140]\t\nTrain: [42][30/140]\t\nTrain: [42][40/140]\t\nTrain: [42][50/140]\t\nTrain: [42][60/140]\t\nTrain: [42][70/140]\t\nTrain: [42][80/140]\t\nTrain: [42][90/140]\t\nTrain: [42][100/140]\t\nTrain: [42][110/140]\t\nTrain: [42][120/140]\t\nTrain: [42][130/140]\t\nTrain: [42][140/140]\t\nTraining Accuracy: 88.39%\nTrain: [43][10/140]\t\nTrain: [43][20/140]\t\nTrain: [43][30/140]\t\nTrain: [43][40/140]\t\nTrain: [43][50/140]\t\nTrain: [43][60/140]\t\nTrain: [43][70/140]\t\nTrain: [43][80/140]\t\nTrain: [43][90/140]\t\nTrain: [43][100/140]\t\nTrain: [43][110/140]\t\nTrain: [43][120/140]\t\nTrain: [43][130/140]\t\nTrain: [43][140/140]\t\nTraining Accuracy: 88.46%\nTrain: [44][10/140]\t\nTrain: [44][20/140]\t\nTrain: [44][30/140]\t\nTrain: [44][40/140]\t\nTrain: [44][50/140]\t\nTrain: [44][60/140]\t\nTrain: [44][70/140]\t\nTrain: [44][80/140]\t\nTrain: [44][90/140]\t\nTrain: [44][100/140]\t\nTrain: [44][110/140]\t\nTrain: [44][120/140]\t\nTrain: [44][130/140]\t\nTrain: [44][140/140]\t\nTraining Accuracy: 88.93%\nTrain: [45][10/140]\t\nTrain: [45][20/140]\t\nTrain: [45][30/140]\t\nTrain: [45][40/140]\t\nTrain: [45][50/140]\t\nTrain: [45][60/140]\t\nTrain: [45][70/140]\t\nTrain: [45][80/140]\t\nTrain: [45][90/140]\t\nTrain: [45][100/140]\t\nTrain: [45][110/140]\t\nTrain: [45][120/140]\t\nTrain: [45][130/140]\t\nTrain: [45][140/140]\t\nTraining Accuracy: 88.65%\nTrain: [46][10/140]\t\nTrain: [46][20/140]\t\nTrain: [46][30/140]\t\nTrain: [46][40/140]\t\nTrain: [46][50/140]\t\nTrain: [46][60/140]\t\nTrain: [46][70/140]\t\nTrain: [46][80/140]\t\nTrain: [46][90/140]\t\nTrain: [46][100/140]\t\nTrain: [46][110/140]\t\nTrain: [46][120/140]\t\nTrain: [46][130/140]\t\nTrain: [46][140/140]\t\nTraining Accuracy: 88.52%\nTrain: [47][10/140]\t\nTrain: [47][20/140]\t\nTrain: [47][30/140]\t\nTrain: [47][40/140]\t\nTrain: [47][50/140]\t\nTrain: [47][60/140]\t\nTrain: [47][70/140]\t\nTrain: [47][80/140]\t\nTrain: [47][90/140]\t\nTrain: [47][100/140]\t\nTrain: [47][110/140]\t\nTrain: [47][120/140]\t\nTrain: [47][130/140]\t\nTrain: [47][140/140]\t\nTraining Accuracy: 88.69%\nTrain: [48][10/140]\t\nTrain: [48][20/140]\t\nTrain: [48][30/140]\t\nTrain: [48][40/140]\t\nTrain: [48][50/140]\t\nTrain: [48][60/140]\t\nTrain: [48][70/140]\t\nTrain: [48][80/140]\t\nTrain: [48][90/140]\t\nTrain: [48][100/140]\t\nTrain: [48][110/140]\t\nTrain: [48][120/140]\t\nTrain: [48][130/140]\t\nTrain: [48][140/140]\t\nTraining Accuracy: 88.65%\nTrain: [49][10/140]\t\nTrain: [49][20/140]\t\nTrain: [49][30/140]\t\nTrain: [49][40/140]\t\nTrain: [49][50/140]\t\nTrain: [49][60/140]\t\nTrain: [49][70/140]\t\nTrain: [49][80/140]\t\nTrain: [49][90/140]\t\nTrain: [49][100/140]\t\nTrain: [49][110/140]\t\nTrain: [49][120/140]\t\nTrain: [49][130/140]\t\nTrain: [49][140/140]\t\nTraining Accuracy: 88.85%\nTrain: [50][10/140]\t\nTrain: [50][20/140]\t\nTrain: [50][30/140]\t\nTrain: [50][40/140]\t\nTrain: [50][50/140]\t\nTrain: [50][60/140]\t\nTrain: [50][70/140]\t\nTrain: [50][80/140]\t\nTrain: [50][90/140]\t\nTrain: [50][100/140]\t\nTrain: [50][110/140]\t\nTrain: [50][120/140]\t\nTrain: [50][130/140]\t\nTrain: [50][140/140]\t\nTraining Accuracy: 88.80%\nTrain: [51][10/140]\t\nTrain: [51][20/140]\t\nTrain: [51][30/140]\t\nTrain: [51][40/140]\t\nTrain: [51][50/140]\t\nTrain: [51][60/140]\t\nTrain: [51][70/140]\t\nTrain: [51][80/140]\t\nTrain: [51][90/140]\t\nTrain: [51][100/140]\t\nTrain: [51][110/140]\t\nTrain: [51][120/140]\t\nTrain: [51][130/140]\t\nTrain: [51][140/140]\t\nTraining Accuracy: 89.01%\nTrain: [52][10/140]\t\nTrain: [52][20/140]\t\nTrain: [52][30/140]\t\nTrain: [52][40/140]\t\nTrain: [52][50/140]\t\nTrain: [52][60/140]\t\nTrain: [52][70/140]\t\nTrain: [52][80/140]\t\nTrain: [52][90/140]\t\nTrain: [52][100/140]\t\nTrain: [52][110/140]\t\nTrain: [52][120/140]\t\nTrain: [52][130/140]\t\nTrain: [52][140/140]\t\nTraining Accuracy: 89.18%\nTrain: [53][10/140]\t\nTrain: [53][20/140]\t\nTrain: [53][30/140]\t\nTrain: [53][40/140]\t\nTrain: [53][50/140]\t\nTrain: [53][60/140]\t\nTrain: [53][70/140]\t\nTrain: [53][80/140]\t\nTrain: [53][90/140]\t\nTrain: [53][100/140]\t\nTrain: [53][110/140]\t\nTrain: [53][120/140]\t\nTrain: [53][130/140]\t\nTrain: [53][140/140]\t\nTraining Accuracy: 89.28%\nTrain: [54][10/140]\t\nTrain: [54][20/140]\t\nTrain: [54][30/140]\t\nTrain: [54][40/140]\t\nTrain: [54][50/140]\t\nTrain: [54][60/140]\t\nTrain: [54][70/140]\t\nTrain: [54][80/140]\t\nTrain: [54][90/140]\t\nTrain: [54][100/140]\t\nTrain: [54][110/140]\t\nTrain: [54][120/140]\t\nTrain: [54][130/140]\t\nTrain: [54][140/140]\t\nTraining Accuracy: 89.27%\nTrain: [55][10/140]\t\nTrain: [55][20/140]\t\nTrain: [55][30/140]\t\nTrain: [55][40/140]\t\nTrain: [55][50/140]\t\nTrain: [55][60/140]\t\nTrain: [55][70/140]\t\nTrain: [55][80/140]\t\nTrain: [55][90/140]\t\nTrain: [55][100/140]\t\nTrain: [55][110/140]\t\nTrain: [55][120/140]\t\nTrain: [55][130/140]\t\nTrain: [55][140/140]\t\nTraining Accuracy: 89.35%\nTrain: [56][10/140]\t\nTrain: [56][20/140]\t\nTrain: [56][30/140]\t\nTrain: [56][40/140]\t\nTrain: [56][50/140]\t\nTrain: [56][60/140]\t\nTrain: [56][70/140]\t\nTrain: [56][80/140]\t\nTrain: [56][90/140]\t\nTrain: [56][100/140]\t\nTrain: [56][110/140]\t\nTrain: [56][120/140]\t\nTrain: [56][130/140]\t\nTrain: [56][140/140]\t\nTraining Accuracy: 89.27%\nTrain: [57][10/140]\t\nTrain: [57][20/140]\t\nTrain: [57][30/140]\t\nTrain: [57][40/140]\t\nTrain: [57][50/140]\t\nTrain: [57][60/140]\t\nTrain: [57][70/140]\t\nTrain: [57][80/140]\t\nTrain: [57][90/140]\t\nTrain: [57][100/140]\t\nTrain: [57][110/140]\t\nTrain: [57][120/140]\t\nTrain: [57][130/140]\t\nTrain: [57][140/140]\t\nTraining Accuracy: 89.43%\nTrain: [58][10/140]\t\nTrain: [58][20/140]\t\nTrain: [58][30/140]\t\nTrain: [58][40/140]\t\nTrain: [58][50/140]\t\nTrain: [58][60/140]\t\nTrain: [58][70/140]\t\nTrain: [58][80/140]\t\nTrain: [58][90/140]\t\nTrain: [58][100/140]\t\nTrain: [58][110/140]\t\nTrain: [58][120/140]\t\nTrain: [58][130/140]\t\nTrain: [58][140/140]\t\nTraining Accuracy: 89.55%\nTrain: [59][10/140]\t\nTrain: [59][20/140]\t\nTrain: [59][30/140]\t\nTrain: [59][40/140]\t\nTrain: [59][50/140]\t\nTrain: [59][60/140]\t\nTrain: [59][70/140]\t\nTrain: [59][80/140]\t\nTrain: [59][90/140]\t\nTrain: [59][100/140]\t\nTrain: [59][110/140]\t\nTrain: [59][120/140]\t\nTrain: [59][130/140]\t\nTrain: [59][140/140]\t\nTraining Accuracy: 89.72%\nTrain: [60][10/140]\t\nTrain: [60][20/140]\t\nTrain: [60][30/140]\t\nTrain: [60][40/140]\t\nTrain: [60][50/140]\t\nTrain: [60][60/140]\t\nTrain: [60][70/140]\t\nTrain: [60][80/140]\t\nTrain: [60][90/140]\t\nTrain: [60][100/140]\t\nTrain: [60][110/140]\t\nTrain: [60][120/140]\t\nTrain: [60][130/140]\t\nTrain: [60][140/140]\t\nTraining Accuracy: 89.55%\nTrain: [61][10/140]\t\nTrain: [61][20/140]\t\nTrain: [61][30/140]\t\nTrain: [61][40/140]\t\nTrain: [61][50/140]\t\nTrain: [61][60/140]\t\nTrain: [61][70/140]\t\nTrain: [61][80/140]\t\nTrain: [61][90/140]\t\nTrain: [61][100/140]\t\nTrain: [61][110/140]\t\nTrain: [61][120/140]\t\nTrain: [61][130/140]\t\nTrain: [61][140/140]\t\nTraining Accuracy: 89.82%\nTrain: [62][10/140]\t\nTrain: [62][20/140]\t\nTrain: [62][30/140]\t\nTrain: [62][40/140]\t\nTrain: [62][50/140]\t\nTrain: [62][60/140]\t\nTrain: [62][70/140]\t\nTrain: [62][80/140]\t\nTrain: [62][90/140]\t\nTrain: [62][100/140]\t\nTrain: [62][110/140]\t\nTrain: [62][120/140]\t\nTrain: [62][130/140]\t\nTrain: [62][140/140]\t\nTraining Accuracy: 89.92%\nTrain: [63][10/140]\t\nTrain: [63][20/140]\t\nTrain: [63][30/140]\t\nTrain: [63][40/140]\t\nTrain: [63][50/140]\t\nTrain: [63][60/140]\t\nTrain: [63][70/140]\t\nTrain: [63][80/140]\t\nTrain: [63][90/140]\t\nTrain: [63][100/140]\t\nTrain: [63][110/140]\t\nTrain: [63][120/140]\t\nTrain: [63][130/140]\t\nTrain: [63][140/140]\t\nTraining Accuracy: 89.87%\nTrain: [64][10/140]\t\nTrain: [64][20/140]\t\nTrain: [64][30/140]\t\nTrain: [64][40/140]\t\nTrain: [64][50/140]\t\nTrain: [64][60/140]\t\nTrain: [64][70/140]\t\nTrain: [64][80/140]\t\nTrain: [64][90/140]\t\nTrain: [64][100/140]\t\nTrain: [64][110/140]\t\nTrain: [64][120/140]\t\nTrain: [64][130/140]\t\nTrain: [64][140/140]\t\nTraining Accuracy: 89.81%\nTrain: [65][10/140]\t\nTrain: [65][20/140]\t\nTrain: [65][30/140]\t\nTrain: [65][40/140]\t\nTrain: [65][50/140]\t\nTrain: [65][60/140]\t\nTrain: [65][70/140]\t\nTrain: [65][80/140]\t\nTrain: [65][90/140]\t\nTrain: [65][100/140]\t\nTrain: [65][110/140]\t\nTrain: [65][120/140]\t\nTrain: [65][130/140]\t\nTrain: [65][140/140]\t\nTraining Accuracy: 89.82%\nTrain: [66][10/140]\t\nTrain: [66][20/140]\t\nTrain: [66][30/140]\t\nTrain: [66][40/140]\t\nTrain: [66][50/140]\t\nTrain: [66][60/140]\t\nTrain: [66][70/140]\t\nTrain: [66][80/140]\t\nTrain: [66][90/140]\t\nTrain: [66][100/140]\t\nTrain: [66][110/140]\t\nTrain: [66][120/140]\t\nTrain: [66][130/140]\t\nTrain: [66][140/140]\t\nTraining Accuracy: 89.95%\nTrain: [67][10/140]\t\nTrain: [67][20/140]\t\nTrain: [67][30/140]\t\nTrain: [67][40/140]\t\nTrain: [67][50/140]\t\nTrain: [67][60/140]\t\nTrain: [67][70/140]\t\nTrain: [67][80/140]\t\nTrain: [67][90/140]\t\nTrain: [67][100/140]\t\nTrain: [67][110/140]\t\nTrain: [67][120/140]\t\nTrain: [67][130/140]\t\nTrain: [67][140/140]\t\nTraining Accuracy: 90.04%\nTrain: [68][10/140]\t\nTrain: [68][20/140]\t\nTrain: [68][30/140]\t\nTrain: [68][40/140]\t\nTrain: [68][50/140]\t\nTrain: [68][60/140]\t\nTrain: [68][70/140]\t\nTrain: [68][80/140]\t\nTrain: [68][90/140]\t\nTrain: [68][100/140]\t\nTrain: [68][110/140]\t\nTrain: [68][120/140]\t\nTrain: [68][130/140]\t\nTrain: [68][140/140]\t\nTraining Accuracy: 90.32%\nTrain: [69][10/140]\t\nTrain: [69][20/140]\t\nTrain: [69][30/140]\t\nTrain: [69][40/140]\t\nTrain: [69][50/140]\t\nTrain: [69][60/140]\t\nTrain: [69][70/140]\t\nTrain: [69][80/140]\t\nTrain: [69][90/140]\t\nTrain: [69][100/140]\t\nTrain: [69][110/140]\t\nTrain: [69][120/140]\t\nTrain: [69][130/140]\t\nTrain: [69][140/140]\t\nTraining Accuracy: 90.00%\nTrain: [70][10/140]\t\nTrain: [70][20/140]\t\nTrain: [70][30/140]\t\nTrain: [70][40/140]\t\nTrain: [70][50/140]\t\nTrain: [70][60/140]\t\nTrain: [70][70/140]\t\nTrain: [70][80/140]\t\nTrain: [70][90/140]\t\nTrain: [70][100/140]\t\nTrain: [70][110/140]\t\nTrain: [70][120/140]\t\nTrain: [70][130/140]\t\nTrain: [70][140/140]\t\nTraining Accuracy: 90.26%\nTrain: [71][10/140]\t\nTrain: [71][20/140]\t\nTrain: [71][30/140]\t\nTrain: [71][40/140]\t\nTrain: [71][50/140]\t\nTrain: [71][60/140]\t\nTrain: [71][70/140]\t\nTrain: [71][80/140]\t\nTrain: [71][90/140]\t\nTrain: [71][100/140]\t\nTrain: [71][110/140]\t\nTrain: [71][120/140]\t\nTrain: [71][130/140]\t\nTrain: [71][140/140]\t\nTraining Accuracy: 90.30%\nTrain: [72][10/140]\t\nTrain: [72][20/140]\t\nTrain: [72][30/140]\t\nTrain: [72][40/140]\t\nTrain: [72][50/140]\t\nTrain: [72][60/140]\t\nTrain: [72][70/140]\t\nTrain: [72][80/140]\t\nTrain: [72][90/140]\t\nTrain: [72][100/140]\t\nTrain: [72][110/140]\t\nTrain: [72][120/140]\t\nTrain: [72][130/140]\t\nTrain: [72][140/140]\t\nTraining Accuracy: 90.31%\nTrain: [73][10/140]\t\nTrain: [73][20/140]\t\nTrain: [73][30/140]\t\nTrain: [73][40/140]\t\nTrain: [73][50/140]\t\nTrain: [73][60/140]\t\nTrain: [73][70/140]\t\nTrain: [73][80/140]\t\nTrain: [73][90/140]\t\nTrain: [73][100/140]\t\nTrain: [73][110/140]\t\nTrain: [73][120/140]\t\nTrain: [73][130/140]\t\nTrain: [73][140/140]\t\nTraining Accuracy: 90.40%\nTrain: [74][10/140]\t\nTrain: [74][20/140]\t\nTrain: [74][30/140]\t\nTrain: [74][40/140]\t\nTrain: [74][50/140]\t\nTrain: [74][60/140]\t\nTrain: [74][70/140]\t\nTrain: [74][80/140]\t\nTrain: [74][90/140]\t\nTrain: [74][100/140]\t\nTrain: [74][110/140]\t\nTrain: [74][120/140]\t\nTrain: [74][130/140]\t\nTrain: [74][140/140]\t\nTraining Accuracy: 90.44%\nTrain: [75][10/140]\t\nTrain: [75][20/140]\t\nTrain: [75][30/140]\t\nTrain: [75][40/140]\t\nTrain: [75][50/140]\t\nTrain: [75][60/140]\t\nTrain: [75][70/140]\t\nTrain: [75][80/140]\t\nTrain: [75][90/140]\t\nTrain: [75][100/140]\t\nTrain: [75][110/140]\t\nTrain: [75][120/140]\t\nTrain: [75][130/140]\t\nTrain: [75][140/140]\t\nTraining Accuracy: 90.67%\nTrain: [76][10/140]\t\nTrain: [76][20/140]\t\nTrain: [76][30/140]\t\nTrain: [76][40/140]\t\nTrain: [76][50/140]\t\nTrain: [76][60/140]\t\nTrain: [76][70/140]\t\nTrain: [76][80/140]\t\nTrain: [76][90/140]\t\nTrain: [76][100/140]\t\nTrain: [76][110/140]\t\nTrain: [76][120/140]\t\nTrain: [76][130/140]\t\nTrain: [76][140/140]\t\nTraining Accuracy: 90.49%\nTrain: [77][10/140]\t\nTrain: [77][20/140]\t\nTrain: [77][30/140]\t\nTrain: [77][40/140]\t\nTrain: [77][50/140]\t\nTrain: [77][60/140]\t\nTrain: [77][70/140]\t\nTrain: [77][80/140]\t\nTrain: [77][90/140]\t\nTrain: [77][100/140]\t\nTrain: [77][110/140]\t\nTrain: [77][120/140]\t\nTrain: [77][130/140]\t\nTrain: [77][140/140]\t\nTraining Accuracy: 90.47%\nTrain: [78][10/140]\t\nTrain: [78][20/140]\t\nTrain: [78][30/140]\t\nTrain: [78][40/140]\t\nTrain: [78][50/140]\t\nTrain: [78][60/140]\t\nTrain: [78][70/140]\t\nTrain: [78][80/140]\t\nTrain: [78][90/140]\t\nTrain: [78][100/140]\t\nTrain: [78][110/140]\t\nTrain: [78][120/140]\t\nTrain: [78][130/140]\t\nTrain: [78][140/140]\t\nTraining Accuracy: 90.45%\nTrain: [79][10/140]\t\nTrain: [79][20/140]\t\nTrain: [79][30/140]\t\nTrain: [79][40/140]\t\nTrain: [79][50/140]\t\nTrain: [79][60/140]\t\nTrain: [79][70/140]\t\nTrain: [79][80/140]\t\nTrain: [79][90/140]\t\nTrain: [79][100/140]\t\nTrain: [79][110/140]\t\nTrain: [79][120/140]\t\nTrain: [79][130/140]\t\nTrain: [79][140/140]\t\nTraining Accuracy: 90.51%\nTrain: [80][10/140]\t\nTrain: [80][20/140]\t\nTrain: [80][30/140]\t\nTrain: [80][40/140]\t\nTrain: [80][50/140]\t\nTrain: [80][60/140]\t\nTrain: [80][70/140]\t\nTrain: [80][80/140]\t\nTrain: [80][90/140]\t\nTrain: [80][100/140]\t\nTrain: [80][110/140]\t\nTrain: [80][120/140]\t\nTrain: [80][130/140]\t\nTrain: [80][140/140]\t\nTraining Accuracy: 90.65%\nTrain: [81][10/140]\t\nTrain: [81][20/140]\t\nTrain: [81][30/140]\t\nTrain: [81][40/140]\t\nTrain: [81][50/140]\t\nTrain: [81][60/140]\t\nTrain: [81][70/140]\t\nTrain: [81][80/140]\t\nTrain: [81][90/140]\t\nTrain: [81][100/140]\t\nTrain: [81][110/140]\t\nTrain: [81][120/140]\t\nTrain: [81][130/140]\t\nTrain: [81][140/140]\t\nTraining Accuracy: 90.69%\nTrain: [82][10/140]\t\nTrain: [82][20/140]\t\nTrain: [82][30/140]\t\nTrain: [82][40/140]\t\nTrain: [82][50/140]\t\nTrain: [82][60/140]\t\nTrain: [82][70/140]\t\nTrain: [82][80/140]\t\nTrain: [82][90/140]\t\nTrain: [82][100/140]\t\nTrain: [82][110/140]\t\nTrain: [82][120/140]\t\nTrain: [82][130/140]\t\nTrain: [82][140/140]\t\nTraining Accuracy: 90.63%\nTrain: [83][10/140]\t\nTrain: [83][20/140]\t\nTrain: [83][30/140]\t\nTrain: [83][40/140]\t\nTrain: [83][50/140]\t\nTrain: [83][60/140]\t\nTrain: [83][70/140]\t\nTrain: [83][80/140]\t\nTrain: [83][90/140]\t\nTrain: [83][100/140]\t\nTrain: [83][110/140]\t\nTrain: [83][120/140]\t\nTrain: [83][130/140]\t\nTrain: [83][140/140]\t\nTraining Accuracy: 90.71%\nTrain: [84][10/140]\t\nTrain: [84][20/140]\t\nTrain: [84][30/140]\t\nTrain: [84][40/140]\t\nTrain: [84][50/140]\t\nTrain: [84][60/140]\t\nTrain: [84][70/140]\t\nTrain: [84][80/140]\t\nTrain: [84][90/140]\t\nTrain: [84][100/140]\t\nTrain: [84][110/140]\t\nTrain: [84][120/140]\t\nTrain: [84][130/140]\t\nTrain: [84][140/140]\t\nTraining Accuracy: 90.56%\nTrain: [85][10/140]\t\nTrain: [85][20/140]\t\nTrain: [85][30/140]\t\nTrain: [85][40/140]\t\nTrain: [85][50/140]\t\nTrain: [85][60/140]\t\nTrain: [85][70/140]\t\nTrain: [85][80/140]\t\nTrain: [85][90/140]\t\nTrain: [85][100/140]\t\nTrain: [85][110/140]\t\nTrain: [85][120/140]\t\nTrain: [85][130/140]\t\nTrain: [85][140/140]\t\nTraining Accuracy: 90.61%\nTrain: [86][10/140]\t\nTrain: [86][20/140]\t\nTrain: [86][30/140]\t\nTrain: [86][40/140]\t\nTrain: [86][50/140]\t\nTrain: [86][60/140]\t\nTrain: [86][70/140]\t\nTrain: [86][80/140]\t\nTrain: [86][90/140]\t\nTrain: [86][100/140]\t\nTrain: [86][110/140]\t\nTrain: [86][120/140]\t\nTrain: [86][130/140]\t\nTrain: [86][140/140]\t\nTraining Accuracy: 91.03%\nTrain: [87][10/140]\t\nTrain: [87][20/140]\t\nTrain: [87][30/140]\t\nTrain: [87][40/140]\t\nTrain: [87][50/140]\t\nTrain: [87][60/140]\t\nTrain: [87][70/140]\t\nTrain: [87][80/140]\t\nTrain: [87][90/140]\t\nTrain: [87][100/140]\t\nTrain: [87][110/140]\t\nTrain: [87][120/140]\t\nTrain: [87][130/140]\t\nTrain: [87][140/140]\t\nTraining Accuracy: 91.10%\nTrain: [88][10/140]\t\nTrain: [88][20/140]\t\nTrain: [88][30/140]\t\nTrain: [88][40/140]\t\nTrain: [88][50/140]\t\nTrain: [88][60/140]\t\nTrain: [88][70/140]\t\nTrain: [88][80/140]\t\nTrain: [88][90/140]\t\nTrain: [88][100/140]\t\nTrain: [88][110/140]\t\nTrain: [88][120/140]\t\nTrain: [88][130/140]\t\nTrain: [88][140/140]\t\nTraining Accuracy: 91.05%\nTrain: [89][10/140]\t\nTrain: [89][20/140]\t\nTrain: [89][30/140]\t\nTrain: [89][40/140]\t\nTrain: [89][50/140]\t\nTrain: [89][60/140]\t\nTrain: [89][70/140]\t\nTrain: [89][80/140]\t\nTrain: [89][90/140]\t\nTrain: [89][100/140]\t\nTrain: [89][110/140]\t\nTrain: [89][120/140]\t\nTrain: [89][130/140]\t\nTrain: [89][140/140]\t\nTraining Accuracy: 91.21%\nTrain: [90][10/140]\t\nTrain: [90][20/140]\t\nTrain: [90][30/140]\t\nTrain: [90][40/140]\t\nTrain: [90][50/140]\t\nTrain: [90][60/140]\t\nTrain: [90][70/140]\t\nTrain: [90][80/140]\t\nTrain: [90][90/140]\t\nTrain: [90][100/140]\t\nTrain: [90][110/140]\t\nTrain: [90][120/140]\t\nTrain: [90][130/140]\t\nTrain: [90][140/140]\t\nTraining Accuracy: 91.16%\nTrain: [91][10/140]\t\nTrain: [91][20/140]\t\nTrain: [91][30/140]\t\nTrain: [91][40/140]\t\nTrain: [91][50/140]\t\nTrain: [91][60/140]\t\nTrain: [91][70/140]\t\nTrain: [91][80/140]\t\nTrain: [91][90/140]\t\nTrain: [91][100/140]\t\nTrain: [91][110/140]\t\nTrain: [91][120/140]\t\nTrain: [91][130/140]\t\nTrain: [91][140/140]\t\nTraining Accuracy: 91.22%\nTrain: [92][10/140]\t\nTrain: [92][20/140]\t\nTrain: [92][30/140]\t\nTrain: [92][40/140]\t\nTrain: [92][50/140]\t\nTrain: [92][60/140]\t\nTrain: [92][70/140]\t\nTrain: [92][80/140]\t\nTrain: [92][90/140]\t\nTrain: [92][100/140]\t\nTrain: [92][110/140]\t\nTrain: [92][120/140]\t\nTrain: [92][130/140]\t\nTrain: [92][140/140]\t\nTraining Accuracy: 90.95%\nTrain: [93][10/140]\t\nTrain: [93][20/140]\t\nTrain: [93][30/140]\t\nTrain: [93][40/140]\t\nTrain: [93][50/140]\t\nTrain: [93][60/140]\t\nTrain: [93][70/140]\t\nTrain: [93][80/140]\t\nTrain: [93][90/140]\t\nTrain: [93][100/140]\t\nTrain: [93][110/140]\t\nTrain: [93][120/140]\t\nTrain: [93][130/140]\t\nTrain: [93][140/140]\t\nTraining Accuracy: 91.26%\nTrain: [94][10/140]\t\nTrain: [94][20/140]\t\nTrain: [94][30/140]\t\nTrain: [94][40/140]\t\nTrain: [94][50/140]\t\nTrain: [94][60/140]\t\nTrain: [94][70/140]\t\nTrain: [94][80/140]\t\nTrain: [94][90/140]\t\nTrain: [94][100/140]\t\nTrain: [94][110/140]\t\nTrain: [94][120/140]\t\nTrain: [94][130/140]\t\nTrain: [94][140/140]\t\nTraining Accuracy: 91.27%\nTrain: [95][10/140]\t\nTrain: [95][20/140]\t\nTrain: [95][30/140]\t\nTrain: [95][40/140]\t\nTrain: [95][50/140]\t\nTrain: [95][60/140]\t\nTrain: [95][70/140]\t\nTrain: [95][80/140]\t\nTrain: [95][90/140]\t\nTrain: [95][100/140]\t\nTrain: [95][110/140]\t\nTrain: [95][120/140]\t\nTrain: [95][130/140]\t\nTrain: [95][140/140]\t\nTraining Accuracy: 91.13%\nTrain: [96][10/140]\t\nTrain: [96][20/140]\t\nTrain: [96][30/140]\t\nTrain: [96][40/140]\t\nTrain: [96][50/140]\t\nTrain: [96][60/140]\t\nTrain: [96][70/140]\t\nTrain: [96][80/140]\t\nTrain: [96][90/140]\t\nTrain: [96][100/140]\t\nTrain: [96][110/140]\t\nTrain: [96][120/140]\t\nTrain: [96][130/140]\t\nTrain: [96][140/140]\t\nTraining Accuracy: 91.30%\nTrain: [97][10/140]\t\nTrain: [97][20/140]\t\nTrain: [97][30/140]\t\nTrain: [97][40/140]\t\nTrain: [97][50/140]\t\nTrain: [97][60/140]\t\nTrain: [97][70/140]\t\nTrain: [97][80/140]\t\nTrain: [97][90/140]\t\nTrain: [97][100/140]\t\nTrain: [97][110/140]\t\nTrain: [97][120/140]\t\nTrain: [97][130/140]\t\nTrain: [97][140/140]\t\nTraining Accuracy: 91.33%\nTrain: [98][10/140]\t\nTrain: [98][20/140]\t\nTrain: [98][30/140]\t\nTrain: [98][40/140]\t\nTrain: [98][50/140]\t\nTrain: [98][60/140]\t\nTrain: [98][70/140]\t\nTrain: [98][80/140]\t\nTrain: [98][90/140]\t\nTrain: [98][100/140]\t\nTrain: [98][110/140]\t\nTrain: [98][120/140]\t\nTrain: [98][130/140]\t\nTrain: [98][140/140]\t\nTraining Accuracy: 91.50%\nTrain: [99][10/140]\t\nTrain: [99][20/140]\t\nTrain: [99][30/140]\t\nTrain: [99][40/140]\t\nTrain: [99][50/140]\t\nTrain: [99][60/140]\t\nTrain: [99][70/140]\t\nTrain: [99][80/140]\t\nTrain: [99][90/140]\t\nTrain: [99][100/140]\t\nTrain: [99][110/140]\t\nTrain: [99][120/140]\t\nTrain: [99][130/140]\t\nTrain: [99][140/140]\t\nTraining Accuracy: 91.37%\nTrain: [100][10/140]\t\nTrain: [100][20/140]\t\nTrain: [100][30/140]\t\nTrain: [100][40/140]\t\nTrain: [100][50/140]\t\nTrain: [100][60/140]\t\nTrain: [100][70/140]\t\nTrain: [100][80/140]\t\nTrain: [100][90/140]\t\nTrain: [100][100/140]\t\nTrain: [100][110/140]\t\nTrain: [100][120/140]\t\nTrain: [100][130/140]\t\nTrain: [100][140/140]\t\nTraining Accuracy: 91.42%\nTrain: [101][10/140]\t\nTrain: [101][20/140]\t\nTrain: [101][30/140]\t\nTrain: [101][40/140]\t\nTrain: [101][50/140]\t\nTrain: [101][60/140]\t\nTrain: [101][70/140]\t\nTrain: [101][80/140]\t\nTrain: [101][90/140]\t\nTrain: [101][100/140]\t\nTrain: [101][110/140]\t\nTrain: [101][120/140]\t\nTrain: [101][130/140]\t\nTrain: [101][140/140]\t\nTraining Accuracy: 91.52%\nTrain: [102][10/140]\t\nTrain: [102][20/140]\t\nTrain: [102][30/140]\t\nTrain: [102][40/140]\t\nTrain: [102][50/140]\t\nTrain: [102][60/140]\t\nTrain: [102][70/140]\t\nTrain: [102][80/140]\t\nTrain: [102][90/140]\t\nTrain: [102][100/140]\t\nTrain: [102][110/140]\t\nTrain: [102][120/140]\t\nTrain: [102][130/140]\t\nTrain: [102][140/140]\t\nTraining Accuracy: 91.43%\nTrain: [103][10/140]\t\nTrain: [103][20/140]\t\nTrain: [103][30/140]\t\nTrain: [103][40/140]\t\nTrain: [103][50/140]\t\nTrain: [103][60/140]\t\nTrain: [103][70/140]\t\nTrain: [103][80/140]\t\nTrain: [103][90/140]\t\nTrain: [103][100/140]\t\nTrain: [103][110/140]\t\nTrain: [103][120/140]\t\nTrain: [103][130/140]\t\nTrain: [103][140/140]\t\nTraining Accuracy: 91.54%\nTrain: [104][10/140]\t\nTrain: [104][20/140]\t\nTrain: [104][30/140]\t\nTrain: [104][40/140]\t\nTrain: [104][50/140]\t\nTrain: [104][60/140]\t\nTrain: [104][70/140]\t\nTrain: [104][80/140]\t\nTrain: [104][90/140]\t\nTrain: [104][100/140]\t\nTrain: [104][110/140]\t\nTrain: [104][120/140]\t\nTrain: [104][130/140]\t\nTrain: [104][140/140]\t\nTraining Accuracy: 91.65%\nTrain: [105][10/140]\t\nTrain: [105][20/140]\t\nTrain: [105][30/140]\t\nTrain: [105][40/140]\t\nTrain: [105][50/140]\t\nTrain: [105][60/140]\t\nTrain: [105][70/140]\t\nTrain: [105][80/140]\t\nTrain: [105][90/140]\t\nTrain: [105][100/140]\t\nTrain: [105][110/140]\t\nTrain: [105][120/140]\t\nTrain: [105][130/140]\t\nTrain: [105][140/140]\t\nTraining Accuracy: 91.75%\nTrain: [106][10/140]\t\nTrain: [106][20/140]\t\nTrain: [106][30/140]\t\nTrain: [106][40/140]\t\nTrain: [106][50/140]\t\nTrain: [106][60/140]\t\nTrain: [106][70/140]\t\nTrain: [106][80/140]\t\nTrain: [106][90/140]\t\nTrain: [106][100/140]\t\nTrain: [106][110/140]\t\nTrain: [106][120/140]\t\nTrain: [106][130/140]\t\nTrain: [106][140/140]\t\nTraining Accuracy: 91.61%\nTrain: [107][10/140]\t\nTrain: [107][20/140]\t\nTrain: [107][30/140]\t\nTrain: [107][40/140]\t\nTrain: [107][50/140]\t\nTrain: [107][60/140]\t\nTrain: [107][70/140]\t\nTrain: [107][80/140]\t\nTrain: [107][90/140]\t\nTrain: [107][100/140]\t\nTrain: [107][110/140]\t\nTrain: [107][120/140]\t\nTrain: [107][130/140]\t\nTrain: [107][140/140]\t\nTraining Accuracy: 91.78%\nTrain: [108][10/140]\t\nTrain: [108][20/140]\t\nTrain: [108][30/140]\t\nTrain: [108][40/140]\t\nTrain: [108][50/140]\t\nTrain: [108][60/140]\t\nTrain: [108][70/140]\t\nTrain: [108][80/140]\t\nTrain: [108][90/140]\t\nTrain: [108][100/140]\t\nTrain: [108][110/140]\t\nTrain: [108][120/140]\t\nTrain: [108][130/140]\t\nTrain: [108][140/140]\t\nTraining Accuracy: 91.68%\nTrain: [109][10/140]\t\nTrain: [109][20/140]\t\nTrain: [109][30/140]\t\nTrain: [109][40/140]\t\nTrain: [109][50/140]\t\nTrain: [109][60/140]\t\nTrain: [109][70/140]\t\nTrain: [109][80/140]\t\nTrain: [109][90/140]\t\nTrain: [109][100/140]\t\nTrain: [109][110/140]\t\nTrain: [109][120/140]\t\nTrain: [109][130/140]\t\nTrain: [109][140/140]\t\nTraining Accuracy: 91.80%\nTrain: [110][10/140]\t\nTrain: [110][20/140]\t\nTrain: [110][30/140]\t\nTrain: [110][40/140]\t\nTrain: [110][50/140]\t\nTrain: [110][60/140]\t\nTrain: [110][70/140]\t\nTrain: [110][80/140]\t\nTrain: [110][90/140]\t\nTrain: [110][100/140]\t\nTrain: [110][110/140]\t\nTrain: [110][120/140]\t\nTrain: [110][130/140]\t\nTrain: [110][140/140]\t\nTraining Accuracy: 91.75%\nTrain: [111][10/140]\t\nTrain: [111][20/140]\t\nTrain: [111][30/140]\t\nTrain: [111][40/140]\t\nTrain: [111][50/140]\t\nTrain: [111][60/140]\t\nTrain: [111][70/140]\t\nTrain: [111][80/140]\t\nTrain: [111][90/140]\t\nTrain: [111][100/140]\t\nTrain: [111][110/140]\t\nTrain: [111][120/140]\t\nTrain: [111][130/140]\t\nTrain: [111][140/140]\t\nTraining Accuracy: 91.88%\nTrain: [112][10/140]\t\nTrain: [112][20/140]\t\nTrain: [112][30/140]\t\nTrain: [112][40/140]\t\nTrain: [112][50/140]\t\nTrain: [112][60/140]\t\nTrain: [112][70/140]\t\nTrain: [112][80/140]\t\nTrain: [112][90/140]\t\nTrain: [112][100/140]\t\nTrain: [112][110/140]\t\nTrain: [112][120/140]\t\nTrain: [112][130/140]\t\nTrain: [112][140/140]\t\nTraining Accuracy: 91.93%\nTrain: [113][10/140]\t\nTrain: [113][20/140]\t\nTrain: [113][30/140]\t\nTrain: [113][40/140]\t\nTrain: [113][50/140]\t\nTrain: [113][60/140]\t\nTrain: [113][70/140]\t\nTrain: [113][80/140]\t\nTrain: [113][90/140]\t\nTrain: [113][100/140]\t\nTrain: [113][110/140]\t\nTrain: [113][120/140]\t\nTrain: [113][130/140]\t\nTrain: [113][140/140]\t\nTraining Accuracy: 91.93%\nTrain: [114][10/140]\t\nTrain: [114][20/140]\t\nTrain: [114][30/140]\t\nTrain: [114][40/140]\t\nTrain: [114][50/140]\t\nTrain: [114][60/140]\t\nTrain: [114][70/140]\t\nTrain: [114][80/140]\t\nTrain: [114][90/140]\t\nTrain: [114][100/140]\t\nTrain: [114][110/140]\t\nTrain: [114][120/140]\t\nTrain: [114][130/140]\t\nTrain: [114][140/140]\t\nTraining Accuracy: 91.99%\nTrain: [115][10/140]\t\nTrain: [115][20/140]\t\nTrain: [115][30/140]\t\nTrain: [115][40/140]\t\nTrain: [115][50/140]\t\nTrain: [115][60/140]\t\nTrain: [115][70/140]\t\nTrain: [115][80/140]\t\nTrain: [115][90/140]\t\nTrain: [115][100/140]\t\nTrain: [115][110/140]\t\nTrain: [115][120/140]\t\nTrain: [115][130/140]\t\nTrain: [115][140/140]\t\nTraining Accuracy: 92.19%\nTrain: [116][10/140]\t\nTrain: [116][20/140]\t\nTrain: [116][30/140]\t\nTrain: [116][40/140]\t\nTrain: [116][50/140]\t\nTrain: [116][60/140]\t\nTrain: [116][70/140]\t\nTrain: [116][80/140]\t\nTrain: [116][90/140]\t\nTrain: [116][100/140]\t\nTrain: [116][110/140]\t\nTrain: [116][120/140]\t\nTrain: [116][130/140]\t\nTrain: [116][140/140]\t\nTraining Accuracy: 91.88%\nTrain: [117][10/140]\t\nTrain: [117][20/140]\t\nTrain: [117][30/140]\t\nTrain: [117][40/140]\t\nTrain: [117][50/140]\t\nTrain: [117][60/140]\t\nTrain: [117][70/140]\t\nTrain: [117][80/140]\t\nTrain: [117][90/140]\t\nTrain: [117][100/140]\t\nTrain: [117][110/140]\t\nTrain: [117][120/140]\t\nTrain: [117][130/140]\t\nTrain: [117][140/140]\t\nTraining Accuracy: 91.95%\nTrain: [118][10/140]\t\nTrain: [118][20/140]\t\nTrain: [118][30/140]\t\nTrain: [118][40/140]\t\nTrain: [118][50/140]\t\nTrain: [118][60/140]\t\nTrain: [118][70/140]\t\nTrain: [118][80/140]\t\nTrain: [118][90/140]\t\nTrain: [118][100/140]\t\nTrain: [118][110/140]\t\nTrain: [118][120/140]\t\nTrain: [118][130/140]\t\nTrain: [118][140/140]\t\nTraining Accuracy: 92.09%\nTrain: [119][10/140]\t\nTrain: [119][20/140]\t\nTrain: [119][30/140]\t\nTrain: [119][40/140]\t\nTrain: [119][50/140]\t\nTrain: [119][60/140]\t\nTrain: [119][70/140]\t\nTrain: [119][80/140]\t\nTrain: [119][90/140]\t\nTrain: [119][100/140]\t\nTrain: [119][110/140]\t\nTrain: [119][120/140]\t\nTrain: [119][130/140]\t\nTrain: [119][140/140]\t\nTraining Accuracy: 92.21%\nTrain: [120][10/140]\t\nTrain: [120][20/140]\t\nTrain: [120][30/140]\t\nTrain: [120][40/140]\t\nTrain: [120][50/140]\t\nTrain: [120][60/140]\t\nTrain: [120][70/140]\t\nTrain: [120][80/140]\t\nTrain: [120][90/140]\t\nTrain: [120][100/140]\t\nTrain: [120][110/140]\t\nTrain: [120][120/140]\t\nTrain: [120][130/140]\t\nTrain: [120][140/140]\t\nTraining Accuracy: 91.93%\n","output_type":"stream"}]},{"cell_type":"code","source":"save_file = os.path.join(opt.save_folder, 'last.pth')\nsave_model(model, optimizer, opt, opt.epochs, save_file)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T12:24:46.693213Z","iopub.execute_input":"2023-08-20T12:24:46.693964Z","iopub.status.idle":"2023-08-20T12:24:47.191169Z","shell.execute_reply.started":"2023-08-20T12:24:46.693919Z","shell.execute_reply":"2023-08-20T12:24:47.189839Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"==> Saving...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Validation\nsample_evaluation(val_loader, model, opt)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T12:24:47.193544Z","iopub.execute_input":"2023-08-20T12:24:47.193977Z","iopub.status.idle":"2023-08-20T12:24:56.960675Z","shell.execute_reply.started":"2023-08-20T12:24:47.193937Z","shell.execute_reply":"2023-08-20T12:24:56.959638Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"87.73049645390071 %\n0.8339412512559757\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_generate(test_loader, model, opt)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T12:24:56.962480Z","iopub.execute_input":"2023-08-20T12:24:56.963091Z","iopub.status.idle":"2023-08-20T12:26:12.468179Z","shell.execute_reply.started":"2023-08-20T12:24:56.963054Z","shell.execute_reply":"2023-08-20T12:26:12.467185Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"output = np.load('/kaggle/working/output.npy')\nsubmission = pd.read_csv(\"/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv\")\nsubmission.iloc[:, 1:] = output\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T12:26:12.469781Z","iopub.execute_input":"2023-08-20T12:26:12.470116Z","iopub.status.idle":"2023-08-20T12:26:12.533401Z","shell.execute_reply.started":"2023-08-20T12:26:12.470084Z","shell.execute_reply":"2023-08-20T12:26:12.532459Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**End**","metadata":{}}]}