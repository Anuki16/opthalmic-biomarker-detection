{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77786c",
   "metadata": {
    "papermill": {
     "duration": 0.014286,
     "end_time": "2023-09-05T15:23:18.317046",
     "exception": false,
     "start_time": "2023-09-05T15:23:18.302760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bdc0e9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:18.346360Z",
     "iopub.status.busy": "2023-09-05T15:23:18.345349Z",
     "iopub.status.idle": "2023-09-05T15:23:19.446197Z",
     "shell.execute_reply": "2023-09-05T15:23:19.445245Z"
    },
    "papermill": {
     "duration": 1.117603,
     "end_time": "2023-09-05T15:23:19.448478",
     "exception": false,
     "start_time": "2023-09-05T15:23:18.330875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "'''\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d6dcea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:19.477498Z",
     "iopub.status.busy": "2023-09-05T15:23:19.477170Z",
     "iopub.status.idle": "2023-09-05T15:23:32.498389Z",
     "shell.execute_reply": "2023-09-05T15:23:32.497234Z"
    },
    "papermill": {
     "duration": 13.03856,
     "end_time": "2023-09-05T15:23:32.501020",
     "exception": false,
     "start_time": "2023-09-05T15:23:19.462460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-metric-learning\r\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (1.2.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (2.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (1.11.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\r\n",
      "Installing collected packages: pytorch-metric-learning\r\n",
      "Successfully installed pytorch-metric-learning-2.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205a461d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:32.531580Z",
     "iopub.status.busy": "2023-09-05T15:23:32.531231Z",
     "iopub.status.idle": "2023-09-05T15:23:36.388074Z",
     "shell.execute_reply": "2023-09-05T15:23:36.387119Z"
    },
    "papermill": {
     "duration": 3.875137,
     "end_time": "2023-09-05T15:23:36.390976",
     "exception": false,
     "start_time": "2023-09-05T15:23:32.515839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"encoder + classifier\"\"\"\n",
    "    def __init__(self, name='resnet50', num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        if (name == 'resnet50'):\n",
    "            self.encoder = torchvision.models.resnet50(zero_init_residual=True)\n",
    "            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            self.encoder.fc = nn.Identity()\n",
    "            self.fc = nn.Linear(2048, num_classes)\n",
    "        else:\n",
    "            self.encoder = torchvision.models.resnet18(zero_init_residual=True)\n",
    "            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            self.encoder.fc = nn.Identity()\n",
    "            self.fc = nn.Linear(512, num_classes)\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.fc(self.encoder(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e8b3a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.422629Z",
     "iopub.status.busy": "2023-09-05T15:23:36.421497Z",
     "iopub.status.idle": "2023-09-05T15:23:36.429727Z",
     "shell.execute_reply": "2023-09-05T15:23:36.428800Z"
    },
    "papermill": {
     "duration": 0.026307,
     "end_time": "2023-09-05T15:23:36.431956",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.405649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Prj_Head(nn.Module):\n",
    "    def __init__(self,in_dim,feature_dim):\n",
    "        super(Prj_Head, self).__init__()\n",
    "        \n",
    "        self.g1 = nn.Sequential(nn.Linear(in_dim, 1024, bias=False),\n",
    "                               nn.BatchNorm1d(1024),\n",
    "                               nn.ReLU(inplace=True)\n",
    "                               )\n",
    "        self.g2 = nn.Sequential(nn.Linear(1024, 512, bias=False),\n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.g3=nn.Linear(512, feature_dim, bias=True)\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=- 1) \n",
    "        x = self.g1(x)\n",
    "        x = self.g2(x)\n",
    "        x = self.g3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309f1e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.461629Z",
     "iopub.status.busy": "2023-09-05T15:23:36.461367Z",
     "iopub.status.idle": "2023-09-05T15:23:36.468533Z",
     "shell.execute_reply": "2023-09-05T15:23:36.467487Z"
    },
    "papermill": {
     "duration": 0.02428,
     "end_time": "2023-09-05T15:23:36.470411",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.446131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encdr(nn.Module):\n",
    "    \"\"\"encoder + classifier\"\"\"\n",
    "    def __init__(self, name='resnet50', num_classes=2):\n",
    "        super(Encdr, self).__init__()\n",
    "        self.encoder = torchvision.models.resnet50(pretrained=True, zero_init_residual=True)\n",
    "        self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.fc = nn.Linear(2048, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.fc(self.encoder(x))\n",
    "    \n",
    "    def add_feature(self):\n",
    "        self.fc1=nn.Linear(512,2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a826acd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.500857Z",
     "iopub.status.busy": "2023-09-05T15:23:36.500601Z",
     "iopub.status.idle": "2023-09-05T15:23:36.517583Z",
     "shell.execute_reply": "2023-09-05T15:23:36.516726Z"
    },
    "papermill": {
     "duration": 0.034873,
     "end_time": "2023-09-05T15:23:36.519596",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.484723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets.py\n",
    "\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class OLIVES(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        b1 = self.df.iloc[idx,1]\n",
    "        b2 = self.df.iloc[idx,2]\n",
    "        b3 = self.df.iloc[idx,3]\n",
    "        b4 = self.df.iloc[idx, 4]\n",
    "        b5 = self.df.iloc[idx, 5]\n",
    "        b6 = self.df.iloc[idx, 6]\n",
    "        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n",
    "        return image, bio_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RECOVERY(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "class RECOVERY_TEST(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        b1 = self.df.iloc[idx,1]\n",
    "        b2 = self.df.iloc[idx,2]\n",
    "        b3 = self.df.iloc[idx,3]\n",
    "        b4 = self.df.iloc[idx, 4]\n",
    "        b5 = self.df.iloc[idx, 5]\n",
    "        b6 = self.df.iloc[idx, 6]\n",
    "        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n",
    "        return image, bio_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cf1f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.549831Z",
     "iopub.status.busy": "2023-09-05T15:23:36.549008Z",
     "iopub.status.idle": "2023-09-05T15:23:36.560059Z",
     "shell.execute_reply": "2023-09-05T15:23:36.559239Z"
    },
    "papermill": {
     "duration": 0.02844,
     "end_time": "2023-09-05T15:23:36.562175",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.533735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def combine_excel(csv_dir):\n",
    "    filenames = glob.glob(csv_dir + \"/*.xlsx\")\n",
    "    outputxlsx = pd.DataFrame()\n",
    "\n",
    "    for file in filenames:\n",
    "        df = pd.concat(pd.read_excel(file, sheet_name=None), ignore_index=True, sort=False)\n",
    "        outputxlsx = outputxlsx.append(df, ignore_index=True)\n",
    "\n",
    "    outputxlsx.to_csv('test_set_labels.csv',index=False)\n",
    "\n",
    "def analyze_dataframe(csv_dir):\n",
    "    pass\n",
    "\n",
    "def process_images(csv_dir):\n",
    "    df = pd.read_csv(csv_dir)\n",
    "\n",
    "    for i in tqdm(range(0,len(df))):\n",
    "        path = df.iloc[i,0]\n",
    "        im = Image.open(path).convert('L')\n",
    "\n",
    "\n",
    "def numpy_submission(sub_dir,np_dir):\n",
    "    np_file  = np.load(np_dir)\n",
    "    print(len(np_file))\n",
    "    sub_dir = pd.read_csv(sub_dir)\n",
    "    print(len(sub_dir))\n",
    "    for i in range(0,len(sub_dir)):\n",
    "        sub_dir.iloc[i,1] = np_file[i,0]\n",
    "        sub_dir.iloc[i, 2] = np_file[i, 1]\n",
    "        sub_dir.iloc[i, 3] = np_file[i, 2]\n",
    "        sub_dir.iloc[i, 4] = np_file[i, 3]\n",
    "        sub_dir.iloc[i, 5] = np_file[i, 4]\n",
    "        sub_dir.iloc[i, 6] = np_file[i, 5]\n",
    "    print(sub_dir.head())\n",
    "    sub_dir.to_csv('baseline_result.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "    #process_images(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f7a018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.592503Z",
     "iopub.status.busy": "2023-09-05T15:23:36.592252Z",
     "iopub.status.idle": "2023-09-05T15:23:36.623862Z",
     "shell.execute_reply": "2023-09-05T15:23:36.623045Z"
    },
    "papermill": {
     "duration": 0.049488,
     "end_time": "2023-09-05T15:23:36.626008",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.576520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import random_split, Subset, SubsetRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "def set_model(opt, freeze = False):\n",
    "\n",
    "\n",
    "    device = opt.device\n",
    "    model = ResNet(name=opt.model,num_classes = opt.ncls)\n",
    "    if freeze:\n",
    "        model.encoder.requires_grad_(False)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "# model for self supervised training\n",
    "\n",
    "def set_model_st(opt,Net):\n",
    "\n",
    "\n",
    "    device = opt.device\n",
    "    #model = Encdr(name=opt.model,num_classes = opt.ncls)\n",
    "    model = nn.Sequential(\n",
    "    Net, \n",
    "    nn.Linear(512, 1024, bias=False),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(1024, 512, bias=False),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 6, bias=True))\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_loader(opt):\n",
    "    # construct data loader\n",
    "    if opt.dataset == 'OLIVES' or opt.dataset == 'RECOVERY':\n",
    "        mean = (.1706)\n",
    "        std = (.2112)\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=224, scale=(0.85, 1.)),\n",
    "        transforms.RandomRotation(30), \n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "\n",
    "    if opt.dataset =='OLIVES':\n",
    "        data_path_train = opt.train_image_path\n",
    "        data_path_test = opt.test_image_path\n",
    "        train_dataset = OLIVES(csv_path_train,data_path_train,transforms = train_transform)\n",
    "        unlabelled_train_dataset = RECOVERY(csv_path_unlabelled,data_path_train,transforms = val_transform)\n",
    "        val_dataset = OLIVES(csv_path_valid,data_path_train,transforms = val_transform)\n",
    "        test_dataset = RECOVERY(csv_path_test,data_path_test,transforms = val_transform)\n",
    "        \n",
    "        # Create a random sampler for the subset\n",
    "        np.random.seed(unlabel_seed)\n",
    "        random_indices = np.random.choice(len(unlabelled_train_dataset), unlabel_count, replace=False)\n",
    "        subset_sampler = SubsetRandomSampler(random_indices)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(opt.dataset)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=True,drop_last=False)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=True,drop_last=False)\n",
    "    \n",
    "    unlabelled_train_loader = torch.utils.data.DataLoader(unlabelled_train_dataset,\n",
    "        sampler=subset_sampler, batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, unlabelled_train_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def adjust_learning_rate(args, optimizer, epoch):\n",
    "    lr = args.learning_rate\n",
    "    if args.cosine:\n",
    "        eta_min = lr * (args.lr_decay_rate ** 3)\n",
    "        lr = eta_min + (lr - eta_min) * (\n",
    "                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n",
    "    else:\n",
    "        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n",
    "        if steps > 0:\n",
    "            lr = lr * (args.lr_decay_rate ** steps)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n",
    "    if args.warm and epoch <= args.warm_epochs:\n",
    "        p = (batch_id + (epoch - 1) * total_batches) / \\\n",
    "            (args.warm_epochs * total_batches)\n",
    "        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def set_optimizer(opt, model):\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=opt.learning_rate,\n",
    "                          momentum=opt.momentum,\n",
    "                          weight_decay=opt.weight_decay)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, opt, epoch, save_file):\n",
    "    print('==> Saving...')\n",
    "    state = {\n",
    "        'opt': opt,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(state, save_file)\n",
    "    del state\n",
    "    \n",
    "def save_model_unsupervised(net, projection_head, save_file):\n",
    "    print('==> Saving...')\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'head': projection_head.state_dict()\n",
    "    }\n",
    "    torch.save(state, save_file)\n",
    "    del state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50fe17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.655694Z",
     "iopub.status.busy": "2023-09-05T15:23:36.655390Z",
     "iopub.status.idle": "2023-09-05T15:23:36.664343Z",
     "shell.execute_reply": "2023-09-05T15:23:36.663509Z"
    },
    "papermill": {
     "duration": 0.026163,
     "end_time": "2023-09-05T15:23:36.666481",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.640318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def set_unlabel_loader(opt, unlabel_seed, unlabel_count):\n",
    "    # construct data loader\n",
    "    mean = (.1706)\n",
    "    std = (.2112)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    data_path_train = opt.train_image_path\n",
    "    data_path_test = opt.test_image_path\n",
    "    \n",
    "    unlabelled_train_dataset = RECOVERY(csv_path_unlabelled,data_path_train,transforms = val_transform)\n",
    "    test_dataset = RECOVERY(csv_path_test,data_path_test,transforms = val_transform)\n",
    "    \n",
    "    full_dataset = torch.utils.data.ConcatDataset([unlabelled_train_dataset, test_dataset])\n",
    "\n",
    "    # Create a random sampler for the subset\n",
    "    np.random.seed(unlabel_seed)\n",
    "    random_indices = np.random.choice(len(full_dataset), unlabel_count, replace=False)\n",
    "    subset_sampler = SubsetRandomSampler(random_indices)\n",
    "    \n",
    "    unlabelled_train_loader = torch.utils.data.DataLoader(full_dataset,\n",
    "        sampler=subset_sampler, batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "\n",
    "    return unlabelled_train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b41a2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.696865Z",
     "iopub.status.busy": "2023-09-05T15:23:36.696523Z",
     "iopub.status.idle": "2023-09-05T15:23:36.704508Z",
     "shell.execute_reply": "2023-09-05T15:23:36.703494Z"
    },
    "papermill": {
     "duration": 0.026199,
     "end_time": "2023-09-05T15:23:36.707115",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.680916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "class Noise(object):\n",
    "    def __init__(self, amount=0.3, brightness=0.2):\n",
    "        self.noise = 200\n",
    "        self.amount = amount\n",
    "        self.brightness = brightness\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dark_region_indices = torch.where(x < self.brightness)\n",
    "        dark_region_coords = torch.stack(dark_region_indices, dim=-1)\n",
    "\n",
    "        # Randomly select pixels from dark regions for adding noise\n",
    "        pixels = torch.randint(0, int(self.amount * 224 * 224), size=(1,))\n",
    "        selected_coords = dark_region_coords[torch.randperm(dark_region_coords.size(0))[:pixels]]\n",
    "\n",
    "        image = x.clone()\n",
    "        # Add salt noise (white pixels)\n",
    "        noise = np.random.randint(self.noise, 250)\n",
    "        image[selected_coords[:, 0], selected_coords[:, 1], selected_coords[:, 2]] = noise\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "204c2dfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.737732Z",
     "iopub.status.busy": "2023-09-05T15:23:36.737441Z",
     "iopub.status.idle": "2023-09-05T15:23:36.780825Z",
     "shell.execute_reply": "2023-09-05T15:23:36.779780Z"
    },
    "papermill": {
     "duration": 0.061563,
     "end_time": "2023-09-05T15:23:36.783131",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.721568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 112, size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da6ae9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.814221Z",
     "iopub.status.busy": "2023-09-05T15:23:36.813928Z",
     "iopub.status.idle": "2023-09-05T15:23:36.829796Z",
     "shell.execute_reply": "2023-09-05T15:23:36.828887Z"
    },
    "papermill": {
     "duration": 0.033654,
     "end_time": "2023-09-05T15:23:36.831785",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.798131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.85, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      "    RandomApply(\n",
      "    p=0.3\n",
      "    ColorJitter(brightness=(0.76, 1.24), contrast=(0.76, 1.24), saturation=(0.76, 1.24), hue=(-0.06, 0.06))\n",
      ")\n",
      "    RandomApply(\n",
      "    p=0.5\n",
      "    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.2))\n",
      ")\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    <__main__.Noise object at 0x7a63bb496a70>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Augmentations\n",
    "from torchvision import transforms\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "    \"\"\"Borrowed from MoCo implementation\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x\n",
    "    \n",
    "class FixedRandomRotation:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "    def __init__(self, angles):\n",
    "        self.angles = angles\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = random.choice(self.angles)\n",
    "        return transforms.functional.rotate(x, angle)\n",
    "    \n",
    "def torchvision_transforms(eval=False, aug=None):\n",
    "\n",
    "    trans = []\n",
    "\n",
    "    if aug[\"resize\"]:\n",
    "        trans.append(transforms.Resize(aug[\"resize\"]))\n",
    "\n",
    "    if aug[\"randcrop\"] and aug[\"scale\"] and not eval:\n",
    "        trans.append(transforms.RandomResizedCrop(aug[\"randcrop\"], scale=aug[\"scale\"]))\n",
    "\n",
    "    if aug[\"randcrop\"] and eval:\n",
    "        trans.append(transforms.CenterCrop(aug[\"randcrop\"]))\n",
    "\n",
    "    if aug[\"flip\"] and not eval:\n",
    "        trans.append(transforms.RandomHorizontalFlip(p=0.5))\n",
    "        trans.append(transforms.RandomVerticalFlip(p=0.5))\n",
    "\n",
    "    if aug[\"jitter_d\"] and not eval:\n",
    "        trans.append(transforms.RandomApply(\n",
    "            [transforms.ColorJitter(0.8*aug[\"jitter_d\"], 0.8*aug[\"jitter_d\"], 0.8*aug[\"jitter_d\"], 0.2*aug[\"jitter_d\"])],\n",
    "             p=aug[\"jitter_p\"]))\n",
    "\n",
    "    if aug[\"gaussian_blur\"] and not eval:\n",
    "        trans.append(transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1,.2))], p=aug[\"gaussian_blur\"]))\n",
    "\n",
    "    if aug[\"rotation\"] and not eval:\n",
    "        # rotation_transform = FixedRandomRotation(angles=[0, 90, 180, 270])\n",
    "        trans.append(transforms.RandomRotation(30))\n",
    "\n",
    "    trans.append(Noise())\n",
    "\n",
    "    trans = transforms.Compose(trans)\n",
    "   \n",
    "    return trans\n",
    "aug = {\"resize\":0,\n",
    "    \"randcrop\":224,\n",
    "      \"scale\": (0.85, 1.0),\n",
    "      \"flip\":0,\n",
    "      \"jitter_d\":0.3,\n",
    "       \"jitter_p\":0.3,\n",
    "       \"gaussian_blur\":0.5,\n",
    "       \"rotation\":1\n",
    "      }\n",
    "augmentations = torchvision_transforms(aug = aug)\n",
    "print(augmentations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca55aeeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.862838Z",
     "iopub.status.busy": "2023-09-05T15:23:36.862586Z",
     "iopub.status.idle": "2023-09-05T15:23:36.879833Z",
     "shell.execute_reply": "2023-09-05T15:23:36.878839Z"
    },
    "papermill": {
     "duration": 0.035376,
     "end_time": "2023-09-05T15:23:36.882128",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.846752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "\n",
    "def parse_option(string):\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "    parser.add_argument('--device', type=str, default='cuda:0')\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.05,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--patient_lambda', type=float, default=1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--cluster_lambda', type=float, default=1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='100',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--train_csv_path', type=str, default='train data csv')\n",
    "    parser.add_argument('--test_csv_path', type=str, default='test data csv')\n",
    "    parser.add_argument('--train_image_path', type=str, default='train data csv')\n",
    "    parser.add_argument('--test_image_path', type=str, default='test data csv')\n",
    "\n",
    "    parser.add_argument('--parallel', type=int, default=1, help='data parallel')\n",
    "    parser.add_argument('--ncls', type=int, default=6, help='Number of Classes')\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='TREX_DME',\n",
    "                        choices=[ 'OLIVES'], help='dataset')\n",
    "    parser.add_argument('--mean', type=str, help='mean of dataset in path in form of str tuple')\n",
    "    parser.add_argument('--std', type=str, help='std of dataset in path in form of str tuple')\n",
    "    parser.add_argument('--data_folder', type=str, default=None, help='path to custom dataset')\n",
    "    parser.add_argument('--size', type=int, default=128, help='parameter for RandomResizedCrop')\n",
    "\n",
    "    # temperature\n",
    "    parser.add_argument('--temp', type=float, default=0.07,\n",
    "                        help='temperature for loss function')\n",
    "\n",
    "\n",
    "\n",
    "    opt = parser.parse_args(string)\n",
    "\n",
    "    # check if dataset is path that passed required arguments\n",
    "    if opt.dataset == 'path':\n",
    "        assert opt.data_folder is not None \\\n",
    "               and opt.mean is not None \\\n",
    "               and opt.std is not None\n",
    "\n",
    "    # set the path according to the environment\n",
    "    if opt.data_folder is None:\n",
    "        opt.data_folder = './datasets/'\n",
    "    opt.model_path = './save/{}_models'.format(opt.dataset)\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_lr_{}_decay_{}_bsz_{}_temp_{}'. \\\n",
    "        format(opt.model, opt.learning_rate,\n",
    "               opt.weight_decay, opt.batch_size, opt.temp)\n",
    "\n",
    "\n",
    "    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.save_folder):\n",
    "        os.makedirs(opt.save_folder)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef86f818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.913424Z",
     "iopub.status.busy": "2023-09-05T15:23:36.913144Z",
     "iopub.status.idle": "2023-09-05T15:23:36.937736Z",
     "shell.execute_reply": "2023-09-05T15:23:36.936896Z"
    },
    "papermill": {
     "duration": 0.042781,
     "end_time": "2023-09-05T15:23:36.939850",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.897069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.losses import NTXentLoss\n",
    "ss_loss_func = NTXentLoss(temperature=0.10)\n",
    "\n",
    "def train_ss(Net,projection_head,data_loader, epoch, print_freq = 10):\n",
    "    Net.train()\n",
    "    projection_head.train()\n",
    "    total_loss = AverageMeter()\n",
    "    for idx, x in enumerate(data_loader): \n",
    "        # print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        # Get data representations\n",
    "        x = x.to(device)\n",
    "        \n",
    "        A1 = augmentations(x)\n",
    "        A2 = augmentations(x)\n",
    "        \n",
    "        h1 = Net(A1)\n",
    "        z1 = projection_head(h1)\n",
    "        \n",
    "        h2 = Net(A2)\n",
    "        z2 = projection_head(h2)\n",
    "        \n",
    "        # Prepare for loss\n",
    "        embeddings = torch.cat((z1, z2))\n",
    "        # The same index corresponds to a positive pair\n",
    "        indices = torch.arange(0, z1.size(0), device=z2.device)\n",
    "        labels = torch.cat((indices, indices))\n",
    "        loss = ss_loss_func(embeddings, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.update(loss.data.item())\n",
    "        \n",
    "        # print info\n",
    "        if (idx + 1) % print_freq == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'.format(\n",
    "                epoch, idx + 1, len(data_loader)))\n",
    "            \n",
    "        del x, A1, A2\n",
    "            \n",
    "    return total_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e705bae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:36.973356Z",
     "iopub.status.busy": "2023-09-05T15:23:36.973078Z",
     "iopub.status.idle": "2023-09-05T15:23:36.983005Z",
     "shell.execute_reply": "2023-09-05T15:23:36.982140Z"
    },
    "papermill": {
     "duration": 0.027595,
     "end_time": "2023-09-05T15:23:36.984972",
     "exception": false,
     "start_time": "2023-09-05T15:23:36.957377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_supervised(train_loader, val_loader, model,criterion, optimizer, epoch, opt):\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    device = opt.device\n",
    "    end = time.time()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for idx, (image, bio_tensor) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = image.to(device)\n",
    "\n",
    "        labels = bio_tensor.float()\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # compute loss\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        predicted_labels = torch.round(torch.sigmoid(output)) \n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # print info\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'.format(\n",
    "                epoch, idx + 1, len(train_loader)))\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    total_values = len(train_loader.dataset) * 6\n",
    "    training_accuracy = (correct_predictions / total_values) * 100.0\n",
    "    print(f\"Training Accuracy: {training_accuracy:.2f}%\")\n",
    "    print(\"Training loss:\", losses.avg)\n",
    "    \n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e2ed485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.016854Z",
     "iopub.status.busy": "2023-09-05T15:23:37.016083Z",
     "iopub.status.idle": "2023-09-05T15:23:37.023735Z",
     "shell.execute_reply": "2023-09-05T15:23:37.022788Z"
    },
    "papermill": {
     "duration": 0.025736,
     "end_time": "2023-09-05T15:23:37.025908",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.000172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submission_generate(val_loader, model, opt, epoch = 'final'):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, image in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    out_submisison = np.array(out_list)\n",
    "    np.save('output',out_submisison)\n",
    "    \n",
    "    output = np.load('/kaggle/working/output.npy')\n",
    "    submission = pd.read_csv(\"/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv\")\n",
    "    submission.iloc[:, 1:] = output\n",
    "    submission.to_csv(f\"/kaggle/working/submission{epoch}.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a541cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.058086Z",
     "iopub.status.busy": "2023-09-05T15:23:37.057821Z",
     "iopub.status.idle": "2023-09-05T15:23:37.066521Z",
     "shell.execute_reply": "2023-09-05T15:23:37.065417Z"
    },
    "papermill": {
     "duration": 0.02704,
     "end_time": "2023-09-05T15:23:37.068667",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.041627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_evaluation(val_loader, model, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (image,bio_tensor) in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "            labels = bio_tensor.float().to(device)\n",
    "\n",
    "            labels = labels.float()\n",
    "\n",
    "            label_list.append(labels.squeeze().detach().cpu().numpy())\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            correct_count += (labels == output).sum().item()\n",
    "            total_count += len(labels) * 6\n",
    "        \n",
    "    print(\"Validation accuracy:\", (correct_count / total_count) * 100, \"%\")\n",
    "\n",
    "    label_array = np.array(label_list)\n",
    "    out_array = np.array(out_list)\n",
    "    f = f1_score(label_array,out_array,average='macro')\n",
    "    print(\"Validation F1:\", f)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64c730f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.100606Z",
     "iopub.status.busy": "2023-09-05T15:23:37.099867Z",
     "iopub.status.idle": "2023-09-05T15:23:37.107233Z",
     "shell.execute_reply": "2023-09-05T15:23:37.106263Z"
    },
    "papermill": {
     "duration": 0.025325,
     "end_time": "2023-09-05T15:23:37.109149",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.083824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_evaluation_acc(val_loader, model, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (image,bio_tensor) in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "            labels = bio_tensor.float().to(device)\n",
    "\n",
    "            labels = labels.float()\n",
    "\n",
    "            #label_list.append(labels.squeeze().detach().cpu().numpy())\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            #out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            correct_count += (labels == output).sum().item()\n",
    "            total_count += len(labels) * 6\n",
    "        \n",
    "    print((correct_count / total_count) * 100, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f34930a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.141390Z",
     "iopub.status.busy": "2023-09-05T15:23:37.140631Z",
     "iopub.status.idle": "2023-09-05T15:23:37.146674Z",
     "shell.execute_reply": "2023-09-05T15:23:37.145760Z"
    },
    "papermill": {
     "duration": 0.024619,
     "end_time": "2023-09-05T15:23:37.148769",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.124150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model, load_file, key = 'model'):\n",
    "    print('==> Loading...')\n",
    "    checkpoint = torch.load(load_file)\n",
    "    model.load_state_dict(checkpoint[key])\n",
    "    return model\n",
    "\n",
    "def load_model_unsupervised(net, head, load_file):\n",
    "    print('==> Loading...')\n",
    "    checkpoint = torch.load(load_file)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    head.load_state_dict(checkpoint['head'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a5577b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.181278Z",
     "iopub.status.busy": "2023-09-05T15:23:37.180497Z",
     "iopub.status.idle": "2023-09-05T15:23:37.186223Z",
     "shell.execute_reply": "2023-09-05T15:23:37.185228Z"
    },
    "papermill": {
     "duration": 0.024705,
     "end_time": "2023-09-05T15:23:37.188717",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.164012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('/kaggle/working/supervised'):\n",
    "    os.makedirs('/kaggle/working/supervised')\n",
    "if not os.path.isdir('/kaggle/working/unsupervised'):\n",
    "    os.makedirs('/kaggle/working/unsupervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fd893d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.222834Z",
     "iopub.status.busy": "2023-09-05T15:23:37.222033Z",
     "iopub.status.idle": "2023-09-05T15:23:37.230452Z",
     "shell.execute_reply": "2023-09-05T15:23:37.229593Z"
    },
    "papermill": {
     "duration": 0.026914,
     "end_time": "2023-09-05T15:23:37.232608",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.205694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = args = ['--batch_size', '64', '--model', \"resnet50\", '--dataset', 'OLIVES', '--epochs', '2', '--device', 'cuda:0', '--train_image_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TRAIN/OLIVES', '--test_image_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/', '--test_csv_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv', '--train_csv_path', '/kaggle/input/olives-training-labels/Training_Biomarker_Data.csv']\n",
    "opt = parse_option(args)\n",
    "\n",
    "# CSV paths\n",
    "csv_path_train = \"/kaggle/input/olives-training-labels/training_split_biomarker_data.csv\"\n",
    "csv_path_valid = \"/kaggle/input/olives-training-labels/validation_biomarker_data.csv\"\n",
    "csv_path_test = \"/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv\"\n",
    "csv_path_unlabelled = \"/kaggle/input/olives-training-labels/unlabelled_images.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47206f",
   "metadata": {
    "papermill": {
     "duration": 0.015671,
     "end_time": "2023-09-05T15:23:37.264067",
     "exception": false,
     "start_time": "2023-09-05T15:23:37.248396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e543fe0",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-05T15:23:37.296945Z",
     "iopub.status.busy": "2023-09-05T15:23:37.296599Z",
     "iopub.status.idle": "2023-09-05T15:23:38.764764Z",
     "shell.execute_reply": "2023-09-05T15:23:38.762121Z"
    },
    "papermill": {
     "duration": 1.486638,
     "end_time": "2023-09-05T15:23:38.766649",
     "exception": true,
     "start_time": "2023-09-05T15:23:37.280011",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m unlabel_seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1231\u001b[39m\n\u001b[1;32m      4\u001b[0m opt\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 5\u001b[0m train_loader, val_loader, test_loader, unlabelled_train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mset_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m unlabelled_train_loader \u001b[38;5;241m=\u001b[39m set_unlabel_loader(opt, unlabel_seed, unlabel_count)\n",
      "Cell \u001b[0;32mIn[8], line 91\u001b[0m, in \u001b[0;36mset_loader\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     89\u001b[0m unlabelled_train_dataset \u001b[38;5;241m=\u001b[39m RECOVERY(csv_path_unlabelled,data_path_train,transforms \u001b[38;5;241m=\u001b[39m val_transform)\n\u001b[1;32m     90\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m OLIVES(csv_path_valid,data_path_train,transforms \u001b[38;5;241m=\u001b[39m val_transform)\n\u001b[0;32m---> 91\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mRECOVERY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_path_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Create a random sampler for the subset\u001b[39;00m\n\u001b[1;32m     94\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(unlabel_seed)\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mRECOVERY.__init__\u001b[0;34m(self, df, img_dir, transforms)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir \u001b[38;5;241m=\u001b[39m img_dir\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv'"
     ]
    }
   ],
   "source": [
    "# build data loader\n",
    "unlabel_count = 20000\n",
    "unlabel_seed = 1231\n",
    "opt.batch_size = 64\n",
    "train_loader, val_loader, test_loader, unlabelled_train_loader = set_loader(opt)\n",
    "unlabelled_train_loader = set_unlabel_loader(opt, unlabel_seed, unlabel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2218dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(unlabelled_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ef3c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### UNSUPERVISED LEARNING PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de71f5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda:0\" )\n",
    "Net = Encdr().to(device)\n",
    "projection_head = Prj_Head(512,128).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(Net.parameters())+list(projection_head.parameters()), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "#train(Net,projection_head,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98da79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_epoch = 0\n",
    "loss_list = []\n",
    "best_loss = 10000\n",
    "save_file = os.path.join(opt.save_folder + 'models', 'last.pth')\n",
    "#save_model(model, optimizer, opt, opt.epochs, save_file)\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    loss = train_ss(Net,projection_head,unlabelled_train_loader, epoch, print_freq = 50)\n",
    "    print(f'Epoch {epoch:3d}, Loss: {loss:.4f}')\n",
    "    scheduler.step()\n",
    "    loss_list.append(loss)\n",
    "    if loss<best_loss:\n",
    "        best_loss = loss\n",
    "        #torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_best_loss.pth.tar') \n",
    "        save_model_unsupervised(Net, projection_head, '/kaggle/working/unsupervised/best_loss.pth')\n",
    "    if epoch % 10 == 0:\n",
    "        #best_loss = loss\n",
    "        #torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_checkpoint.pth.tar') \n",
    "        save_model_unsupervised(Net, projection_head, f'/kaggle/working/unsupervised/epoch{epoch}.pth')\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        unlabelled_train_loader = set_unlabel_loader(opt, np.random.randint(1, 100000), unlabel_count)\n",
    "        print(\"Dataset changed, indices =\", unlabelled_train_loader.sampler.indices)\n",
    "        \n",
    "#torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_final_checkpoint.pth.tar') \n",
    "plt.figure()\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b016164",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43026777",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d847ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155cd8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4c02d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### SUPERVISED LEARNING PART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1de99",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If loading pretrained\n",
    "load_file = \"/kaggle/input/models/epoch90.pth\"  # change to model path\n",
    "device = torch.device(\"cuda:0\" )\n",
    "Net = Encdr().to(device)\n",
    "Net = load_model(Net, load_file, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3516c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Net.add_feature()\n",
    "model, criterion = set_model_st(opt, Net)    \n",
    "optimizer = set_optimizer(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0bf84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To check performance without the pre training\n",
    "#model, criterion = set_model(opt)    \n",
    "#optimizer = set_optimizer(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50508410",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01240143",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training routine with freezing\n",
    "#model[0].requires_grad_(False)\n",
    "#opt.learning_rate = 0.05\n",
    "#for epoch in range(1, 15+1):\n",
    "#    train_supervised(train_loader, val_loader, model, criterion, optimizer, epoch, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483b29e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training routine without freezing\n",
    "model[0].requires_grad_(True)\n",
    "opt.learning_rate = 0.005\n",
    "\n",
    "best_f1 = 0.50\n",
    "for epoch in range(1, 80+1):\n",
    "    train_supervised(train_loader, val_loader, model, criterion, optimizer, epoch, opt)\n",
    "    cur_f1 = sample_evaluation(val_loader, model, opt)\n",
    "    if cur_f1 > best_f1:\n",
    "        #best_f1 = cur_f1\n",
    "        submission_generate(test_loader, model, opt, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        submission_generate(test_loader, model, opt, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b1410",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_file = os.path.join('/kaggle/working/supervised/last.pth')\n",
    "save_model(model, optimizer, opt, opt.epochs, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e397b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "sample_evaluation(val_loader, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7419",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_generate(test_loader, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d0aaa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f164b00",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc36946",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e662b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3c1e2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26598f1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee5579",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7dde7e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d62925",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b879da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7970e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea685d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec4200",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43277a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c1466",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.463724,
   "end_time": "2023-09-05T15:23:40.506722",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-05T15:23:08.042998",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
