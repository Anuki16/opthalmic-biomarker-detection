{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56588035",
   "metadata": {
    "papermill": {
     "duration": 0.015235,
     "end_time": "2023-08-27T06:16:16.612921",
     "exception": false,
     "start_time": "2023-08-27T06:16:16.597686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585e1430",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:16.641911Z",
     "iopub.status.busy": "2023-08-27T06:16:16.641142Z",
     "iopub.status.idle": "2023-08-27T06:16:17.704003Z",
     "shell.execute_reply": "2023-08-27T06:16:17.702981Z"
    },
    "papermill": {
     "duration": 1.079795,
     "end_time": "2023-08-27T06:16:17.706126",
     "exception": false,
     "start_time": "2023-08-27T06:16:16.626331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "'''\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef38e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:17.736135Z",
     "iopub.status.busy": "2023-08-27T06:16:17.734512Z",
     "iopub.status.idle": "2023-08-27T06:16:31.018639Z",
     "shell.execute_reply": "2023-08-27T06:16:31.017456Z"
    },
    "papermill": {
     "duration": 13.301242,
     "end_time": "2023-08-27T06:16:31.021083",
     "exception": false,
     "start_time": "2023-08-27T06:16:17.719841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-metric-learning\r\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (1.23.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (1.2.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-metric-learning) (2.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (1.11.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\r\n",
      "Installing collected packages: pytorch-metric-learning\r\n",
      "Successfully installed pytorch-metric-learning-2.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdecc7fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:31.051872Z",
     "iopub.status.busy": "2023-08-27T06:16:31.051543Z",
     "iopub.status.idle": "2023-08-27T06:16:34.719234Z",
     "shell.execute_reply": "2023-08-27T06:16:34.718252Z"
    },
    "papermill": {
     "duration": 3.685781,
     "end_time": "2023-08-27T06:16:34.721623",
     "exception": false,
     "start_time": "2023-08-27T06:16:31.035842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"encoder + classifier\"\"\"\n",
    "    def __init__(self, name='resnet50', num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        if (name == 'resnet50'):\n",
    "            self.encoder = torchvision.models.resnet50(zero_init_residual=True)\n",
    "            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            self.encoder.fc = nn.Identity()\n",
    "            self.fc = nn.Linear(2048, num_classes)\n",
    "        else:\n",
    "            self.encoder = torchvision.models.resnet18(zero_init_residual=True)\n",
    "            self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            self.encoder.fc = nn.Identity()\n",
    "            self.fc = nn.Linear(512, num_classes)\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.fc(self.encoder(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55a02fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:34.753817Z",
     "iopub.status.busy": "2023-08-27T06:16:34.752801Z",
     "iopub.status.idle": "2023-08-27T06:16:34.760756Z",
     "shell.execute_reply": "2023-08-27T06:16:34.759841Z"
    },
    "papermill": {
     "duration": 0.026525,
     "end_time": "2023-08-27T06:16:34.762793",
     "exception": false,
     "start_time": "2023-08-27T06:16:34.736268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Prj_Head(nn.Module):\n",
    "    def __init__(self,in_dim,feature_dim):\n",
    "        super(Prj_Head, self).__init__()\n",
    "        \n",
    "        self.g1 = nn.Sequential(nn.Linear(in_dim, 1024, bias=False),\n",
    "                               nn.BatchNorm1d(1024),\n",
    "                               nn.ReLU(inplace=True)\n",
    "                               )\n",
    "        self.g2 = nn.Sequential(nn.Linear(1024, 512, bias=False),\n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.ReLU(inplace=True)\n",
    "                                )\n",
    "        self.g3=nn.Linear(512, feature_dim, bias=True)\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=- 1) \n",
    "        x = self.g1(x)\n",
    "        x = self.g2(x)\n",
    "        x = self.g3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03511d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:34.793106Z",
     "iopub.status.busy": "2023-08-27T06:16:34.792255Z",
     "iopub.status.idle": "2023-08-27T06:16:34.799902Z",
     "shell.execute_reply": "2023-08-27T06:16:34.799069Z"
    },
    "papermill": {
     "duration": 0.025035,
     "end_time": "2023-08-27T06:16:34.801940",
     "exception": false,
     "start_time": "2023-08-27T06:16:34.776905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encdr(nn.Module):\n",
    "    \"\"\"encoder + classifier\"\"\"\n",
    "    def __init__(self, name='resnet50', num_classes=2):\n",
    "        super(Encdr, self).__init__()\n",
    "        self.encoder = torchvision.models.resnet50(pretrained=True, zero_init_residual=True)\n",
    "        self.encoder.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.fc = nn.Linear(2048, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.fc(self.encoder(x))\n",
    "    \n",
    "    def add_feature(self):\n",
    "        self.fc1=nn.Linear(512,2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23bff34e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:34.831349Z",
     "iopub.status.busy": "2023-08-27T06:16:34.831084Z",
     "iopub.status.idle": "2023-08-27T06:16:34.846561Z",
     "shell.execute_reply": "2023-08-27T06:16:34.845537Z"
    },
    "papermill": {
     "duration": 0.032878,
     "end_time": "2023-08-27T06:16:34.848845",
     "exception": false,
     "start_time": "2023-08-27T06:16:34.815967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets.py\n",
    "\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class OLIVES(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        b1 = self.df.iloc[idx,1]\n",
    "        b2 = self.df.iloc[idx,2]\n",
    "        b3 = self.df.iloc[idx,3]\n",
    "        b4 = self.df.iloc[idx, 4]\n",
    "        b5 = self.df.iloc[idx, 5]\n",
    "        b6 = self.df.iloc[idx, 6]\n",
    "        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n",
    "        return image, bio_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RECOVERY(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "class RECOVERY_TEST(data.Dataset):\n",
    "    def __init__(self,df, img_dir, transforms):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(df)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_dir + self.df.iloc[idx,0]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        image = np.array(image)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transforms(image)\n",
    "        b1 = self.df.iloc[idx,1]\n",
    "        b2 = self.df.iloc[idx,2]\n",
    "        b3 = self.df.iloc[idx,3]\n",
    "        b4 = self.df.iloc[idx, 4]\n",
    "        b5 = self.df.iloc[idx, 5]\n",
    "        b6 = self.df.iloc[idx, 6]\n",
    "        bio_tensor = torch.tensor([b1, b2, b3, b4, b5, b6])\n",
    "        return image, bio_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690c7115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:34.878091Z",
     "iopub.status.busy": "2023-08-27T06:16:34.877811Z",
     "iopub.status.idle": "2023-08-27T06:16:34.888736Z",
     "shell.execute_reply": "2023-08-27T06:16:34.887909Z"
    },
    "papermill": {
     "duration": 0.027723,
     "end_time": "2023-08-27T06:16:34.890630",
     "exception": false,
     "start_time": "2023-08-27T06:16:34.862907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def combine_excel(csv_dir):\n",
    "    filenames = glob.glob(csv_dir + \"/*.xlsx\")\n",
    "    outputxlsx = pd.DataFrame()\n",
    "\n",
    "    for file in filenames:\n",
    "        df = pd.concat(pd.read_excel(file, sheet_name=None), ignore_index=True, sort=False)\n",
    "        outputxlsx = outputxlsx.append(df, ignore_index=True)\n",
    "\n",
    "    outputxlsx.to_csv('test_set_labels.csv',index=False)\n",
    "\n",
    "def analyze_dataframe(csv_dir):\n",
    "    pass\n",
    "\n",
    "def process_images(csv_dir):\n",
    "    df = pd.read_csv(csv_dir)\n",
    "\n",
    "    for i in tqdm(range(0,len(df))):\n",
    "        path = df.iloc[i,0]\n",
    "        im = Image.open(path).convert('L')\n",
    "\n",
    "\n",
    "def numpy_submission(sub_dir,np_dir):\n",
    "    np_file  = np.load(np_dir)\n",
    "    print(len(np_file))\n",
    "    sub_dir = pd.read_csv(sub_dir)\n",
    "    print(len(sub_dir))\n",
    "    for i in range(0,len(sub_dir)):\n",
    "        sub_dir.iloc[i,1] = np_file[i,0]\n",
    "        sub_dir.iloc[i, 2] = np_file[i, 1]\n",
    "        sub_dir.iloc[i, 3] = np_file[i, 2]\n",
    "        sub_dir.iloc[i, 4] = np_file[i, 3]\n",
    "        sub_dir.iloc[i, 5] = np_file[i, 4]\n",
    "        sub_dir.iloc[i, 6] = np_file[i, 5]\n",
    "    print(sub_dir.head())\n",
    "    sub_dir.to_csv('baseline_result.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "    #process_images(csv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fefa9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:34.920811Z",
     "iopub.status.busy": "2023-08-27T06:16:34.920549Z",
     "iopub.status.idle": "2023-08-27T06:16:34.951681Z",
     "shell.execute_reply": "2023-08-27T06:16:34.950848Z"
    },
    "papermill": {
     "duration": 0.048509,
     "end_time": "2023-08-27T06:16:34.953762",
     "exception": false,
     "start_time": "2023-08-27T06:16:34.905253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import random_split, Subset, SubsetRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "def set_model(opt, freeze = False):\n",
    "\n",
    "\n",
    "    device = opt.device\n",
    "    model = ResNet(name=opt.model,num_classes = opt.ncls)\n",
    "    if freeze:\n",
    "        model.encoder.requires_grad_(False)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "# model for self supervised training\n",
    "\n",
    "def set_model_st(opt,Net):\n",
    "\n",
    "\n",
    "    device = opt.device\n",
    "    #model = Encdr(name=opt.model,num_classes = opt.ncls)\n",
    "    model = nn.Sequential(\n",
    "    Net, \n",
    "    nn.Linear(512, 1024, bias=False),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(1024, 512, bias=False),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 6, bias=True))\n",
    "    \n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    return model, criterion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_loader(opt):\n",
    "    # construct data loader\n",
    "    if opt.dataset == 'OLIVES' or opt.dataset == 'RECOVERY':\n",
    "        mean = (.1706)\n",
    "        std = (.2112)\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=224, scale=(0.85, 1.)),\n",
    "        transforms.RandomRotation(30), \n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "\n",
    "    if opt.dataset =='OLIVES':\n",
    "        data_path_train = opt.train_image_path\n",
    "        data_path_test = opt.test_image_path\n",
    "        train_dataset = OLIVES(csv_path_train,data_path_train,transforms = train_transform)\n",
    "        unlabelled_train_dataset = RECOVERY(csv_path_unlabelled,data_path_train,transforms = val_transform)\n",
    "        val_dataset = OLIVES(csv_path_valid,data_path_train,transforms = val_transform)\n",
    "        test_dataset = RECOVERY(csv_path_test,data_path_test,transforms = val_transform)\n",
    "        \n",
    "        # Create a random sampler for the subset\n",
    "        np.random.seed(unlabel_seed)\n",
    "        random_indices = np.random.choice(len(unlabelled_train_dataset), unlabel_count, replace=False)\n",
    "        subset_sampler = SubsetRandomSampler(random_indices)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(opt.dataset)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=opt.batch_size, shuffle=True,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=True,drop_last=False)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=True,drop_last=False)\n",
    "    \n",
    "    unlabelled_train_loader = torch.utils.data.DataLoader(unlabelled_train_dataset,\n",
    "        sampler=subset_sampler, batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, unlabelled_train_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def adjust_learning_rate(args, optimizer, epoch):\n",
    "    lr = args.learning_rate\n",
    "    if args.cosine:\n",
    "        eta_min = lr * (args.lr_decay_rate ** 3)\n",
    "        lr = eta_min + (lr - eta_min) * (\n",
    "                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n",
    "    else:\n",
    "        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n",
    "        if steps > 0:\n",
    "            lr = lr * (args.lr_decay_rate ** steps)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n",
    "    if args.warm and epoch <= args.warm_epochs:\n",
    "        p = (batch_id + (epoch - 1) * total_batches) / \\\n",
    "            (args.warm_epochs * total_batches)\n",
    "        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def set_optimizer(opt, model):\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=opt.learning_rate,\n",
    "                          momentum=opt.momentum,\n",
    "                          weight_decay=opt.weight_decay)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=opt.learning_rate)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, opt, epoch, save_file):\n",
    "    print('==> Saving...')\n",
    "    state = {\n",
    "        'opt': opt,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(state, save_file)\n",
    "    del state\n",
    "    \n",
    "def save_model_unsupervised(net, projection_head, save_file):\n",
    "    print('==> Saving...')\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'head': projection_head.state_dict()\n",
    "    }\n",
    "    torch.save(state, save_file)\n",
    "    del state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb86980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:34.983717Z",
     "iopub.status.busy": "2023-08-27T06:16:34.983423Z",
     "iopub.status.idle": "2023-08-27T06:16:34.991448Z",
     "shell.execute_reply": "2023-08-27T06:16:34.990402Z"
    },
    "papermill": {
     "duration": 0.025547,
     "end_time": "2023-08-27T06:16:34.993457",
     "exception": false,
     "start_time": "2023-08-27T06:16:34.967910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def set_unlabel_loader(opt, unlabel_seed, unlabel_count):\n",
    "    # construct data loader\n",
    "    mean = (.1706)\n",
    "    std = (.2112)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    data_path_train = opt.train_image_path\n",
    "    data_path_test = opt.test_image_path\n",
    "    \n",
    "    unlabelled_train_dataset = RECOVERY(csv_path_unlabelled,data_path_train,transforms = val_transform)\n",
    "    test_dataset = RECOVERY(csv_path_test,data_path_test,transforms = val_transform)\n",
    "    \n",
    "    full_dataset = torch.utils.data.ConcatDataset([unlabelled_train_dataset, test_dataset])\n",
    "\n",
    "    # Create a random sampler for the subset\n",
    "    np.random.seed(unlabel_seed)\n",
    "    random_indices = np.random.choice(len(full_dataset), unlabel_count, replace=False)\n",
    "    subset_sampler = SubsetRandomSampler(random_indices)\n",
    "    \n",
    "    unlabelled_train_loader = torch.utils.data.DataLoader(full_dataset,\n",
    "        sampler=subset_sampler, batch_size=opt.batch_size,\n",
    "        num_workers=opt.num_workers, pin_memory=True)\n",
    "\n",
    "    return unlabelled_train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88ab43d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.022673Z",
     "iopub.status.busy": "2023-08-27T06:16:35.022406Z",
     "iopub.status.idle": "2023-08-27T06:16:35.029995Z",
     "shell.execute_reply": "2023-08-27T06:16:35.029011Z"
    },
    "papermill": {
     "duration": 0.024247,
     "end_time": "2023-08-27T06:16:35.031780",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.007533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "class Noise(object):\n",
    "    def __init__(self, amount=0.3, brightness=0.2):\n",
    "        self.noise = 200\n",
    "        self.amount = amount\n",
    "        self.brightness = brightness\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dark_region_indices = torch.where(x < self.brightness)\n",
    "        dark_region_coords = torch.stack(dark_region_indices, dim=-1)\n",
    "\n",
    "        # Randomly select pixels from dark regions for adding noise\n",
    "        pixels = torch.randint(0, int(self.amount * 224 * 224), size=(1,))\n",
    "        selected_coords = dark_region_coords[torch.randperm(dark_region_coords.size(0))[:pixels]]\n",
    "\n",
    "        image = x.clone()\n",
    "        # Add salt noise (white pixels)\n",
    "        noise = np.random.randint(self.noise, 250)\n",
    "        image[selected_coords[:, 0], selected_coords[:, 1], selected_coords[:, 2]] = noise\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c07887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.061346Z",
     "iopub.status.busy": "2023-08-27T06:16:35.060828Z",
     "iopub.status.idle": "2023-08-27T06:16:35.093646Z",
     "shell.execute_reply": "2023-08-27T06:16:35.092813Z"
    },
    "papermill": {
     "duration": 0.049727,
     "end_time": "2023-08-27T06:16:35.095647",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.045920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([86])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 112, size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9329d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.125068Z",
     "iopub.status.busy": "2023-08-27T06:16:35.124788Z",
     "iopub.status.idle": "2023-08-27T06:16:35.139777Z",
     "shell.execute_reply": "2023-08-27T06:16:35.138747Z"
    },
    "papermill": {
     "duration": 0.032028,
     "end_time": "2023-08-27T06:16:35.141674",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.109646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.85, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      "    RandomApply(\n",
      "    p=0.3\n",
      "    ColorJitter(brightness=(0.76, 1.24), contrast=(0.76, 1.24), saturation=(0.76, 1.24), hue=(-0.06, 0.06))\n",
      ")\n",
      "    RandomApply(\n",
      "    p=0.5\n",
      "    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.2))\n",
      ")\n",
      "    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
      "    <__main__.Noise object at 0x7b83a73e84f0>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------------------------\n",
    "# Augmentations\n",
    "from torchvision import transforms\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "    \"\"\"Borrowed from MoCo implementation\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x\n",
    "    \n",
    "class FixedRandomRotation:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "    def __init__(self, angles):\n",
    "        self.angles = angles\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = random.choice(self.angles)\n",
    "        return transforms.functional.rotate(x, angle)\n",
    "    \n",
    "def torchvision_transforms(eval=False, aug=None):\n",
    "\n",
    "    trans = []\n",
    "\n",
    "    if aug[\"resize\"]:\n",
    "        trans.append(transforms.Resize(aug[\"resize\"]))\n",
    "\n",
    "    if aug[\"randcrop\"] and aug[\"scale\"] and not eval:\n",
    "        trans.append(transforms.RandomResizedCrop(aug[\"randcrop\"], scale=aug[\"scale\"]))\n",
    "\n",
    "    if aug[\"randcrop\"] and eval:\n",
    "        trans.append(transforms.CenterCrop(aug[\"randcrop\"]))\n",
    "\n",
    "    if aug[\"flip\"] and not eval:\n",
    "        trans.append(transforms.RandomHorizontalFlip(p=0.5))\n",
    "        trans.append(transforms.RandomVerticalFlip(p=0.5))\n",
    "\n",
    "    if aug[\"jitter_d\"] and not eval:\n",
    "        trans.append(transforms.RandomApply(\n",
    "            [transforms.ColorJitter(0.8*aug[\"jitter_d\"], 0.8*aug[\"jitter_d\"], 0.8*aug[\"jitter_d\"], 0.2*aug[\"jitter_d\"])],\n",
    "             p=aug[\"jitter_p\"]))\n",
    "\n",
    "    if aug[\"gaussian_blur\"] and not eval:\n",
    "        trans.append(transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1,.2))], p=aug[\"gaussian_blur\"]))\n",
    "\n",
    "    if aug[\"rotation\"] and not eval:\n",
    "        # rotation_transform = FixedRandomRotation(angles=[0, 90, 180, 270])\n",
    "        trans.append(transforms.RandomRotation(30))\n",
    "\n",
    "    trans.append(Noise())\n",
    "\n",
    "    trans = transforms.Compose(trans)\n",
    "   \n",
    "    return trans\n",
    "aug = {\"resize\":0,\n",
    "    \"randcrop\":224,\n",
    "      \"scale\": (0.85, 1.0),\n",
    "      \"flip\":0,\n",
    "      \"jitter_d\":0.3,\n",
    "       \"jitter_p\":0.3,\n",
    "       \"gaussian_blur\":0.5,\n",
    "       \"rotation\":1\n",
    "      }\n",
    "augmentations = torchvision_transforms(aug = aug)\n",
    "print(augmentations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae17ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.171790Z",
     "iopub.status.busy": "2023-08-27T06:16:35.171171Z",
     "iopub.status.idle": "2023-08-27T06:16:35.188413Z",
     "shell.execute_reply": "2023-08-27T06:16:35.187359Z"
    },
    "papermill": {
     "duration": 0.034805,
     "end_time": "2023-08-27T06:16:35.190578",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.155773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "\n",
    "def parse_option(string):\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=8,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "    parser.add_argument('--device', type=str, default='cuda:0')\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.05,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--patient_lambda', type=float, default=1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--cluster_lambda', type=float, default=1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='100',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--train_csv_path', type=str, default='train data csv')\n",
    "    parser.add_argument('--test_csv_path', type=str, default='test data csv')\n",
    "    parser.add_argument('--train_image_path', type=str, default='train data csv')\n",
    "    parser.add_argument('--test_image_path', type=str, default='test data csv')\n",
    "\n",
    "    parser.add_argument('--parallel', type=int, default=1, help='data parallel')\n",
    "    parser.add_argument('--ncls', type=int, default=6, help='Number of Classes')\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='TREX_DME',\n",
    "                        choices=[ 'OLIVES'], help='dataset')\n",
    "    parser.add_argument('--mean', type=str, help='mean of dataset in path in form of str tuple')\n",
    "    parser.add_argument('--std', type=str, help='std of dataset in path in form of str tuple')\n",
    "    parser.add_argument('--data_folder', type=str, default=None, help='path to custom dataset')\n",
    "    parser.add_argument('--size', type=int, default=128, help='parameter for RandomResizedCrop')\n",
    "\n",
    "    # temperature\n",
    "    parser.add_argument('--temp', type=float, default=0.07,\n",
    "                        help='temperature for loss function')\n",
    "\n",
    "\n",
    "\n",
    "    opt = parser.parse_args(string)\n",
    "\n",
    "    # check if dataset is path that passed required arguments\n",
    "    if opt.dataset == 'path':\n",
    "        assert opt.data_folder is not None \\\n",
    "               and opt.mean is not None \\\n",
    "               and opt.std is not None\n",
    "\n",
    "    # set the path according to the environment\n",
    "    if opt.data_folder is None:\n",
    "        opt.data_folder = './datasets/'\n",
    "    opt.model_path = './save/{}_models'.format(opt.dataset)\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_lr_{}_decay_{}_bsz_{}_temp_{}'. \\\n",
    "        format(opt.model, opt.learning_rate,\n",
    "               opt.weight_decay, opt.batch_size, opt.temp)\n",
    "\n",
    "\n",
    "    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.save_folder):\n",
    "        os.makedirs(opt.save_folder)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030f9db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.220371Z",
     "iopub.status.busy": "2023-08-27T06:16:35.220100Z",
     "iopub.status.idle": "2023-08-27T06:16:35.245428Z",
     "shell.execute_reply": "2023-08-27T06:16:35.244516Z"
    },
    "papermill": {
     "duration": 0.042725,
     "end_time": "2023-08-27T06:16:35.247695",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.204970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.losses import NTXentLoss\n",
    "ss_loss_func = NTXentLoss(temperature=0.10)\n",
    "\n",
    "def train_ss(Net,projection_head,data_loader, epoch, print_freq = 10):\n",
    "    Net.train()\n",
    "    projection_head.train()\n",
    "    total_loss = AverageMeter()\n",
    "    for idx, x in enumerate(data_loader): \n",
    "        # print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        # Get data representations\n",
    "        x = x.to(device)\n",
    "        \n",
    "        A1 = augmentations(x)\n",
    "        A2 = augmentations(x)\n",
    "        \n",
    "        h1 = Net(A1)\n",
    "        z1 = projection_head(h1)\n",
    "        \n",
    "        h2 = Net(A2)\n",
    "        z2 = projection_head(h2)\n",
    "        \n",
    "        # Prepare for loss\n",
    "        embeddings = torch.cat((z1, z2))\n",
    "        # The same index corresponds to a positive pair\n",
    "        indices = torch.arange(0, z1.size(0), device=z2.device)\n",
    "        labels = torch.cat((indices, indices))\n",
    "        loss = ss_loss_func(embeddings, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.update(loss.data.item())\n",
    "        \n",
    "        # print info\n",
    "        if (idx + 1) % print_freq == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'.format(\n",
    "                epoch, idx + 1, len(data_loader)))\n",
    "            \n",
    "        del x, A1, A2\n",
    "            \n",
    "    return total_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06022dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.278189Z",
     "iopub.status.busy": "2023-08-27T06:16:35.277419Z",
     "iopub.status.idle": "2023-08-27T06:16:35.288096Z",
     "shell.execute_reply": "2023-08-27T06:16:35.287265Z"
    },
    "papermill": {
     "duration": 0.027692,
     "end_time": "2023-08-27T06:16:35.290049",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.262357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_supervised(train_loader, val_loader, model,criterion, optimizer, epoch, opt):\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    device = opt.device\n",
    "    end = time.time()\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for idx, (image, bio_tensor) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = image.to(device)\n",
    "\n",
    "        labels = bio_tensor.float()\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # compute loss\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        predicted_labels = torch.round(torch.sigmoid(output)) \n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # print info\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print('Train: [{0}][{1}/{2}]\\t'.format(\n",
    "                epoch, idx + 1, len(train_loader)))\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    total_values = len(train_loader.dataset) * 6\n",
    "    training_accuracy = (correct_predictions / total_values) * 100.0\n",
    "    print(f\"Training Accuracy: {training_accuracy:.2f}%\")\n",
    "    print(\"Training loss:\", losses.avg)\n",
    "    \n",
    "    return losses.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0917cdc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.320134Z",
     "iopub.status.busy": "2023-08-27T06:16:35.319280Z",
     "iopub.status.idle": "2023-08-27T06:16:35.327070Z",
     "shell.execute_reply": "2023-08-27T06:16:35.326101Z"
    },
    "papermill": {
     "duration": 0.024734,
     "end_time": "2023-08-27T06:16:35.329000",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.304266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submission_generate(val_loader, model, opt, epoch = 'final'):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, image in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    out_submisison = np.array(out_list)\n",
    "    np.save('output',out_submisison)\n",
    "    \n",
    "    output = np.load('/kaggle/working/output.npy')\n",
    "    submission = pd.read_csv(\"/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv\")\n",
    "    submission.iloc[:, 1:] = output\n",
    "    submission.to_csv(f\"/kaggle/working/submission{epoch}.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "944faa33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.359077Z",
     "iopub.status.busy": "2023-08-27T06:16:35.358239Z",
     "iopub.status.idle": "2023-08-27T06:16:35.367243Z",
     "shell.execute_reply": "2023-08-27T06:16:35.366404Z"
    },
    "papermill": {
     "duration": 0.025851,
     "end_time": "2023-08-27T06:16:35.369133",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.343282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_evaluation(val_loader, model, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (image,bio_tensor) in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "            labels = bio_tensor.float().to(device)\n",
    "\n",
    "            labels = labels.float()\n",
    "\n",
    "            label_list.append(labels.squeeze().detach().cpu().numpy())\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            correct_count += (labels == output).sum().item()\n",
    "            total_count += len(labels) * 6\n",
    "        \n",
    "    print(\"Validation accuracy:\", (correct_count / total_count) * 100, \"%\")\n",
    "\n",
    "    label_array = np.array(label_list)\n",
    "    out_array = np.array(out_list)\n",
    "    f = f1_score(label_array,out_array,average='macro')\n",
    "    print(\"Validation F1:\", f)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4332d065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.399272Z",
     "iopub.status.busy": "2023-08-27T06:16:35.398455Z",
     "iopub.status.idle": "2023-08-27T06:16:35.405803Z",
     "shell.execute_reply": "2023-08-27T06:16:35.404989Z"
    },
    "papermill": {
     "duration": 0.024404,
     "end_time": "2023-08-27T06:16:35.407735",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.383331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_evaluation_acc(val_loader, model, opt):\n",
    "    \"\"\"validation\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    device = opt.device\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (image,bio_tensor) in (enumerate(val_loader)):\n",
    "\n",
    "            images = image.float().to(device)\n",
    "            labels = bio_tensor.float().to(device)\n",
    "\n",
    "            labels = labels.float()\n",
    "\n",
    "            #label_list.append(labels.squeeze().detach().cpu().numpy())\n",
    "            # forward\n",
    "            output = model(images)\n",
    "            output = torch.round(torch.sigmoid(output))\n",
    "            #out_list.append(output.squeeze().detach().cpu().numpy())\n",
    "            \n",
    "            correct_count += (labels == output).sum().item()\n",
    "            total_count += len(labels) * 6\n",
    "        \n",
    "    print((correct_count / total_count) * 100, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfffac19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.438415Z",
     "iopub.status.busy": "2023-08-27T06:16:35.437010Z",
     "iopub.status.idle": "2023-08-27T06:16:35.443124Z",
     "shell.execute_reply": "2023-08-27T06:16:35.442262Z"
    },
    "papermill": {
     "duration": 0.023069,
     "end_time": "2023-08-27T06:16:35.445034",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.421965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model, load_file, key = 'model'):\n",
    "    print('==> Loading...')\n",
    "    checkpoint = torch.load(load_file)\n",
    "    model.load_state_dict(checkpoint[key])\n",
    "    return model\n",
    "\n",
    "def load_model_unsupervised(net, head, load_file):\n",
    "    print('==> Loading...')\n",
    "    checkpoint = torch.load(load_file)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    head.load_state_dict(checkpoint['head'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004a9822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.475007Z",
     "iopub.status.busy": "2023-08-27T06:16:35.474252Z",
     "iopub.status.idle": "2023-08-27T06:16:35.479284Z",
     "shell.execute_reply": "2023-08-27T06:16:35.478446Z"
    },
    "papermill": {
     "duration": 0.022081,
     "end_time": "2023-08-27T06:16:35.481287",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.459206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('/kaggle/working/supervised'):\n",
    "    os.makedirs('/kaggle/working/supervised')\n",
    "if not os.path.isdir('/kaggle/working/unsupervised'):\n",
    "    os.makedirs('/kaggle/working/unsupervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01de8eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.511978Z",
     "iopub.status.busy": "2023-08-27T06:16:35.511112Z",
     "iopub.status.idle": "2023-08-27T06:16:35.520507Z",
     "shell.execute_reply": "2023-08-27T06:16:35.519676Z"
    },
    "papermill": {
     "duration": 0.02705,
     "end_time": "2023-08-27T06:16:35.522716",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.495666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = args = ['--batch_size', '64', '--model', \"resnet50\", '--dataset', 'OLIVES', '--epochs', '2', '--device', 'cuda:0', '--train_image_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TRAIN/OLIVES', '--test_image_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/', '--test_csv_path', '/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv', '--train_csv_path', '/kaggle/input/olives-training-labels/Training_Biomarker_Data.csv']\n",
    "opt = parse_option(args)\n",
    "\n",
    "# CSV paths\n",
    "csv_path_train = \"/kaggle/input/olives-training-labels/training_split_biomarker_data.csv\"\n",
    "csv_path_valid = \"/kaggle/input/olives-training-labels/validation_biomarker_data.csv\"\n",
    "csv_path_test = \"/kaggle/input/olives-vip-cup-2023/2023 IEEE SPS Video and Image Processing (VIP) Cup - Ophthalmic Biomarker Detection/TEST/test_set_submission_template.csv\"\n",
    "csv_path_unlabelled = \"/kaggle/input/olives-training-labels/unlabelled_images.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312f33f",
   "metadata": {
    "papermill": {
     "duration": 0.013993,
     "end_time": "2023-08-27T06:16:35.550873",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.536880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa2366d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:35.584715Z",
     "iopub.status.busy": "2023-08-27T06:16:35.583820Z",
     "iopub.status.idle": "2023-08-27T06:16:36.010178Z",
     "shell.execute_reply": "2023-08-27T06:16:36.007964Z"
    },
    "papermill": {
     "duration": 0.445109,
     "end_time": "2023-08-27T06:16:36.012831",
     "exception": false,
     "start_time": "2023-08-27T06:16:35.567722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# build data loader\n",
    "unlabel_count = 20000\n",
    "unlabel_seed = 1231\n",
    "opt.batch_size = 64\n",
    "train_loader, val_loader, test_loader, unlabelled_train_loader = set_loader(opt)\n",
    "unlabelled_train_loader = set_unlabel_loader(opt, unlabel_seed, unlabel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0acfba62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:36.045750Z",
     "iopub.status.busy": "2023-08-27T06:16:36.044164Z",
     "iopub.status.idle": "2023-08-27T06:16:36.053054Z",
     "shell.execute_reply": "2023-08-27T06:16:36.051998Z"
    },
    "papermill": {
     "duration": 0.027125,
     "end_time": "2023-08-27T06:16:36.055249",
     "exception": false,
     "start_time": "2023-08-27T06:16:36.028124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlabelled_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6734e002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:36.085635Z",
     "iopub.status.busy": "2023-08-27T06:16:36.085357Z",
     "iopub.status.idle": "2023-08-27T06:16:36.089542Z",
     "shell.execute_reply": "2023-08-27T06:16:36.088516Z"
    },
    "papermill": {
     "duration": 0.021888,
     "end_time": "2023-08-27T06:16:36.091827",
     "exception": false,
     "start_time": "2023-08-27T06:16:36.069939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### UNSUPERVISED LEARNING PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1446db5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:36.122919Z",
     "iopub.status.busy": "2023-08-27T06:16:36.122567Z",
     "iopub.status.idle": "2023-08-27T06:16:41.348684Z",
     "shell.execute_reply": "2023-08-27T06:16:41.347715Z"
    },
    "papermill": {
     "duration": 5.244586,
     "end_time": "2023-08-27T06:16:41.351159",
     "exception": false,
     "start_time": "2023-08-27T06:16:36.106573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 67.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda:0\" )\n",
    "Net = Encdr().to(device)\n",
    "projection_head = Prj_Head(512,128).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(Net.parameters())+list(projection_head.parameters()), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "#train(Net,projection_head,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5d9ee24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T06:16:41.386711Z",
     "iopub.status.busy": "2023-08-27T06:16:41.386374Z",
     "iopub.status.idle": "2023-08-27T10:38:41.568214Z",
     "shell.execute_reply": "2023-08-27T10:38:41.567157Z"
    },
    "papermill": {
     "duration": 15720.203,
     "end_time": "2023-08-27T10:38:41.571557",
     "exception": false,
     "start_time": "2023-08-27T06:16:41.368557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1][50/313]\t\n",
      "Train: [1][100/313]\t\n",
      "Train: [1][150/313]\t\n",
      "Train: [1][200/313]\t\n",
      "Train: [1][250/313]\t\n",
      "Train: [1][300/313]\t\n",
      "Epoch   1, Loss: 4.5482\n",
      "==> Saving...\n",
      "Train: [2][50/313]\t\n",
      "Train: [2][100/313]\t\n",
      "Train: [2][150/313]\t\n",
      "Train: [2][200/313]\t\n",
      "Train: [2][250/313]\t\n",
      "Train: [2][300/313]\t\n",
      "Epoch   2, Loss: 4.1480\n",
      "==> Saving...\n",
      "Train: [3][50/313]\t\n",
      "Train: [3][100/313]\t\n",
      "Train: [3][150/313]\t\n",
      "Train: [3][200/313]\t\n",
      "Train: [3][250/313]\t\n",
      "Train: [3][300/313]\t\n",
      "Epoch   3, Loss: 3.9860\n",
      "==> Saving...\n",
      "Train: [4][50/313]\t\n",
      "Train: [4][100/313]\t\n",
      "Train: [4][150/313]\t\n",
      "Train: [4][200/313]\t\n",
      "Train: [4][250/313]\t\n",
      "Train: [4][300/313]\t\n",
      "Epoch   4, Loss: 3.0918\n",
      "==> Saving...\n",
      "Train: [5][50/313]\t\n",
      "Train: [5][100/313]\t\n",
      "Train: [5][150/313]\t\n",
      "Train: [5][200/313]\t\n",
      "Train: [5][250/313]\t\n",
      "Train: [5][300/313]\t\n",
      "Epoch   5, Loss: 1.6729\n",
      "==> Saving...\n",
      "Dataset changed, indices = [110516 145986  68965 ... 118184   6527  88061]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [6][50/313]\t\n",
      "Train: [6][100/313]\t\n",
      "Train: [6][150/313]\t\n",
      "Train: [6][200/313]\t\n",
      "Train: [6][250/313]\t\n",
      "Train: [6][300/313]\t\n",
      "Epoch   6, Loss: 0.8505\n",
      "==> Saving...\n",
      "Train: [7][50/313]\t\n",
      "Train: [7][100/313]\t\n",
      "Train: [7][150/313]\t\n",
      "Train: [7][200/313]\t\n",
      "Train: [7][250/313]\t\n",
      "Train: [7][300/313]\t\n",
      "Epoch   7, Loss: 0.6215\n",
      "==> Saving...\n",
      "Train: [8][50/313]\t\n",
      "Train: [8][100/313]\t\n",
      "Train: [8][150/313]\t\n",
      "Train: [8][200/313]\t\n",
      "Train: [8][250/313]\t\n",
      "Train: [8][300/313]\t\n",
      "Epoch   8, Loss: 0.4744\n",
      "==> Saving...\n",
      "Train: [9][50/313]\t\n",
      "Train: [9][100/313]\t\n",
      "Train: [9][150/313]\t\n",
      "Train: [9][200/313]\t\n",
      "Train: [9][250/313]\t\n",
      "Train: [9][300/313]\t\n",
      "Epoch   9, Loss: 0.3831\n",
      "==> Saving...\n",
      "Train: [10][50/313]\t\n",
      "Train: [10][100/313]\t\n",
      "Train: [10][150/313]\t\n",
      "Train: [10][200/313]\t\n",
      "Train: [10][250/313]\t\n",
      "Train: [10][300/313]\t\n",
      "Epoch  10, Loss: 0.3219\n",
      "==> Saving...\n",
      "==> Saving...\n",
      "Dataset changed, indices = [120672 151355 140318 ...  92501  61615 114141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [11][50/313]\t\n",
      "Train: [11][100/313]\t\n",
      "Train: [11][150/313]\t\n",
      "Train: [11][200/313]\t\n",
      "Train: [11][250/313]\t\n",
      "Train: [11][300/313]\t\n",
      "Epoch  11, Loss: 0.2603\n",
      "==> Saving...\n",
      "Train: [12][50/313]\t\n",
      "Train: [12][100/313]\t\n",
      "Train: [12][150/313]\t\n",
      "Train: [12][200/313]\t\n",
      "Train: [12][250/313]\t\n",
      "Train: [12][300/313]\t\n",
      "Epoch  12, Loss: 0.2821\n",
      "Train: [13][50/313]\t\n",
      "Train: [13][100/313]\t\n",
      "Train: [13][150/313]\t\n",
      "Train: [13][200/313]\t\n",
      "Train: [13][250/313]\t\n",
      "Train: [13][300/313]\t\n",
      "Epoch  13, Loss: 0.2245\n",
      "==> Saving...\n",
      "Train: [14][50/313]\t\n",
      "Train: [14][100/313]\t\n",
      "Train: [14][150/313]\t\n",
      "Train: [14][200/313]\t\n",
      "Train: [14][250/313]\t\n",
      "Train: [14][300/313]\t\n",
      "Epoch  14, Loss: 0.2231\n",
      "==> Saving...\n",
      "Train: [15][50/313]\t\n",
      "Train: [15][100/313]\t\n",
      "Train: [15][150/313]\t\n",
      "Train: [15][200/313]\t\n",
      "Train: [15][250/313]\t\n",
      "Train: [15][300/313]\t\n",
      "Epoch  15, Loss: 0.1920\n",
      "==> Saving...\n",
      "Dataset changed, indices = [107003 107557 107710 ...  79790  38478  68877]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [16][50/313]\t\n",
      "Train: [16][100/313]\t\n",
      "Train: [16][150/313]\t\n",
      "Train: [16][200/313]\t\n",
      "Train: [16][250/313]\t\n",
      "Train: [16][300/313]\t\n",
      "Epoch  16, Loss: 0.2182\n",
      "Train: [17][50/313]\t\n",
      "Train: [17][100/313]\t\n",
      "Train: [17][150/313]\t\n",
      "Train: [17][200/313]\t\n",
      "Train: [17][250/313]\t\n",
      "Train: [17][300/313]\t\n",
      "Epoch  17, Loss: 0.1667\n",
      "==> Saving...\n",
      "Train: [18][50/313]\t\n",
      "Train: [18][100/313]\t\n",
      "Train: [18][150/313]\t\n",
      "Train: [18][200/313]\t\n",
      "Train: [18][250/313]\t\n",
      "Train: [18][300/313]\t\n",
      "Epoch  18, Loss: 0.1936\n",
      "Train: [19][50/313]\t\n",
      "Train: [19][100/313]\t\n",
      "Train: [19][150/313]\t\n",
      "Train: [19][200/313]\t\n",
      "Train: [19][250/313]\t\n",
      "Train: [19][300/313]\t\n",
      "Epoch  19, Loss: 0.1437\n",
      "==> Saving...\n",
      "Train: [20][50/313]\t\n",
      "Train: [20][100/313]\t\n",
      "Train: [20][150/313]\t\n",
      "Train: [20][200/313]\t\n",
      "Train: [20][250/313]\t\n",
      "Train: [20][300/313]\t\n",
      "Epoch  20, Loss: 0.1288\n",
      "==> Saving...\n",
      "==> Saving...\n",
      "Dataset changed, indices = [ 18652  42803 117833 ... 140832 144561  69073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [21][50/313]\t\n",
      "Train: [21][100/313]\t\n",
      "Train: [21][150/313]\t\n",
      "Train: [21][200/313]\t\n",
      "Train: [21][250/313]\t\n",
      "Train: [21][300/313]\t\n",
      "Epoch  21, Loss: 0.1077\n",
      "==> Saving...\n",
      "Train: [22][50/313]\t\n",
      "Train: [22][100/313]\t\n",
      "Train: [22][150/313]\t\n",
      "Train: [22][200/313]\t\n",
      "Train: [22][250/313]\t\n",
      "Train: [22][300/313]\t\n",
      "Epoch  22, Loss: 0.1033\n",
      "==> Saving...\n",
      "Train: [23][50/313]\t\n",
      "Train: [23][100/313]\t\n",
      "Train: [23][150/313]\t\n",
      "Train: [23][200/313]\t\n",
      "Train: [23][250/313]\t\n",
      "Train: [23][300/313]\t\n",
      "Epoch  23, Loss: 0.1065\n",
      "Train: [24][50/313]\t\n",
      "Train: [24][100/313]\t\n",
      "Train: [24][150/313]\t\n",
      "Train: [24][200/313]\t\n",
      "Train: [24][250/313]\t\n",
      "Train: [24][300/313]\t\n",
      "Epoch  24, Loss: 0.1340\n",
      "Train: [25][50/313]\t\n",
      "Train: [25][100/313]\t\n",
      "Train: [25][150/313]\t\n",
      "Train: [25][200/313]\t\n",
      "Train: [25][250/313]\t\n",
      "Train: [25][300/313]\t\n",
      "Epoch  25, Loss: 0.1040\n",
      "Dataset changed, indices = [ 74308  81567  38810 ... 147735  72543 125353]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [26][50/313]\t\n",
      "Train: [26][100/313]\t\n",
      "Train: [26][150/313]\t\n",
      "Train: [26][200/313]\t\n",
      "Train: [26][250/313]\t\n",
      "Train: [26][300/313]\t\n",
      "Epoch  26, Loss: 0.0938\n",
      "==> Saving...\n",
      "Train: [27][50/313]\t\n",
      "Train: [27][100/313]\t\n",
      "Train: [27][150/313]\t\n",
      "Train: [27][200/313]\t\n",
      "Train: [27][250/313]\t\n",
      "Train: [27][300/313]\t\n",
      "Epoch  27, Loss: 0.0935\n",
      "==> Saving...\n",
      "Train: [28][50/313]\t\n",
      "Train: [28][100/313]\t\n",
      "Train: [28][150/313]\t\n",
      "Train: [28][200/313]\t\n",
      "Train: [28][250/313]\t\n",
      "Train: [28][300/313]\t\n",
      "Epoch  28, Loss: 0.0870\n",
      "==> Saving...\n",
      "Train: [29][50/313]\t\n",
      "Train: [29][100/313]\t\n",
      "Train: [29][150/313]\t\n",
      "Train: [29][200/313]\t\n",
      "Train: [29][250/313]\t\n",
      "Train: [29][300/313]\t\n",
      "Epoch  29, Loss: 0.0879\n",
      "Train: [30][50/313]\t\n",
      "Train: [30][100/313]\t\n",
      "Train: [30][150/313]\t\n",
      "Train: [30][200/313]\t\n",
      "Train: [30][250/313]\t\n",
      "Train: [30][300/313]\t\n",
      "Epoch  30, Loss: 0.0868\n",
      "==> Saving...\n",
      "==> Saving...\n",
      "Dataset changed, indices = [ 78581  43739   4753 ... 106216 148004  74997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [31][50/313]\t\n",
      "Train: [31][100/313]\t\n",
      "Train: [31][150/313]\t\n",
      "Train: [31][200/313]\t\n",
      "Train: [31][250/313]\t\n",
      "Train: [31][300/313]\t\n",
      "Epoch  31, Loss: 0.0911\n",
      "Train: [32][50/313]\t\n",
      "Train: [32][100/313]\t\n",
      "Train: [32][150/313]\t\n",
      "Train: [32][200/313]\t\n",
      "Train: [32][250/313]\t\n",
      "Train: [32][300/313]\t\n",
      "Epoch  32, Loss: 0.0857\n",
      "==> Saving...\n",
      "Train: [33][50/313]\t\n",
      "Train: [33][100/313]\t\n",
      "Train: [33][150/313]\t\n",
      "Train: [33][200/313]\t\n",
      "Train: [33][250/313]\t\n",
      "Train: [33][300/313]\t\n",
      "Epoch  33, Loss: 0.0970\n",
      "Train: [34][50/313]\t\n",
      "Train: [34][100/313]\t\n",
      "Train: [34][150/313]\t\n",
      "Train: [34][200/313]\t\n",
      "Train: [34][250/313]\t\n",
      "Train: [34][300/313]\t\n",
      "Epoch  34, Loss: 0.0837\n",
      "==> Saving...\n",
      "Train: [35][50/313]\t\n",
      "Train: [35][100/313]\t\n",
      "Train: [35][150/313]\t\n",
      "Train: [35][200/313]\t\n",
      "Train: [35][250/313]\t\n",
      "Train: [35][300/313]\t\n",
      "Epoch  35, Loss: 0.0782\n",
      "==> Saving...\n",
      "Dataset changed, indices = [101959  86095 114908 ... 109590 125422   3434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [36][50/313]\t\n",
      "Train: [36][100/313]\t\n",
      "Train: [36][150/313]\t\n",
      "Train: [36][200/313]\t\n",
      "Train: [36][250/313]\t\n",
      "Train: [36][300/313]\t\n",
      "Epoch  36, Loss: 0.0729\n",
      "==> Saving...\n",
      "Train: [37][50/313]\t\n",
      "Train: [37][100/313]\t\n",
      "Train: [37][150/313]\t\n",
      "Train: [37][200/313]\t\n",
      "Train: [37][250/313]\t\n",
      "Train: [37][300/313]\t\n",
      "Epoch  37, Loss: 0.0853\n",
      "Train: [38][50/313]\t\n",
      "Train: [38][100/313]\t\n",
      "Train: [38][150/313]\t\n",
      "Train: [38][200/313]\t\n",
      "Train: [38][250/313]\t\n",
      "Train: [38][300/313]\t\n",
      "Epoch  38, Loss: 0.0841\n",
      "Train: [39][50/313]\t\n",
      "Train: [39][100/313]\t\n",
      "Train: [39][150/313]\t\n",
      "Train: [39][200/313]\t\n",
      "Train: [39][250/313]\t\n",
      "Train: [39][300/313]\t\n",
      "Epoch  39, Loss: 0.1015\n",
      "Train: [40][50/313]\t\n",
      "Train: [40][100/313]\t\n",
      "Train: [40][150/313]\t\n",
      "Train: [40][200/313]\t\n",
      "Train: [40][250/313]\t\n",
      "Train: [40][300/313]\t\n",
      "Epoch  40, Loss: 0.0752\n",
      "==> Saving...\n",
      "Dataset changed, indices = [138167 141905  37643 ... 149843  35181  95055]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [41][50/313]\t\n",
      "Train: [41][100/313]\t\n",
      "Train: [41][150/313]\t\n",
      "Train: [41][200/313]\t\n",
      "Train: [41][250/313]\t\n",
      "Train: [41][300/313]\t\n",
      "Epoch  41, Loss: 0.0626\n",
      "==> Saving...\n",
      "Train: [42][50/313]\t\n",
      "Train: [42][100/313]\t\n",
      "Train: [42][150/313]\t\n",
      "Train: [42][200/313]\t\n",
      "Train: [42][250/313]\t\n",
      "Train: [42][300/313]\t\n",
      "Epoch  42, Loss: 0.0585\n",
      "==> Saving...\n",
      "Train: [43][50/313]\t\n",
      "Train: [43][100/313]\t\n",
      "Train: [43][150/313]\t\n",
      "Train: [43][200/313]\t\n",
      "Train: [43][250/313]\t\n",
      "Train: [43][300/313]\t\n",
      "Epoch  43, Loss: 0.0778\n",
      "Train: [44][50/313]\t\n",
      "Train: [44][100/313]\t\n",
      "Train: [44][150/313]\t\n",
      "Train: [44][200/313]\t\n",
      "Train: [44][250/313]\t\n",
      "Train: [44][300/313]\t\n",
      "Epoch  44, Loss: 0.0593\n",
      "Train: [45][50/313]\t\n",
      "Train: [45][100/313]\t\n",
      "Train: [45][150/313]\t\n",
      "Train: [45][200/313]\t\n",
      "Train: [45][250/313]\t\n",
      "Train: [45][300/313]\t\n",
      "Epoch  45, Loss: 0.0545\n",
      "==> Saving...\n",
      "Dataset changed, indices = [  5308 103566 110248 ...  94124  63670  63560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [46][50/313]\t\n",
      "Train: [46][100/313]\t\n",
      "Train: [46][150/313]\t\n",
      "Train: [46][200/313]\t\n",
      "Train: [46][250/313]\t\n",
      "Train: [46][300/313]\t\n",
      "Epoch  46, Loss: 0.0553\n",
      "Train: [47][50/313]\t\n",
      "Train: [47][100/313]\t\n",
      "Train: [47][150/313]\t\n",
      "Train: [47][200/313]\t\n",
      "Train: [47][250/313]\t\n",
      "Train: [47][300/313]\t\n",
      "Epoch  47, Loss: 0.0549\n",
      "Train: [48][50/313]\t\n",
      "Train: [48][100/313]\t\n",
      "Train: [48][150/313]\t\n",
      "Train: [48][200/313]\t\n",
      "Train: [48][250/313]\t\n",
      "Train: [48][300/313]\t\n",
      "Epoch  48, Loss: 0.0536\n",
      "==> Saving...\n",
      "Train: [49][50/313]\t\n",
      "Train: [49][100/313]\t\n",
      "Train: [49][150/313]\t\n",
      "Train: [49][200/313]\t\n",
      "Train: [49][250/313]\t\n",
      "Train: [49][300/313]\t\n",
      "Epoch  49, Loss: 0.0554\n",
      "Train: [50][50/313]\t\n",
      "Train: [50][100/313]\t\n",
      "Train: [50][150/313]\t\n",
      "Train: [50][200/313]\t\n",
      "Train: [50][250/313]\t\n",
      "Train: [50][300/313]\t\n",
      "Epoch  50, Loss: 0.0547\n",
      "==> Saving...\n",
      "Dataset changed, indices = [113683  62606  34779 ...  64695 113256 108965]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [51][50/313]\t\n",
      "Train: [51][100/313]\t\n",
      "Train: [51][150/313]\t\n",
      "Train: [51][200/313]\t\n",
      "Train: [51][250/313]\t\n",
      "Train: [51][300/313]\t\n",
      "Epoch  51, Loss: 0.0489\n",
      "==> Saving...\n",
      "Train: [52][50/313]\t\n",
      "Train: [52][100/313]\t\n",
      "Train: [52][150/313]\t\n",
      "Train: [52][200/313]\t\n",
      "Train: [52][250/313]\t\n",
      "Train: [52][300/313]\t\n",
      "Epoch  52, Loss: 0.0514\n",
      "Train: [53][50/313]\t\n",
      "Train: [53][100/313]\t\n",
      "Train: [53][150/313]\t\n",
      "Train: [53][200/313]\t\n",
      "Train: [53][250/313]\t\n",
      "Train: [53][300/313]\t\n",
      "Epoch  53, Loss: 0.0587\n",
      "Train: [54][50/313]\t\n",
      "Train: [54][100/313]\t\n",
      "Train: [54][150/313]\t\n",
      "Train: [54][200/313]\t\n",
      "Train: [54][250/313]\t\n",
      "Train: [54][300/313]\t\n",
      "Epoch  54, Loss: 0.0497\n",
      "Train: [55][50/313]\t\n",
      "Train: [55][100/313]\t\n",
      "Train: [55][150/313]\t\n",
      "Train: [55][200/313]\t\n",
      "Train: [55][250/313]\t\n",
      "Train: [55][300/313]\t\n",
      "Epoch  55, Loss: 0.0572\n",
      "Dataset changed, indices = [53080 99346 54806 ... 25640 75564 67222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [56][50/313]\t\n",
      "Train: [56][100/313]\t\n",
      "Train: [56][150/313]\t\n",
      "Train: [56][200/313]\t\n",
      "Train: [56][250/313]\t\n",
      "Train: [56][300/313]\t\n",
      "Epoch  56, Loss: 0.0483\n",
      "==> Saving...\n",
      "Train: [57][50/313]\t\n",
      "Train: [57][100/313]\t\n",
      "Train: [57][150/313]\t\n",
      "Train: [57][200/313]\t\n",
      "Train: [57][250/313]\t\n",
      "Train: [57][300/313]\t\n",
      "Epoch  57, Loss: 0.0436\n",
      "==> Saving...\n",
      "Train: [58][50/313]\t\n",
      "Train: [58][100/313]\t\n",
      "Train: [58][150/313]\t\n",
      "Train: [58][200/313]\t\n",
      "Train: [58][250/313]\t\n",
      "Train: [58][300/313]\t\n",
      "Epoch  58, Loss: 0.0446\n",
      "Train: [59][50/313]\t\n",
      "Train: [59][100/313]\t\n",
      "Train: [59][150/313]\t\n",
      "Train: [59][200/313]\t\n",
      "Train: [59][250/313]\t\n",
      "Train: [59][300/313]\t\n",
      "Epoch  59, Loss: 0.0414\n",
      "==> Saving...\n",
      "Train: [60][50/313]\t\n",
      "Train: [60][100/313]\t\n",
      "Train: [60][150/313]\t\n",
      "Train: [60][200/313]\t\n",
      "Train: [60][250/313]\t\n",
      "Train: [60][300/313]\t\n",
      "Epoch  60, Loss: 0.0450\n",
      "==> Saving...\n",
      "Dataset changed, indices = [152911 153011  59879 ...  32255  13534   2234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7b83a422c6d0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epoch = 60\n",
    "loss_list = []\n",
    "best_loss = 10000\n",
    "save_file = os.path.join(opt.save_folder + 'models', 'last.pth')\n",
    "#save_model(model, optimizer, opt, opt.epochs, save_file)\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    loss = train_ss(Net,projection_head,unlabelled_train_loader, epoch, print_freq = 50)\n",
    "    print(f'Epoch {epoch:3d}, Loss: {loss:.4f}')\n",
    "    scheduler.step()\n",
    "    loss_list.append(loss)\n",
    "    if loss<best_loss:\n",
    "        best_loss = loss\n",
    "        #torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_best_loss.pth.tar') \n",
    "        save_model_unsupervised(Net, projection_head, '/kaggle/working/unsupervised/best_loss.pth')\n",
    "    if epoch % 10 == 0:\n",
    "        #best_loss = loss\n",
    "        #torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_checkpoint.pth.tar') \n",
    "        save_model_unsupervised(Net, projection_head, f'/kaggle/working/unsupervised/epoch{epoch}.pth')\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        unlabelled_train_loader = set_unlabel_loader(opt, np.random.randint(1, 100000), unlabel_count)\n",
    "        print(\"Dataset changed, indices =\", unlabelled_train_loader.sampler.indices)\n",
    "        \n",
    "#torch.save(Net, f'./model_checkpoints/simclr_ki67/resnet50_ki67_dapi_chan_pretraining_final_checkpoint.pth.tar') \n",
    "plt.figure()\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7021c55",
   "metadata": {
    "papermill": {
     "duration": 0.050402,
     "end_time": "2023-08-27T10:38:41.673724",
     "exception": false,
     "start_time": "2023-08-27T10:38:41.623322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641ff0a",
   "metadata": {
    "papermill": {
     "duration": 0.049563,
     "end_time": "2023-08-27T10:38:41.772707",
     "exception": false,
     "start_time": "2023-08-27T10:38:41.723144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa8139",
   "metadata": {
    "papermill": {
     "duration": 0.049406,
     "end_time": "2023-08-27T10:38:41.871888",
     "exception": false,
     "start_time": "2023-08-27T10:38:41.822482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24596af",
   "metadata": {
    "papermill": {
     "duration": 0.048849,
     "end_time": "2023-08-27T10:38:41.969938",
     "exception": false,
     "start_time": "2023-08-27T10:38:41.921089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d391111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:42.074997Z",
     "iopub.status.busy": "2023-08-27T10:38:42.074579Z",
     "iopub.status.idle": "2023-08-27T10:38:42.079382Z",
     "shell.execute_reply": "2023-08-27T10:38:42.078326Z"
    },
    "papermill": {
     "duration": 0.061979,
     "end_time": "2023-08-27T10:38:42.081879",
     "exception": false,
     "start_time": "2023-08-27T10:38:42.019900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###### SUPERVISED LEARNING PART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "223af7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:42.181915Z",
     "iopub.status.busy": "2023-08-27T10:38:42.181622Z",
     "iopub.status.idle": "2023-08-27T10:38:48.157722Z",
     "shell.execute_reply": "2023-08-27T10:38:48.156743Z"
    },
    "papermill": {
     "duration": 6.029058,
     "end_time": "2023-08-27T10:38:48.160298",
     "exception": false,
     "start_time": "2023-08-27T10:38:42.131240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading...\n"
     ]
    }
   ],
   "source": [
    "# If loading pretrained\n",
    "load_file = \"/kaggle/input/models/pretrain_unsupervised.pth\"  # change to model path\n",
    "device = torch.device(\"cuda:0\" )\n",
    "Net = Encdr().to(device)\n",
    "Net = load_model(Net, load_file, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "990502f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:48.263109Z",
     "iopub.status.busy": "2023-08-27T10:38:48.262080Z",
     "iopub.status.idle": "2023-08-27T10:38:48.279813Z",
     "shell.execute_reply": "2023-08-27T10:38:48.278835Z"
    },
    "papermill": {
     "duration": 0.071059,
     "end_time": "2023-08-27T10:38:48.281941",
     "exception": false,
     "start_time": "2023-08-27T10:38:48.210882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Net.add_feature()\n",
    "model, criterion = set_model_st(opt, Net)    \n",
    "optimizer = set_optimizer(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3fda931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:48.382925Z",
     "iopub.status.busy": "2023-08-27T10:38:48.382612Z",
     "iopub.status.idle": "2023-08-27T10:38:48.387810Z",
     "shell.execute_reply": "2023-08-27T10:38:48.386941Z"
    },
    "papermill": {
     "duration": 0.058525,
     "end_time": "2023-08-27T10:38:48.389894",
     "exception": false,
     "start_time": "2023-08-27T10:38:48.331369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To check performance without the pre training\n",
    "#model, criterion = set_model(opt)    \n",
    "#optimizer = set_optimizer(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412b857",
   "metadata": {
    "papermill": {
     "duration": 0.050243,
     "end_time": "2023-08-27T10:38:48.489809",
     "exception": false,
     "start_time": "2023-08-27T10:38:48.439566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1485bb15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:48.591773Z",
     "iopub.status.busy": "2023-08-27T10:38:48.591360Z",
     "iopub.status.idle": "2023-08-27T10:38:48.595796Z",
     "shell.execute_reply": "2023-08-27T10:38:48.594773Z"
    },
    "papermill": {
     "duration": 0.057339,
     "end_time": "2023-08-27T10:38:48.598239",
     "exception": false,
     "start_time": "2023-08-27T10:38:48.540900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training routine with freezing\n",
    "#model[0].requires_grad_(False)\n",
    "#opt.learning_rate = 0.05\n",
    "#for epoch in range(1, 15+1):\n",
    "#    train_supervised(train_loader, val_loader, model, criterion, optimizer, epoch, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0344a21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:48.700094Z",
     "iopub.status.busy": "2023-08-27T10:38:48.699707Z",
     "iopub.status.idle": "2023-08-27T10:38:48.707205Z",
     "shell.execute_reply": "2023-08-27T10:38:48.706241Z"
    },
    "papermill": {
     "duration": 0.061105,
     "end_time": "2023-08-27T10:38:48.709287",
     "exception": false,
     "start_time": "2023-08-27T10:38:48.648182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training routine without freezing\n",
    "model[0].requires_grad_(True)\n",
    "opt.learning_rate = 0.005\n",
    "\n",
    "best_f1 = 0.50\n",
    "for epoch in range(1, 0+1):\n",
    "    train_supervised(train_loader, val_loader, model, criterion, optimizer, epoch, opt)\n",
    "    cur_f1 = sample_evaluation(val_loader, model, opt)\n",
    "    if cur_f1 > best_f1:\n",
    "        best_f1 = cur_f1\n",
    "        submission_generate(test_loader, model, opt, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        submission_generate(test_loader, model, opt, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "297c94f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:48.809380Z",
     "iopub.status.busy": "2023-08-27T10:38:48.809104Z",
     "iopub.status.idle": "2023-08-27T10:38:48.999156Z",
     "shell.execute_reply": "2023-08-27T10:38:48.998018Z"
    },
    "papermill": {
     "duration": 0.242755,
     "end_time": "2023-08-27T10:38:49.001800",
     "exception": false,
     "start_time": "2023-08-27T10:38:48.759045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving...\n"
     ]
    }
   ],
   "source": [
    "save_file = os.path.join('/kaggle/working/supervised/last.pth')\n",
    "save_model(model, optimizer, opt, opt.epochs, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a11e0010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:49.106406Z",
     "iopub.status.busy": "2023-08-27T10:38:49.105835Z",
     "iopub.status.idle": "2023-08-27T10:38:57.147245Z",
     "shell.execute_reply": "2023-08-27T10:38:57.146258Z"
    },
    "papermill": {
     "duration": 8.094684,
     "end_time": "2023-08-27T10:38:57.149235",
     "exception": false,
     "start_time": "2023-08-27T10:38:49.054551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.49659863945578 %\n",
      "Validation F1: 0.14034180630637264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14034180630637264"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "sample_evaluation(val_loader, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce1d4fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T10:38:57.253444Z",
     "iopub.status.busy": "2023-08-27T10:38:57.251450Z",
     "iopub.status.idle": "2023-08-27T10:39:57.820992Z",
     "shell.execute_reply": "2023-08-27T10:39:57.819994Z"
    },
    "papermill": {
     "duration": 60.623339,
     "end_time": "2023-08-27T10:39:57.823600",
     "exception": false,
     "start_time": "2023-08-27T10:38:57.200261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_generate(test_loader, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca11086",
   "metadata": {
    "papermill": {
     "duration": 0.049983,
     "end_time": "2023-08-27T10:39:57.924460",
     "exception": false,
     "start_time": "2023-08-27T10:39:57.874477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721ebcb",
   "metadata": {
    "papermill": {
     "duration": 0.049862,
     "end_time": "2023-08-27T10:39:58.024398",
     "exception": false,
     "start_time": "2023-08-27T10:39:57.974536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640a603",
   "metadata": {
    "papermill": {
     "duration": 0.050223,
     "end_time": "2023-08-27T10:39:58.124082",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.073859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368974bd",
   "metadata": {
    "papermill": {
     "duration": 0.049707,
     "end_time": "2023-08-27T10:39:58.223604",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.173897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2b6be",
   "metadata": {
    "papermill": {
     "duration": 0.05004,
     "end_time": "2023-08-27T10:39:58.323261",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.273221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b3ccc",
   "metadata": {
    "papermill": {
     "duration": 0.051745,
     "end_time": "2023-08-27T10:39:58.425747",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.374002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db823335",
   "metadata": {
    "papermill": {
     "duration": 0.050082,
     "end_time": "2023-08-27T10:39:58.527640",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.477558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bdd48",
   "metadata": {
    "papermill": {
     "duration": 0.049892,
     "end_time": "2023-08-27T10:39:58.628232",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.578340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153c45f",
   "metadata": {
    "papermill": {
     "duration": 0.049685,
     "end_time": "2023-08-27T10:39:58.729573",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.679888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ab005",
   "metadata": {
    "papermill": {
     "duration": 0.051431,
     "end_time": "2023-08-27T10:39:58.831588",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.780157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11aac5",
   "metadata": {
    "papermill": {
     "duration": 0.049701,
     "end_time": "2023-08-27T10:39:58.930926",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.881225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb62e86",
   "metadata": {
    "papermill": {
     "duration": 0.050127,
     "end_time": "2023-08-27T10:39:59.030900",
     "exception": false,
     "start_time": "2023-08-27T10:39:58.980773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3b99c",
   "metadata": {
    "papermill": {
     "duration": 0.050557,
     "end_time": "2023-08-27T10:39:59.131142",
     "exception": false,
     "start_time": "2023-08-27T10:39:59.080585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8789615",
   "metadata": {
    "papermill": {
     "duration": 0.050121,
     "end_time": "2023-08-27T10:39:59.231135",
     "exception": false,
     "start_time": "2023-08-27T10:39:59.181014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d06955",
   "metadata": {
    "papermill": {
     "duration": 0.051618,
     "end_time": "2023-08-27T10:39:59.332628",
     "exception": false,
     "start_time": "2023-08-27T10:39:59.281010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15836.003106,
   "end_time": "2023-08-27T10:40:02.571775",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-27T06:16:06.568669",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
